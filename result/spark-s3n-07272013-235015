run1 #: 0

spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:50:18 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:50:18 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:43502
Creating SparkContext...
13/07/27 23:50:27 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:50:27 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:50:27 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:50:27 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235027-4498
13/07/27 23:50:27 INFO network.ConnectionManager: Bound socket to port 41623 with id = ConnectionManagerId(tachyon-ec2-0,41623)
13/07/27 23:50:27 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:50:27 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:41623 with 1295.4 MB RAM
13/07/27 23:50:27 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:50:27 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:50:27 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:47544
13/07/27 23:50:27 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:47544
13/07/27 23:50:27 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:50:27 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-1bd799b6-d7ef-4d52-aae7-1da63caa8bb8
13/07/27 23:50:27 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:50:27 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:46778
13/07/27 23:50:27 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:50:27 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:50:27 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:50:27 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:50:27 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:50:27 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:50:27 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:50:27 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:50:27 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:50:27 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:50:27 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1").cache()
13/07/27 23:50:29 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:50:29 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:50:29 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:50:29 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:50:30 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:50:30 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:50:30 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:50:30 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:50:30 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:50:30 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:50:30 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:50:30 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:50:30 INFO local.LocalTaskSetManager: Size of task 0 is 1492 bytes
13/07/27 23:50:30 INFO local.LocalScheduler: Running 0
13/07/27 23:50:30 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:50:30 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:50:30 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1' for reading
13/07/27 23:50:30 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1' for reading at position '0'
13/07/27 23:50:30 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58407, maxMem=1358297825
13/07/27 23:50:30 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/27 23:50:30 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:41623 (size: 1192.0 B, free: 1295.4 MB)
13/07/27 23:50:30 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:50:30 INFO local.LocalScheduler: Finished 0
13/07/27 23:50:30 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:50:30 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:50:30 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.419 s
13/07/27 23:50:30 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.466185548 s
res0: Long = 1

scala> 13/07/27 23:50:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:50:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:50:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:50:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:50:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:50:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:50:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:50:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:50:33 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:50:33 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50176
Creating SparkContext...
13/07/27 23:50:42 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:50:42 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:50:42 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:50:42 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235042-71c4
13/07/27 23:50:42 INFO network.ConnectionManager: Bound socket to port 53888 with id = ConnectionManagerId(tachyon-ec2-0,53888)
13/07/27 23:50:42 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:50:42 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:53888 with 1295.4 MB RAM
13/07/27 23:50:42 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:50:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:50:42 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38849
13/07/27 23:50:42 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:38849
13/07/27 23:50:42 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:50:42 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-7c2a2dd7-8ce8-41ab-8054-66eb86eb08aa
13/07/27 23:50:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:50:42 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:43157
13/07/27 23:50:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:50:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:50:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:50:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:50:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:50:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:50:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:50:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:50:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:50:42 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:50:42 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100").cache()
13/07/27 23:50:44 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:50:44 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:50:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:50:44 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:50:45 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:50:45 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:50:45 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:50:45 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:50:45 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:50:45 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:50:45 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:50:45 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:50:45 INFO local.LocalTaskSetManager: Size of task 0 is 1494 bytes
13/07/27 23:50:45 INFO local.LocalScheduler: Running 0
13/07/27 23:50:45 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:50:45 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:50:45 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100' for reading
13/07/27 23:50:45 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100' for reading at position '0'
13/07/27 23:50:45 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58407, maxMem=1358297825
13/07/27 23:50:45 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/27 23:50:45 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:53888 (size: 113.4 KB, free: 1295.3 MB)
13/07/27 23:50:45 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:50:45 INFO local.LocalScheduler: Finished 0
13/07/27 23:50:45 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:50:45 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:50:45 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.372 s
13/07/27 23:50:45 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.417656238 s
res0: Long = 100

scala> 13/07/27 23:50:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:50:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:50:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:50:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:50:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:50:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:50:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:50:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:50:48 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:50:48 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:33221
Creating SparkContext...
13/07/27 23:50:57 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:50:58 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:50:58 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:50:58 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235058-8f33
13/07/27 23:50:58 INFO network.ConnectionManager: Bound socket to port 55213 with id = ConnectionManagerId(tachyon-ec2-0,55213)
13/07/27 23:50:58 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:50:58 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:55213 with 1295.4 MB RAM
13/07/27 23:50:58 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:50:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:50:58 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:46283
13/07/27 23:50:58 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:46283
13/07/27 23:50:58 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:50:58 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-5b70d580-a46b-4d98-ada9-7cc37b7dc680
13/07/27 23:50:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:50:58 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:54610
13/07/27 23:50:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:50:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:50:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:50:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:50:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:50:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:50:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:50:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:50:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:50:58 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:50:58 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1000").cache()
13/07/27 23:50:59 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/27 23:50:59 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:50:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:50:59 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:51:00 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:51:00 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:51:00 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:51:00 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:51:00 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:51:00 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:51:00 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:51:00 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:51:00 INFO local.LocalTaskSetManager: Size of task 0 is 1495 bytes
13/07/27 23:51:00 INFO local.LocalScheduler: Running 0
13/07/27 23:51:00 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:51:00 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:51:01 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1000' for reading
13/07/27 23:51:01 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1000' for reading at position '0'
13/07/27 23:51:01 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58415, maxMem=1358297825
13/07/27 23:51:01 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/27 23:51:01 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:55213 (size: 1580.2 KB, free: 1293.8 MB)
13/07/27 23:51:01 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:51:01 INFO local.LocalScheduler: Finished 0
13/07/27 23:51:01 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:51:01 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:51:01 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.752 s
13/07/27 23:51:01 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.79817811 s
res0: Long = 1000

scala> 13/07/27 23:51:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:51:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:51:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:51:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:51:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:51:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:51:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:51:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:51:04 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:51:04 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55992
Creating SparkContext...
13/07/27 23:51:13 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:51:13 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:51:13 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:51:13 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235113-7ece
13/07/27 23:51:13 INFO network.ConnectionManager: Bound socket to port 44588 with id = ConnectionManagerId(tachyon-ec2-0,44588)
13/07/27 23:51:13 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:51:13 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:44588 with 1295.4 MB RAM
13/07/27 23:51:13 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:51:13 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:51:13 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:39385
13/07/27 23:51:13 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:39385
13/07/27 23:51:13 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:51:13 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-eeea6da0-3894-428f-8894-1de369fcdcc0
13/07/27 23:51:13 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:51:13 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55137
13/07/27 23:51:13 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:51:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:51:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:51:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:51:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:51:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:51:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:51:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:51:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:51:13 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:51:13 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.10000").cache()
13/07/27 23:51:15 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/27 23:51:15 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:51:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:51:15 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:51:16 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:51:16 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:51:16 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:51:16 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:51:16 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:51:16 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:51:16 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:51:16 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:51:16 INFO local.LocalTaskSetManager: Size of task 0 is 1496 bytes
13/07/27 23:51:16 INFO local.LocalScheduler: Running 0
13/07/27 23:51:16 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:51:16 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:51:16 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.10000' for reading
13/07/27 23:51:16 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.10000' for reading at position '0'
13/07/27 23:51:17 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58415, maxMem=1358297825
13/07/27 23:51:17 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/27 23:51:17 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:44588 (size: 25.0 MB, free: 1270.4 MB)
13/07/27 23:51:17 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:51:17 INFO local.LocalScheduler: Finished 0
13/07/27 23:51:17 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:51:17 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:51:17 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.168 s
13/07/27 23:51:17 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.215403971 s
res0: Long = 10000

scala> 13/07/27 23:51:17 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:51:17 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:51:17 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:51:17 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:51:17 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:51:17 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:51:17 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:51:17 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:51:20 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:51:20 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38818
Creating SparkContext...
13/07/27 23:51:29 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:51:29 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:51:29 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:51:29 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235129-8c4b
13/07/27 23:51:29 INFO network.ConnectionManager: Bound socket to port 34810 with id = ConnectionManagerId(tachyon-ec2-0,34810)
13/07/27 23:51:29 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:51:29 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:34810 with 1295.4 MB RAM
13/07/27 23:51:29 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:51:29 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:51:29 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38587
13/07/27 23:51:29 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:38587
13/07/27 23:51:29 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:51:29 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-c8e06767-d74b-416c-b5f3-58379a0cfcb3
13/07/27 23:51:29 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:51:29 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:43983
13/07/27 23:51:29 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:51:29 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:51:29 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:51:29 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:51:29 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:51:29 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:51:29 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:51:29 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:51:29 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:51:29 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:51:29 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100000").cache()
13/07/27 23:51:31 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/27 23:51:31 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:51:31 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:51:31 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:51:32 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:51:32 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:51:32 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:51:32 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:51:32 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:51:32 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:51:32 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:51:32 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:51:32 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/27 23:51:32 INFO local.LocalScheduler: Running 0
13/07/27 23:51:32 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:51:32 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:51:32 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100000' for reading
13/07/27 23:51:32 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100000' for reading at position '0'
13/07/27 23:51:37 INFO storage.MemoryStore: ensureFreeSpace(261997239) called with curMem=58415, maxMem=1358297825
13/07/27 23:51:37 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 249.9 MB, free 1045.5 MB)
13/07/27 23:51:37 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:34810 (size: 249.9 MB, free: 1045.5 MB)
13/07/27 23:51:37 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:51:37 INFO local.LocalScheduler: Finished 0
13/07/27 23:51:37 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:51:37 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:51:37 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 5.471 s
13/07/27 23:51:37 INFO spark.SparkContext: Job finished: count at <console>:15, took 5.516285995 s
res0: Long = 100002

scala> 13/07/27 23:51:37 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:51:37 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:51:37 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:51:37 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:51:37 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:51:37 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:51:37 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:51:37 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:51:40 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:51:40 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37535
Creating SparkContext...
13/07/27 23:51:49 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:51:49 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:51:50 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:51:50 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235150-60f1
13/07/27 23:51:50 INFO network.ConnectionManager: Bound socket to port 34445 with id = ConnectionManagerId(tachyon-ec2-0,34445)
13/07/27 23:51:50 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:51:50 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:34445 with 1295.4 MB RAM
13/07/27 23:51:50 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:51:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:51:50 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:45317
13/07/27 23:51:50 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:45317
13/07/27 23:51:50 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:51:50 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-fe15d6ec-1b7a-4e3d-af93-619e1b13b270
13/07/27 23:51:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:51:50 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:45063
13/07/27 23:51:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:51:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:51:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:51:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:51:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:51:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:51:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:51:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:51:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:51:50 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:51:50 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.500000").cache()
13/07/27 23:51:51 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/27 23:51:51 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:51:51 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:51:51 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:51:52 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:51:52 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:51:52 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:51:52 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:51:52 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:51:52 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:51:52 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:51:52 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:51:52 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/27 23:51:52 INFO local.LocalScheduler: Running 0
13/07/27 23:51:52 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:51:52 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:51:53 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.500000' for reading
13/07/27 23:51:53 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.500000' for reading at position '0'
13/07/27 23:52:33 INFO storage.MemoryStore: ensureFreeSpace(1288783830) called with curMem=58415, maxMem=1358297825
13/07/27 23:52:33 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1229.1 MB, free 66.2 MB)
13/07/27 23:52:33 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:34445 (size: 1229.1 MB, free: 66.3 MB)
13/07/27 23:52:33 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:52:33 INFO local.LocalScheduler: Finished 0
13/07/27 23:52:33 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:52:33 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:52:33 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 40.748 s
13/07/27 23:52:33 INFO spark.SparkContext: Job finished: count at <console>:15, took 40.793683437 s
res0: Long = 500094

scala> 13/07/27 23:52:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:52:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:52:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:52:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:52:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:52:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:52:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:52:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 1

spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:52:36 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:52:36 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:32869
Creating SparkContext...
13/07/27 23:52:45 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:52:45 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:52:45 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:52:45 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235245-fc55
13/07/27 23:52:45 INFO network.ConnectionManager: Bound socket to port 39967 with id = ConnectionManagerId(tachyon-ec2-0,39967)
13/07/27 23:52:45 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:52:45 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:39967 with 1295.4 MB RAM
13/07/27 23:52:45 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:52:45 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:52:45 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:56882
13/07/27 23:52:45 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:56882
13/07/27 23:52:45 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:52:45 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-141452ae-04ab-4f54-8491-e616be527650
13/07/27 23:52:45 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:52:45 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59421
13/07/27 23:52:45 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:52:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:52:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:52:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:52:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:52:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:52:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:52:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:52:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:52:45 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:52:45 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1").cache()
13/07/27 23:52:47 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:52:47 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:52:47 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:52:47 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:52:48 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:52:48 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:52:48 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:52:48 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:52:48 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:52:48 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:52:48 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:52:48 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:52:48 INFO local.LocalTaskSetManager: Size of task 0 is 1492 bytes
13/07/27 23:52:48 INFO local.LocalScheduler: Running 0
13/07/27 23:52:48 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:52:48 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:52:48 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1' for reading
13/07/27 23:52:48 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1' for reading at position '0'
13/07/27 23:52:48 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58407, maxMem=1358297825
13/07/27 23:52:48 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/27 23:52:48 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:39967 (size: 1192.0 B, free: 1295.4 MB)
13/07/27 23:52:48 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:52:48 INFO local.LocalScheduler: Finished 0
13/07/27 23:52:48 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:52:48 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:52:48 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.305 s
13/07/27 23:52:48 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.350652255 s
res0: Long = 1

scala> 13/07/27 23:52:48 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:52:48 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:52:48 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:52:48 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:52:48 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:52:48 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:52:48 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:52:48 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:52:51 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:52:51 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:35138
Creating SparkContext...
13/07/27 23:53:00 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:53:00 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:53:00 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:53:00 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235300-508d
13/07/27 23:53:00 INFO network.ConnectionManager: Bound socket to port 40869 with id = ConnectionManagerId(tachyon-ec2-0,40869)
13/07/27 23:53:00 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:53:00 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:40869 with 1295.4 MB RAM
13/07/27 23:53:00 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:53:00 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:53:00 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59050
13/07/27 23:53:00 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:59050
13/07/27 23:53:00 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:53:00 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-312814e9-2d56-400c-b110-45c9a5a7a3f2
13/07/27 23:53:00 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:53:00 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53012
13/07/27 23:53:00 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:53:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:53:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:53:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:53:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:53:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:53:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:53:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:53:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:53:00 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:53:00 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100").cache()
13/07/27 23:53:02 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:53:02 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:53:02 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:53:02 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:53:03 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:53:03 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:53:03 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:53:03 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:53:03 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:53:03 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:53:03 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:53:03 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:53:03 INFO local.LocalTaskSetManager: Size of task 0 is 1494 bytes
13/07/27 23:53:03 INFO local.LocalScheduler: Running 0
13/07/27 23:53:03 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:53:03 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:53:03 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100' for reading
13/07/27 23:53:03 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100' for reading at position '0'
13/07/27 23:53:03 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58407, maxMem=1358297825
13/07/27 23:53:03 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/27 23:53:03 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:40869 (size: 113.4 KB, free: 1295.3 MB)
13/07/27 23:53:03 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:53:03 INFO local.LocalScheduler: Finished 0
13/07/27 23:53:03 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:53:03 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:53:03 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.346 s
13/07/27 23:53:03 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.390990193 s
res0: Long = 100

scala> 13/07/27 23:53:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:53:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:53:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:53:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:53:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:53:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:53:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:53:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:53:06 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:53:06 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:45072
Creating SparkContext...
13/07/27 23:53:15 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:53:15 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:53:15 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:53:15 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235315-bbd3
13/07/27 23:53:15 INFO network.ConnectionManager: Bound socket to port 47919 with id = ConnectionManagerId(tachyon-ec2-0,47919)
13/07/27 23:53:15 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:53:15 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:47919 with 1295.4 MB RAM
13/07/27 23:53:15 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:53:15 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:53:15 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:41176
13/07/27 23:53:15 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:41176
13/07/27 23:53:15 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:53:15 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-3c8045c2-c26c-4690-8afa-ac1becc0f6a2
13/07/27 23:53:15 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:53:15 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:39124
13/07/27 23:53:15 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:53:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:53:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:53:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:53:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:53:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:53:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:53:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:53:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:53:15 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:53:15 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1000").cache()
13/07/27 23:53:17 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/27 23:53:17 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:53:17 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:53:17 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:53:18 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:53:18 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:53:18 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:53:18 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:53:18 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:53:18 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:53:18 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:53:18 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:53:18 INFO local.LocalTaskSetManager: Size of task 0 is 1495 bytes
13/07/27 23:53:18 INFO local.LocalScheduler: Running 0
13/07/27 23:53:18 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:53:18 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:53:18 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1000' for reading
13/07/27 23:53:18 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1000' for reading at position '0'
13/07/27 23:53:18 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58415, maxMem=1358297825
13/07/27 23:53:18 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/27 23:53:18 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:47919 (size: 1580.2 KB, free: 1293.8 MB)
13/07/27 23:53:18 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:53:19 INFO local.LocalScheduler: Finished 0
13/07/27 23:53:19 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:53:19 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:53:19 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.618 s
13/07/27 23:53:19 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.663874812 s
res0: Long = 1000

scala> 13/07/27 23:53:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:53:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:53:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:53:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:53:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:53:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:53:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:53:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:53:21 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:53:21 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53667
Creating SparkContext...
13/07/27 23:53:30 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:53:31 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:53:31 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:53:31 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235331-13c4
13/07/27 23:53:31 INFO network.ConnectionManager: Bound socket to port 60729 with id = ConnectionManagerId(tachyon-ec2-0,60729)
13/07/27 23:53:31 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:53:31 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:60729 with 1295.4 MB RAM
13/07/27 23:53:31 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:53:31 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:53:31 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:56929
13/07/27 23:53:31 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:56929
13/07/27 23:53:31 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:53:31 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-607c3372-0d1c-4124-96a8-24f462b9be7c
13/07/27 23:53:31 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:53:31 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37839
13/07/27 23:53:31 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:53:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:53:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:53:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:53:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:53:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:53:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:53:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:53:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:53:31 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:53:31 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.10000").cache()
13/07/27 23:53:32 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/27 23:53:32 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:53:33 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:53:33 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:53:33 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:53:33 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:53:33 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:53:33 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:53:33 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:53:33 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:53:33 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:53:33 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:53:33 INFO local.LocalTaskSetManager: Size of task 0 is 1496 bytes
13/07/27 23:53:33 INFO local.LocalScheduler: Running 0
13/07/27 23:53:33 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:53:33 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:53:34 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.10000' for reading
13/07/27 23:53:34 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.10000' for reading at position '0'
13/07/27 23:53:35 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58415, maxMem=1358297825
13/07/27 23:53:35 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/27 23:53:35 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:60729 (size: 25.0 MB, free: 1270.4 MB)
13/07/27 23:53:35 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:53:35 INFO local.LocalScheduler: Finished 0
13/07/27 23:53:35 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:53:35 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:53:35 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.299 s
13/07/27 23:53:35 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.344455546 s
res0: Long = 10000

scala> 13/07/27 23:53:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:53:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:53:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:53:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:53:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:53:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:53:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:53:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:53:37 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:53:37 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:46344
Creating SparkContext...
13/07/27 23:53:46 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:53:47 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:53:47 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:53:47 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235347-fc7c
13/07/27 23:53:47 INFO network.ConnectionManager: Bound socket to port 53727 with id = ConnectionManagerId(tachyon-ec2-0,53727)
13/07/27 23:53:47 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:53:47 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:53727 with 1295.4 MB RAM
13/07/27 23:53:47 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:53:47 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:53:47 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:36575
13/07/27 23:53:47 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:36575
13/07/27 23:53:47 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:53:47 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-6b1d2955-5870-4a5c-bd2d-9d38d6199221
13/07/27 23:53:47 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:53:47 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:34526
13/07/27 23:53:47 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:53:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:53:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:53:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:53:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:53:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:53:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:53:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:53:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:53:47 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:53:47 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100000").cache()
13/07/27 23:53:48 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/27 23:53:48 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:53:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:53:49 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:53:49 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:53:49 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:53:49 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:53:49 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:53:49 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:53:49 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:53:49 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:53:49 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:53:49 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/27 23:53:49 INFO local.LocalScheduler: Running 0
13/07/27 23:53:50 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:53:50 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:53:50 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100000' for reading
13/07/27 23:53:50 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100000' for reading at position '0'
13/07/27 23:53:57 INFO storage.MemoryStore: ensureFreeSpace(261997239) called with curMem=58415, maxMem=1358297825
13/07/27 23:53:57 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 249.9 MB, free 1045.5 MB)
13/07/27 23:53:57 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:53727 (size: 249.9 MB, free: 1045.5 MB)
13/07/27 23:53:57 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:53:57 INFO local.LocalScheduler: Finished 0
13/07/27 23:53:57 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:53:57 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:53:57 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 7.338 s
13/07/27 23:53:57 INFO spark.SparkContext: Job finished: count at <console>:15, took 7.384369998 s
res0: Long = 100002

scala> 13/07/27 23:53:57 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:53:57 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:53:57 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:53:57 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:53:57 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:53:57 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:53:57 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:53:57 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:53:59 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:53:59 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:35812
Creating SparkContext...
13/07/27 23:54:09 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:54:09 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:54:09 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:54:09 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235409-75e0
13/07/27 23:54:09 INFO network.ConnectionManager: Bound socket to port 34882 with id = ConnectionManagerId(tachyon-ec2-0,34882)
13/07/27 23:54:09 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:54:09 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:34882 with 1295.4 MB RAM
13/07/27 23:54:09 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:54:09 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:54:09 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:33898
13/07/27 23:54:09 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:33898
13/07/27 23:54:09 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:54:09 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-d00caed1-ac1e-431c-80c7-48ae3f677cca
13/07/27 23:54:09 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:54:09 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59592
13/07/27 23:54:09 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:54:09 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:54:09 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:54:09 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:54:09 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:54:09 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:54:09 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:54:09 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:54:09 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:54:09 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:54:09 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.500000").cache()
13/07/27 23:54:10 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/27 23:54:10 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:54:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:54:11 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:54:12 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:54:12 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:54:12 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:54:12 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:54:12 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:54:12 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:54:12 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:54:12 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:54:12 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/27 23:54:12 INFO local.LocalScheduler: Running 0
13/07/27 23:54:12 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:54:12 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:54:12 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.500000' for reading
13/07/27 23:54:12 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.500000' for reading at position '0'
13/07/27 23:54:45 INFO storage.MemoryStore: ensureFreeSpace(1288783830) called with curMem=58415, maxMem=1358297825
13/07/27 23:54:45 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1229.1 MB, free 66.2 MB)
13/07/27 23:54:45 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:34882 (size: 1229.1 MB, free: 66.3 MB)
13/07/27 23:54:45 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:54:45 INFO local.LocalScheduler: Finished 0
13/07/27 23:54:45 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:54:45 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:54:45 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 33.152 s
13/07/27 23:54:45 INFO spark.SparkContext: Job finished: count at <console>:15, took 33.196527965 s
res0: Long = 500094

scala> 13/07/27 23:54:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:54:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:54:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:54:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:54:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:54:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:54:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:54:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 2

spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:54:47 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:54:47 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38932
Creating SparkContext...
13/07/27 23:54:57 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:54:57 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:54:57 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:54:57 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235457-b82f
13/07/27 23:54:57 INFO network.ConnectionManager: Bound socket to port 60028 with id = ConnectionManagerId(tachyon-ec2-0,60028)
13/07/27 23:54:57 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:54:57 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:60028 with 1295.4 MB RAM
13/07/27 23:54:57 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:54:57 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:54:57 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:57034
13/07/27 23:54:57 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:57034
13/07/27 23:54:57 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:54:57 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-d39ebf7f-f011-4d2b-b722-016884ef1f88
13/07/27 23:54:57 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:54:57 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:33979
13/07/27 23:54:57 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:54:57 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:54:57 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:54:57 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:54:57 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:54:57 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:54:57 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:54:57 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:54:57 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:54:57 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:54:57 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1").cache()
13/07/27 23:54:58 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:54:58 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:54:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:54:59 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:55:00 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:55:00 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:55:00 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:55:00 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:55:00 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:55:00 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:55:00 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:55:00 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:55:00 INFO local.LocalTaskSetManager: Size of task 0 is 1492 bytes
13/07/27 23:55:00 INFO local.LocalScheduler: Running 0
13/07/27 23:55:00 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:55:00 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:55:00 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1' for reading
13/07/27 23:55:00 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1' for reading at position '0'
13/07/27 23:55:00 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58407, maxMem=1358297825
13/07/27 23:55:00 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/27 23:55:00 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:60028 (size: 1192.0 B, free: 1295.4 MB)
13/07/27 23:55:00 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:55:00 INFO local.LocalScheduler: Finished 0
13/07/27 23:55:00 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:55:00 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:55:00 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.307 s
13/07/27 23:55:00 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.352323304 s
res0: Long = 1

scala> 13/07/27 23:55:00 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:55:00 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:55:00 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:55:00 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:55:00 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:55:00 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:55:00 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:55:00 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:55:03 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:55:03 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50787
Creating SparkContext...
13/07/27 23:55:12 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:55:12 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:55:12 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:55:12 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235512-b506
13/07/27 23:55:12 INFO network.ConnectionManager: Bound socket to port 55542 with id = ConnectionManagerId(tachyon-ec2-0,55542)
13/07/27 23:55:12 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:55:12 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:55542 with 1295.4 MB RAM
13/07/27 23:55:12 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:55:12 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:55:12 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50272
13/07/27 23:55:12 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:50272
13/07/27 23:55:12 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:55:12 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-23f15ee2-a93e-4013-ae7f-6072ee837d95
13/07/27 23:55:12 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:55:12 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:57878
13/07/27 23:55:12 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:55:12 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:55:12 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:55:12 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:55:12 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:55:12 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:55:12 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:55:12 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:55:12 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:55:12 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:55:12 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100").cache()
13/07/27 23:55:13 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:55:13 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:55:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:55:14 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:55:14 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:55:15 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:55:15 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:55:15 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:55:15 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:55:15 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:55:15 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:55:15 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:55:15 INFO local.LocalTaskSetManager: Size of task 0 is 1494 bytes
13/07/27 23:55:15 INFO local.LocalScheduler: Running 0
13/07/27 23:55:15 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:55:15 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:55:15 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100' for reading
13/07/27 23:55:15 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100' for reading at position '0'
13/07/27 23:55:15 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58407, maxMem=1358297825
13/07/27 23:55:15 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/27 23:55:15 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:55542 (size: 113.4 KB, free: 1295.3 MB)
13/07/27 23:55:15 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:55:15 INFO local.LocalScheduler: Finished 0
13/07/27 23:55:15 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:55:15 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:55:15 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.405 s
13/07/27 23:55:15 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.44978362 s
res0: Long = 100

scala> 13/07/27 23:55:15 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:55:15 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:55:15 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:55:15 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:55:15 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:55:15 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:55:15 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:55:15 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:55:18 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:55:18 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:48853
Creating SparkContext...
13/07/27 23:55:27 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:55:27 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:55:27 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:55:27 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235527-3054
13/07/27 23:55:27 INFO network.ConnectionManager: Bound socket to port 45871 with id = ConnectionManagerId(tachyon-ec2-0,45871)
13/07/27 23:55:27 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:55:27 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:45871 with 1295.4 MB RAM
13/07/27 23:55:27 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:55:27 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:55:27 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60462
13/07/27 23:55:27 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:60462
13/07/27 23:55:27 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:55:27 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-d23db179-e829-4010-9195-7b42360d864a
13/07/27 23:55:27 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:55:27 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:34059
13/07/27 23:55:27 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:55:27 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:55:27 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:55:27 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:55:27 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:55:27 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:55:27 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:55:27 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:55:27 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:55:27 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:55:27 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1000").cache()
13/07/27 23:55:29 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/27 23:55:29 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:55:29 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:55:29 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:55:30 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:55:30 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:55:30 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:55:30 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:55:30 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:55:30 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:55:30 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:55:30 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:55:30 INFO local.LocalTaskSetManager: Size of task 0 is 1495 bytes
13/07/27 23:55:30 INFO local.LocalScheduler: Running 0
13/07/27 23:55:30 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:55:30 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:55:30 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1000' for reading
13/07/27 23:55:30 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1000' for reading at position '0'
13/07/27 23:55:30 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58415, maxMem=1358297825
13/07/27 23:55:30 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/27 23:55:30 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:45871 (size: 1580.2 KB, free: 1293.8 MB)
13/07/27 23:55:30 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:55:30 INFO local.LocalScheduler: Finished 0
13/07/27 23:55:30 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:55:30 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:55:30 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.528 s
13/07/27 23:55:30 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.572638771 s
res0: Long = 1000

scala> 13/07/27 23:55:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:55:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:55:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:55:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:55:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:55:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:55:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:55:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:55:33 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:55:33 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:48188
Creating SparkContext...
13/07/27 23:55:42 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:55:42 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:55:42 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:55:42 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235542-5f5f
13/07/27 23:55:42 INFO network.ConnectionManager: Bound socket to port 43078 with id = ConnectionManagerId(tachyon-ec2-0,43078)
13/07/27 23:55:42 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:55:42 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:43078 with 1295.4 MB RAM
13/07/27 23:55:42 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:55:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:55:42 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53743
13/07/27 23:55:42 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:53743
13/07/27 23:55:42 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:55:42 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-ec46e1f0-fc97-4fd4-ae97-88c9fb7200be
13/07/27 23:55:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:55:42 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:51780
13/07/27 23:55:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:55:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:55:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:55:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:55:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:55:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:55:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:55:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:55:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:55:42 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:55:42 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.10000").cache()
13/07/27 23:55:44 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/27 23:55:44 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:55:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:55:44 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:55:45 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:55:45 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:55:45 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:55:45 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:55:45 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:55:45 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:55:45 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:55:45 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:55:45 INFO local.LocalTaskSetManager: Size of task 0 is 1496 bytes
13/07/27 23:55:45 INFO local.LocalScheduler: Running 0
13/07/27 23:55:45 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:55:45 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:55:45 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.10000' for reading
13/07/27 23:55:45 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.10000' for reading at position '0'
13/07/27 23:55:46 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58415, maxMem=1358297825
13/07/27 23:55:46 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/27 23:55:46 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:43078 (size: 25.0 MB, free: 1270.4 MB)
13/07/27 23:55:46 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:55:46 INFO local.LocalScheduler: Finished 0
13/07/27 23:55:46 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:55:46 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:55:46 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.318 s
13/07/27 23:55:46 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.363282599 s
res0: Long = 10000

scala> 13/07/27 23:55:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:55:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:55:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:55:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:55:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:55:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:55:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:55:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:55:49 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:55:49 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:42191
Creating SparkContext...
13/07/27 23:55:58 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:55:58 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:55:58 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:55:58 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235558-2211
13/07/27 23:55:58 INFO network.ConnectionManager: Bound socket to port 37599 with id = ConnectionManagerId(tachyon-ec2-0,37599)
13/07/27 23:55:58 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:55:58 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:37599 with 1295.4 MB RAM
13/07/27 23:55:58 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:55:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:55:58 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:40541
13/07/27 23:55:58 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:40541
13/07/27 23:55:58 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:55:58 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-bb9bdba9-7758-4f6d-b08f-8d015912e26b
13/07/27 23:55:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:55:58 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:34126
13/07/27 23:55:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:55:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:55:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:55:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:55:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:55:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:55:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:55:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:55:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:55:58 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:55:58 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100000").cache()
13/07/27 23:56:00 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/27 23:56:00 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:56:00 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:56:00 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:56:01 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:56:01 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:56:01 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:56:01 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:56:01 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:56:01 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:56:01 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:56:01 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:56:01 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/27 23:56:01 INFO local.LocalScheduler: Running 0
13/07/27 23:56:01 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:56:01 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:56:01 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100000' for reading
13/07/27 23:56:01 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100000' for reading at position '0'
13/07/27 23:56:09 INFO storage.MemoryStore: ensureFreeSpace(261997239) called with curMem=58415, maxMem=1358297825
13/07/27 23:56:09 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 249.9 MB, free 1045.5 MB)
13/07/27 23:56:09 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:37599 (size: 249.9 MB, free: 1045.5 MB)
13/07/27 23:56:09 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:56:09 INFO local.LocalScheduler: Finished 0
13/07/27 23:56:09 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:56:09 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:56:09 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 7.811 s
13/07/27 23:56:09 INFO spark.SparkContext: Job finished: count at <console>:15, took 7.856125092 s
res0: Long = 100002

scala> 13/07/27 23:56:09 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:56:09 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:56:09 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:56:09 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:56:09 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:56:09 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:56:09 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:56:09 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:56:11 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:56:11 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60696
Creating SparkContext...
13/07/27 23:56:21 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:56:21 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:56:21 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:56:21 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235621-23ca
13/07/27 23:56:21 INFO network.ConnectionManager: Bound socket to port 42378 with id = ConnectionManagerId(tachyon-ec2-0,42378)
13/07/27 23:56:21 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:56:21 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:42378 with 1295.4 MB RAM
13/07/27 23:56:21 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:56:21 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:56:21 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:51420
13/07/27 23:56:21 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:51420
13/07/27 23:56:21 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:56:21 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-1c32595f-c53c-4d9c-8b67-3334fd6dae08
13/07/27 23:56:21 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:56:21 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:35314
13/07/27 23:56:21 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:56:21 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:56:21 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:56:21 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:56:21 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:56:21 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:56:21 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:56:21 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:56:21 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:56:21 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:56:21 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.500000").cache()
13/07/27 23:56:22 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/27 23:56:22 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:56:23 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:56:23 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:56:23 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:56:23 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:56:23 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:56:23 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:56:23 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:56:23 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:56:23 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:56:23 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:56:24 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/27 23:56:24 INFO local.LocalScheduler: Running 0
13/07/27 23:56:24 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:56:24 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:56:24 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.500000' for reading
13/07/27 23:56:24 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.500000' for reading at position '0'
13/07/27 23:56:58 INFO storage.MemoryStore: ensureFreeSpace(1288783830) called with curMem=58415, maxMem=1358297825
13/07/27 23:56:58 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1229.1 MB, free 66.2 MB)
13/07/27 23:56:58 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:42378 (size: 1229.1 MB, free: 66.3 MB)
13/07/27 23:56:58 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:56:58 INFO local.LocalScheduler: Finished 0
13/07/27 23:56:58 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:56:58 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:56:58 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 34.978 s
13/07/27 23:56:58 INFO spark.SparkContext: Job finished: count at <console>:15, took 35.023524259 s
res0: Long = 500094

scala> 13/07/27 23:56:59 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:56:59 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:56:59 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:56:59 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:56:59 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:56:59 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:56:59 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:56:59 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 3

spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:57:01 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:57:01 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:41082
Creating SparkContext...
13/07/27 23:57:11 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:57:11 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:57:11 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:57:11 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235711-fea1
13/07/27 23:57:11 INFO network.ConnectionManager: Bound socket to port 48484 with id = ConnectionManagerId(tachyon-ec2-0,48484)
13/07/27 23:57:11 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:57:11 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:48484 with 1295.4 MB RAM
13/07/27 23:57:11 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:57:11 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:57:11 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38474
13/07/27 23:57:11 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:38474
13/07/27 23:57:11 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:57:11 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-e826eaf1-fbf4-4561-a3c0-e555859c8c87
13/07/27 23:57:11 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:57:11 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:35343
13/07/27 23:57:11 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:57:11 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:57:11 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:57:11 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:57:11 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:57:11 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:57:11 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:57:11 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:57:11 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:57:11 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:57:11 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1").cache()
13/07/27 23:57:12 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:57:12 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:57:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:57:13 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:57:13 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:57:13 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:57:13 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:57:13 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:57:13 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:57:13 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:57:13 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:57:13 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:57:13 INFO local.LocalTaskSetManager: Size of task 0 is 1492 bytes
13/07/27 23:57:13 INFO local.LocalScheduler: Running 0
13/07/27 23:57:14 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:57:14 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:57:14 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1' for reading
13/07/27 23:57:14 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1' for reading at position '0'
13/07/27 23:57:14 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58407, maxMem=1358297825
13/07/27 23:57:14 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/27 23:57:14 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:48484 (size: 1192.0 B, free: 1295.4 MB)
13/07/27 23:57:14 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:57:14 INFO local.LocalScheduler: Finished 0
13/07/27 23:57:14 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:57:14 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:57:14 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.297 s
13/07/27 23:57:14 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.342243184 s
res0: Long = 1

scala> 13/07/27 23:57:14 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:57:14 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:57:14 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:57:14 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:57:14 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:57:14 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:57:14 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:57:14 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:57:16 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:57:16 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:56548
Creating SparkContext...
13/07/27 23:57:26 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:57:26 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:57:26 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:57:26 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235726-8fbf
13/07/27 23:57:26 INFO network.ConnectionManager: Bound socket to port 44057 with id = ConnectionManagerId(tachyon-ec2-0,44057)
13/07/27 23:57:26 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:57:26 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:44057 with 1295.4 MB RAM
13/07/27 23:57:26 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:57:26 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:57:26 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60803
13/07/27 23:57:26 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:60803
13/07/27 23:57:26 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:57:26 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-ad398140-3ba4-44f3-a36a-c24e35e8b4da
13/07/27 23:57:26 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:57:26 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50126
13/07/27 23:57:26 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:57:26 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:57:26 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:57:26 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:57:26 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:57:26 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:57:26 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:57:26 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:57:26 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:57:26 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:57:26 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100").cache()
13/07/27 23:57:27 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:57:27 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:57:28 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:57:28 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:57:28 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:57:28 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:57:28 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:57:28 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:57:28 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:57:28 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:57:28 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:57:28 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:57:28 INFO local.LocalTaskSetManager: Size of task 0 is 1494 bytes
13/07/27 23:57:28 INFO local.LocalScheduler: Running 0
13/07/27 23:57:29 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:57:29 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:57:29 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100' for reading
13/07/27 23:57:29 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100' for reading at position '0'
13/07/27 23:57:29 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58407, maxMem=1358297825
13/07/27 23:57:29 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/27 23:57:29 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:44057 (size: 113.4 KB, free: 1295.3 MB)
13/07/27 23:57:29 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:57:29 INFO local.LocalScheduler: Finished 0
13/07/27 23:57:29 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:57:29 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:57:29 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.368 s
13/07/27 23:57:29 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.414433739 s
res0: Long = 100

scala> 13/07/27 23:57:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:57:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:57:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:57:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:57:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:57:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:57:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:57:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:57:31 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:57:31 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53435
Creating SparkContext...
13/07/27 23:57:41 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:57:41 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:57:41 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:57:41 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235741-b0b3
13/07/27 23:57:41 INFO network.ConnectionManager: Bound socket to port 32782 with id = ConnectionManagerId(tachyon-ec2-0,32782)
13/07/27 23:57:41 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:57:41 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:32782 with 1295.4 MB RAM
13/07/27 23:57:41 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:57:41 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:57:41 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60959
13/07/27 23:57:41 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:60959
13/07/27 23:57:41 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:57:41 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-27fa9645-84db-45ec-8771-4fb0ef957ada
13/07/27 23:57:41 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:57:41 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:51360
13/07/27 23:57:41 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:57:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:57:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:57:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:57:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:57:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:57:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:57:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:57:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:57:41 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:57:41 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1000").cache()
13/07/27 23:57:42 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/27 23:57:42 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:57:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:57:43 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:57:43 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:57:43 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:57:43 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:57:43 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:57:43 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:57:43 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:57:43 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:57:43 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:57:44 INFO local.LocalTaskSetManager: Size of task 0 is 1495 bytes
13/07/27 23:57:44 INFO local.LocalScheduler: Running 0
13/07/27 23:57:44 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:57:44 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:57:44 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1000' for reading
13/07/27 23:57:44 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1000' for reading at position '0'
13/07/27 23:57:44 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58415, maxMem=1358297825
13/07/27 23:57:44 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/27 23:57:44 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:32782 (size: 1580.2 KB, free: 1293.8 MB)
13/07/27 23:57:44 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:57:44 INFO local.LocalScheduler: Finished 0
13/07/27 23:57:44 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:57:44 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:57:44 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.506 s
13/07/27 23:57:44 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.552201348 s
res0: Long = 1000

scala> 13/07/27 23:57:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:57:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:57:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:57:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:57:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:57:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:57:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:57:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:57:47 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:57:47 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:44766
Creating SparkContext...
13/07/27 23:57:56 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:57:56 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:57:56 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:57:56 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235756-0723
13/07/27 23:57:56 INFO network.ConnectionManager: Bound socket to port 38802 with id = ConnectionManagerId(tachyon-ec2-0,38802)
13/07/27 23:57:56 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:57:56 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:38802 with 1295.4 MB RAM
13/07/27 23:57:56 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:57:56 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:57:56 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38837
13/07/27 23:57:56 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:38837
13/07/27 23:57:56 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:57:56 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-5a9237a0-ae11-4e5e-8474-225387d5edcf
13/07/27 23:57:56 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:57:56 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37631
13/07/27 23:57:56 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:57:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:57:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:57:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:57:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:57:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:57:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:57:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:57:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:57:56 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:57:56 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.10000").cache()
13/07/27 23:57:58 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/27 23:57:58 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:57:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:57:58 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:57:59 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:57:59 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:57:59 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:57:59 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:57:59 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:57:59 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:57:59 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:57:59 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:57:59 INFO local.LocalTaskSetManager: Size of task 0 is 1496 bytes
13/07/27 23:57:59 INFO local.LocalScheduler: Running 0
13/07/27 23:57:59 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:57:59 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:57:59 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.10000' for reading
13/07/27 23:57:59 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.10000' for reading at position '0'
13/07/27 23:58:00 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58415, maxMem=1358297825
13/07/27 23:58:00 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/27 23:58:00 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:38802 (size: 25.0 MB, free: 1270.4 MB)
13/07/27 23:58:00 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:58:00 INFO local.LocalScheduler: Finished 0
13/07/27 23:58:00 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:58:00 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:58:00 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.319 s
13/07/27 23:58:00 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.364418937 s
res0: Long = 10000

scala> 13/07/27 23:58:00 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:58:00 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:58:00 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:58:00 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:58:00 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:58:00 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:58:00 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:58:00 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:58:03 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:58:03 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37625
Creating SparkContext...
13/07/27 23:58:12 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:58:12 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:58:12 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:58:12 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235812-ef14
13/07/27 23:58:12 INFO network.ConnectionManager: Bound socket to port 52941 with id = ConnectionManagerId(tachyon-ec2-0,52941)
13/07/27 23:58:12 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:58:12 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:52941 with 1295.4 MB RAM
13/07/27 23:58:12 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:58:12 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:58:12 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50308
13/07/27 23:58:12 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:50308
13/07/27 23:58:12 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:58:12 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-49003db2-9301-4889-bc5f-f2b6cf289458
13/07/27 23:58:12 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:58:12 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:57743
13/07/27 23:58:12 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:58:12 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:58:12 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:58:12 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:58:12 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:58:12 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:58:12 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:58:12 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:58:12 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:58:12 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:58:12 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100000").cache()
13/07/27 23:58:14 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/27 23:58:14 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:58:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:58:14 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:58:15 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:58:15 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:58:15 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:58:15 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:58:15 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:58:15 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:58:15 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:58:15 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:58:15 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/27 23:58:15 INFO local.LocalScheduler: Running 0
13/07/27 23:58:15 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:58:15 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:58:15 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100000' for reading
13/07/27 23:58:15 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100000' for reading at position '0'
13/07/27 23:58:22 INFO storage.MemoryStore: ensureFreeSpace(261997239) called with curMem=58415, maxMem=1358297825
13/07/27 23:58:22 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 249.9 MB, free 1045.5 MB)
13/07/27 23:58:22 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:52941 (size: 249.9 MB, free: 1045.5 MB)
13/07/27 23:58:22 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:58:22 INFO local.LocalScheduler: Finished 0
13/07/27 23:58:22 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:58:22 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:58:22 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 7.026 s
13/07/27 23:58:22 INFO spark.SparkContext: Job finished: count at <console>:15, took 7.072239442 s
res0: Long = 100002

scala> 13/07/27 23:58:22 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:58:22 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:58:22 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:58:22 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:58:22 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:58:22 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:58:22 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:58:22 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:58:24 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:58:25 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:39191
Creating SparkContext...
13/07/27 23:58:34 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:58:34 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:58:34 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:58:34 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235834-070b
13/07/27 23:58:34 INFO network.ConnectionManager: Bound socket to port 35786 with id = ConnectionManagerId(tachyon-ec2-0,35786)
13/07/27 23:58:34 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:58:34 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:35786 with 1295.4 MB RAM
13/07/27 23:58:34 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:58:34 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:58:34 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38979
13/07/27 23:58:34 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:38979
13/07/27 23:58:34 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:58:34 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-a570a2e3-d1f6-47fc-a0bd-5ec3f65c0fe0
13/07/27 23:58:34 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:58:34 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:35509
13/07/27 23:58:34 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:58:34 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:58:34 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:58:34 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:58:34 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:58:34 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:58:34 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:58:34 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:58:34 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:58:34 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:58:34 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.500000").cache()
13/07/27 23:58:35 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/27 23:58:35 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:58:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:58:36 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:58:36 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:58:36 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:58:37 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:58:37 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:58:37 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:58:37 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:58:37 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:58:37 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:58:37 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/27 23:58:37 INFO local.LocalScheduler: Running 0
13/07/27 23:58:37 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:58:37 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:58:37 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.500000' for reading
13/07/27 23:58:37 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.500000' for reading at position '0'
13/07/27 23:59:10 INFO storage.MemoryStore: ensureFreeSpace(1288783830) called with curMem=58415, maxMem=1358297825
13/07/27 23:59:10 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1229.1 MB, free 66.2 MB)
13/07/27 23:59:10 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:35786 (size: 1229.1 MB, free: 66.3 MB)
13/07/27 23:59:10 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:59:10 INFO local.LocalScheduler: Finished 0
13/07/27 23:59:10 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:59:10 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:59:10 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 33.306 s
13/07/27 23:59:10 INFO spark.SparkContext: Job finished: count at <console>:15, took 33.351406344 s
res0: Long = 500094

scala> 13/07/27 23:59:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:59:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:59:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:59:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:59:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:59:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:59:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:59:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 4

spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:59:13 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:59:13 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:48993
Creating SparkContext...
13/07/27 23:59:22 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:59:22 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:59:22 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:59:22 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235922-9bf3
13/07/27 23:59:22 INFO network.ConnectionManager: Bound socket to port 45455 with id = ConnectionManagerId(tachyon-ec2-0,45455)
13/07/27 23:59:22 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:59:22 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:45455 with 1295.4 MB RAM
13/07/27 23:59:22 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:59:22 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:59:22 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:43905
13/07/27 23:59:22 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:43905
13/07/27 23:59:22 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:59:22 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-5b9eb61a-7b6d-467c-bc24-304a7263b03b
13/07/27 23:59:22 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:59:22 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:40497
13/07/27 23:59:22 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:59:22 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:59:22 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:59:22 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:59:22 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:59:22 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:59:22 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:59:22 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:59:22 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:59:22 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:59:22 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1").cache()
13/07/27 23:59:24 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:59:24 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:59:24 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:59:24 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:59:25 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:59:25 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:59:25 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:59:25 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:59:25 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:59:25 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:59:25 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:59:25 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:59:25 INFO local.LocalTaskSetManager: Size of task 0 is 1492 bytes
13/07/27 23:59:25 INFO local.LocalScheduler: Running 0
13/07/27 23:59:25 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:59:25 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:59:25 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1' for reading
13/07/27 23:59:25 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1' for reading at position '0'
13/07/27 23:59:25 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58407, maxMem=1358297825
13/07/27 23:59:25 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/27 23:59:25 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:45455 (size: 1192.0 B, free: 1295.4 MB)
13/07/27 23:59:25 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:59:25 INFO local.LocalScheduler: Finished 0
13/07/27 23:59:25 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:59:25 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:59:25 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.287 s
13/07/27 23:59:25 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.332089453 s
res0: Long = 1

scala> 13/07/27 23:59:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:59:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:59:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:59:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:59:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:59:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:59:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:59:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:59:28 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:59:28 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:54752
Creating SparkContext...
13/07/27 23:59:37 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:59:37 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:59:37 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:59:37 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235937-5ce1
13/07/27 23:59:37 INFO network.ConnectionManager: Bound socket to port 52929 with id = ConnectionManagerId(tachyon-ec2-0,52929)
13/07/27 23:59:37 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:59:37 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:52929 with 1295.4 MB RAM
13/07/27 23:59:37 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:59:37 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:59:37 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:33818
13/07/27 23:59:37 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:33818
13/07/27 23:59:37 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:59:37 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-01d245ca-2d20-4ce3-b396-ea05773367c7
13/07/27 23:59:37 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:59:37 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37544
13/07/27 23:59:37 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:59:37 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:59:37 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:59:37 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:59:37 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:59:37 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:59:37 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:59:37 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:59:37 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:59:37 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:59:37 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100").cache()
13/07/27 23:59:39 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:59:39 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:59:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:59:39 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:59:40 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:59:40 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:59:40 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:59:40 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:59:40 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:59:40 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:59:40 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:59:40 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:59:40 INFO local.LocalTaskSetManager: Size of task 0 is 1494 bytes
13/07/27 23:59:40 INFO local.LocalScheduler: Running 0
13/07/27 23:59:40 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:59:40 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:59:40 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100' for reading
13/07/27 23:59:40 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100' for reading at position '0'
13/07/27 23:59:40 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58407, maxMem=1358297825
13/07/27 23:59:40 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/27 23:59:40 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:52929 (size: 113.4 KB, free: 1295.3 MB)
13/07/27 23:59:40 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:59:40 INFO local.LocalScheduler: Finished 0
13/07/27 23:59:40 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:59:40 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:59:40 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.348 s
13/07/27 23:59:40 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.39343275 s
res0: Long = 100

scala> 13/07/27 23:59:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:59:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:59:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:59:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:59:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:59:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:59:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:59:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:59:43 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:59:43 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60388
Creating SparkContext...
13/07/27 23:59:52 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:59:52 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:59:52 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:59:52 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727235952-f68e
13/07/27 23:59:52 INFO network.ConnectionManager: Bound socket to port 57632 with id = ConnectionManagerId(tachyon-ec2-0,57632)
13/07/27 23:59:52 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:59:52 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:57632 with 1295.4 MB RAM
13/07/27 23:59:52 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:59:52 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:59:52 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:44305
13/07/27 23:59:52 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:44305
13/07/27 23:59:52 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:59:52 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-4e29348e-da13-4171-be47-1b3e246af14d
13/07/27 23:59:52 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:59:52 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:46894
13/07/27 23:59:52 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:59:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:59:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:59:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:59:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:59:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:59:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:59:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:59:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:59:52 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:59:52 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1000").cache()
13/07/27 23:59:54 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/27 23:59:54 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:59:54 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:59:54 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:59:55 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:59:55 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:59:55 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:59:55 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:59:55 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:59:55 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:59:55 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:59:55 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:59:55 INFO local.LocalTaskSetManager: Size of task 0 is 1495 bytes
13/07/27 23:59:55 INFO local.LocalScheduler: Running 0
13/07/27 23:59:55 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:59:55 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:59:55 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1000' for reading
13/07/27 23:59:55 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1000' for reading at position '0'
13/07/27 23:59:55 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58415, maxMem=1358297825
13/07/27 23:59:55 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/27 23:59:55 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:57632 (size: 1580.2 KB, free: 1293.8 MB)
13/07/27 23:59:55 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:59:55 INFO local.LocalScheduler: Finished 0
13/07/27 23:59:55 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:59:55 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:59:55 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.624 s
13/07/27 23:59:55 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.670343611 s
res0: Long = 1000

scala> 13/07/27 23:59:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:59:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:59:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:59:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:59:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:59:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:59:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:59:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:59:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:59:58 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:58183
Creating SparkContext...
13/07/28 00:00:07 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:00:08 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:00:08 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:00:08 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000008-c1b0
13/07/28 00:00:08 INFO network.ConnectionManager: Bound socket to port 34029 with id = ConnectionManagerId(tachyon-ec2-0,34029)
13/07/28 00:00:08 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:00:08 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:34029 with 1295.4 MB RAM
13/07/28 00:00:08 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:00:08 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:00:08 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59129
13/07/28 00:00:08 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:59129
13/07/28 00:00:08 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:00:08 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-74acc654-1713-4f25-adcd-7085da0fdbf9
13/07/28 00:00:08 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:00:08 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:41820
13/07/28 00:00:08 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:00:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:00:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:00:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:00:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:00:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:00:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:00:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:00:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:00:08 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:00:08 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.10000").cache()
13/07/28 00:00:09 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:00:09 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:00:10 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:00:10 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:00:10 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:00:10 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:00:10 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:00:10 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:00:10 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:00:10 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:00:10 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:00:10 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:00:10 INFO local.LocalTaskSetManager: Size of task 0 is 1496 bytes
13/07/28 00:00:10 INFO local.LocalScheduler: Running 0
13/07/28 00:00:10 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:00:10 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:00:10 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.10000' for reading
13/07/28 00:00:11 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.10000' for reading at position '0'
13/07/28 00:00:12 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58415, maxMem=1358297825
13/07/28 00:00:12 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/28 00:00:12 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:34029 (size: 25.0 MB, free: 1270.4 MB)
13/07/28 00:00:12 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:00:12 INFO local.LocalScheduler: Finished 0
13/07/28 00:00:12 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:00:12 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:00:12 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.320 s
13/07/28 00:00:12 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.365123877 s
res0: Long = 10000

scala> 13/07/28 00:00:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:00:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:00:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:00:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:00:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:00:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:00:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:00:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:00:14 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:00:14 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:48427
Creating SparkContext...
13/07/28 00:00:23 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:00:24 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:00:24 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:00:24 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000024-3e6d
13/07/28 00:00:24 INFO network.ConnectionManager: Bound socket to port 49950 with id = ConnectionManagerId(tachyon-ec2-0,49950)
13/07/28 00:00:24 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:00:24 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:49950 with 1295.4 MB RAM
13/07/28 00:00:24 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:00:24 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:00:24 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:56356
13/07/28 00:00:24 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:56356
13/07/28 00:00:24 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:00:24 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-76ca8526-1245-4312-8437-18cd330dd26a
13/07/28 00:00:24 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:00:24 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53919
13/07/28 00:00:24 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:00:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:00:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:00:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:00:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:00:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:00:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:00:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:00:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:00:24 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:00:24 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100000").cache()
13/07/28 00:00:25 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:00:25 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:00:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:00:25 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:00:26 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:00:26 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:00:26 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:00:26 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:00:26 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:00:26 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:00:26 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:00:26 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:00:26 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/28 00:00:26 INFO local.LocalScheduler: Running 0
13/07/28 00:00:26 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:00:26 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:00:26 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100000' for reading
13/07/28 00:00:27 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100000' for reading at position '0'
13/07/28 00:00:35 INFO storage.MemoryStore: ensureFreeSpace(261997239) called with curMem=58415, maxMem=1358297825
13/07/28 00:00:35 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 249.9 MB, free 1045.5 MB)
13/07/28 00:00:35 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:49950 (size: 249.9 MB, free: 1045.5 MB)
13/07/28 00:00:35 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:00:35 INFO local.LocalScheduler: Finished 0
13/07/28 00:00:35 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:00:35 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:00:35 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 8.686 s
13/07/28 00:00:35 INFO spark.SparkContext: Job finished: count at <console>:15, took 8.733578723 s
res0: Long = 100002

scala> 13/07/28 00:00:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:00:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:00:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:00:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:00:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:00:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:00:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:00:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:00:38 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:00:38 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37366
Creating SparkContext...
13/07/28 00:00:47 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:00:47 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:00:47 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:00:47 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000047-57bf
13/07/28 00:00:47 INFO network.ConnectionManager: Bound socket to port 54170 with id = ConnectionManagerId(tachyon-ec2-0,54170)
13/07/28 00:00:47 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:00:47 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:54170 with 1295.4 MB RAM
13/07/28 00:00:47 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:00:47 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:00:47 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:57657
13/07/28 00:00:47 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:57657
13/07/28 00:00:47 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:00:47 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-70d6f6b1-74c4-4c48-95fd-24a42ef56850
13/07/28 00:00:47 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:00:47 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:33473
13/07/28 00:00:47 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:00:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:00:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:00:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:00:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:00:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:00:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:00:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:00:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:00:47 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:00:47 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.500000").cache()
13/07/28 00:00:48 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:00:48 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:00:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:00:49 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:00:50 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:00:50 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:00:50 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:00:50 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:00:50 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:00:50 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:00:50 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:00:50 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:00:50 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/28 00:00:50 INFO local.LocalScheduler: Running 0
13/07/28 00:00:50 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:00:50 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:00:50 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.500000' for reading
13/07/28 00:00:50 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.500000' for reading at position '0'
13/07/28 00:01:24 INFO storage.MemoryStore: ensureFreeSpace(1288783830) called with curMem=58415, maxMem=1358297825
13/07/28 00:01:24 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1229.1 MB, free 66.2 MB)
13/07/28 00:01:24 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:54170 (size: 1229.1 MB, free: 66.3 MB)
13/07/28 00:01:24 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:01:24 INFO local.LocalScheduler: Finished 0
13/07/28 00:01:24 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:01:24 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:01:24 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 34.487 s
13/07/28 00:01:24 INFO spark.SparkContext: Job finished: count at <console>:15, took 34.531852886 s
res0: Long = 500094

scala> 13/07/28 00:01:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:01:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:01:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:01:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:01:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:01:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:01:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:01:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 5

spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:01:27 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:01:27 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:46762
Creating SparkContext...
13/07/28 00:01:36 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:01:36 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:01:36 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:01:36 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000136-be0a
13/07/28 00:01:36 INFO network.ConnectionManager: Bound socket to port 42174 with id = ConnectionManagerId(tachyon-ec2-0,42174)
13/07/28 00:01:36 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:01:36 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:42174 with 1295.4 MB RAM
13/07/28 00:01:36 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:01:36 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:01:36 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:44801
13/07/28 00:01:36 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:44801
13/07/28 00:01:36 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:01:36 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-4ec5dbf8-a555-4f58-a47a-7e7af337166d
13/07/28 00:01:36 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:01:36 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60849
13/07/28 00:01:36 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:01:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:01:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:01:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:01:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:01:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:01:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:01:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:01:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:01:36 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:01:36 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1").cache()
13/07/28 00:01:38 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/28 00:01:38 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:01:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:01:38 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:01:39 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:01:39 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:01:39 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:01:39 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:01:39 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:01:39 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:01:39 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:01:39 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:01:39 INFO local.LocalTaskSetManager: Size of task 0 is 1492 bytes
13/07/28 00:01:39 INFO local.LocalScheduler: Running 0
13/07/28 00:01:39 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:01:39 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:01:39 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1' for reading
13/07/28 00:01:39 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1' for reading at position '0'
13/07/28 00:01:39 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58407, maxMem=1358297825
13/07/28 00:01:39 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/28 00:01:39 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:42174 (size: 1192.0 B, free: 1295.4 MB)
13/07/28 00:01:39 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:01:39 INFO local.LocalScheduler: Finished 0
13/07/28 00:01:39 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:01:39 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:01:39 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.317 s
13/07/28 00:01:39 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.362128874 s
res0: Long = 1

scala> 13/07/28 00:01:39 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:01:39 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:01:39 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:01:39 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:01:39 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:01:39 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:01:39 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:01:39 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:01:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:01:42 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:45832
Creating SparkContext...
13/07/28 00:01:51 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:01:51 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:01:51 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:01:51 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000151-6fdd
13/07/28 00:01:51 INFO network.ConnectionManager: Bound socket to port 60546 with id = ConnectionManagerId(tachyon-ec2-0,60546)
13/07/28 00:01:51 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:01:51 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:60546 with 1295.4 MB RAM
13/07/28 00:01:51 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:01:51 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:01:51 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38704
13/07/28 00:01:51 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:38704
13/07/28 00:01:51 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:01:51 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-e489fb90-0ef5-43e7-94cd-b832eea93f6c
13/07/28 00:01:51 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:01:51 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37140
13/07/28 00:01:51 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:01:51 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:01:51 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:01:51 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:01:51 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:01:51 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:01:51 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:01:51 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:01:51 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:01:51 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:01:51 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100").cache()
13/07/28 00:01:53 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/28 00:01:53 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:01:53 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:01:53 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:01:54 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:01:54 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:01:54 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:01:54 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:01:54 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:01:54 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:01:54 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:01:54 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:01:54 INFO local.LocalTaskSetManager: Size of task 0 is 1494 bytes
13/07/28 00:01:54 INFO local.LocalScheduler: Running 0
13/07/28 00:01:54 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:01:54 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:01:54 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100' for reading
13/07/28 00:01:54 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100' for reading at position '0'
13/07/28 00:01:54 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58407, maxMem=1358297825
13/07/28 00:01:54 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/28 00:01:54 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:60546 (size: 113.4 KB, free: 1295.3 MB)
13/07/28 00:01:54 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:01:54 INFO local.LocalScheduler: Finished 0
13/07/28 00:01:54 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:01:54 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:01:54 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.351 s
13/07/28 00:01:54 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.396967164 s
res0: Long = 100

scala> 13/07/28 00:01:54 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:01:54 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:01:54 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:01:54 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:01:54 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:01:54 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:01:54 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:01:54 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:01:57 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:01:57 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:57742
Creating SparkContext...
13/07/28 00:02:06 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:02:06 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:02:06 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:02:06 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000206-b565
13/07/28 00:02:06 INFO network.ConnectionManager: Bound socket to port 43833 with id = ConnectionManagerId(tachyon-ec2-0,43833)
13/07/28 00:02:06 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:02:06 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:43833 with 1295.4 MB RAM
13/07/28 00:02:06 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:02:06 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:02:06 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60021
13/07/28 00:02:06 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:60021
13/07/28 00:02:06 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:02:06 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-b0897df8-8652-4a9b-a37e-e326f97e0d94
13/07/28 00:02:06 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:02:06 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59883
13/07/28 00:02:06 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:02:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:02:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:02:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:02:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:02:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:02:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:02:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:02:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:02:06 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:02:06 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1000").cache()
13/07/28 00:02:08 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:02:08 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:02:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:02:08 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:02:09 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:02:09 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:02:09 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:02:09 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:02:09 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:02:09 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:02:09 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:02:09 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:02:09 INFO local.LocalTaskSetManager: Size of task 0 is 1495 bytes
13/07/28 00:02:09 INFO local.LocalScheduler: Running 0
13/07/28 00:02:09 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:02:09 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:02:09 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1000' for reading
13/07/28 00:02:09 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1000' for reading at position '0'
13/07/28 00:02:10 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58415, maxMem=1358297825
13/07/28 00:02:10 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/28 00:02:10 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:43833 (size: 1580.2 KB, free: 1293.8 MB)
13/07/28 00:02:10 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:02:10 INFO local.LocalScheduler: Finished 0
13/07/28 00:02:10 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:02:10 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:02:10 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.630 s
13/07/28 00:02:10 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.675511591 s
res0: Long = 1000

scala> 13/07/28 00:02:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:02:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:02:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:02:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:02:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:02:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:02:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:02:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:02:12 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:02:12 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:58871
Creating SparkContext...
13/07/28 00:02:21 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:02:22 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:02:22 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:02:22 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000222-9e52
13/07/28 00:02:22 INFO network.ConnectionManager: Bound socket to port 35387 with id = ConnectionManagerId(tachyon-ec2-0,35387)
13/07/28 00:02:22 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:02:22 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:35387 with 1295.4 MB RAM
13/07/28 00:02:22 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:02:22 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:02:22 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60582
13/07/28 00:02:22 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:60582
13/07/28 00:02:22 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:02:22 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-f85488de-e01e-47a8-aa0d-711709d6cdb5
13/07/28 00:02:22 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:02:22 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:43359
13/07/28 00:02:22 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:02:22 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:02:22 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:02:22 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:02:22 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:02:22 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:02:22 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:02:22 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:02:22 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:02:22 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:02:22 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.10000").cache()
13/07/28 00:02:23 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:02:23 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:02:23 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:02:23 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:02:24 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:02:24 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:02:24 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:02:24 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:02:24 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:02:24 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:02:24 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:02:24 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:02:24 INFO local.LocalTaskSetManager: Size of task 0 is 1496 bytes
13/07/28 00:02:24 INFO local.LocalScheduler: Running 0
13/07/28 00:02:24 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:02:24 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:02:24 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.10000' for reading
13/07/28 00:02:24 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.10000' for reading at position '0'
13/07/28 00:02:26 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58415, maxMem=1358297825
13/07/28 00:02:26 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/28 00:02:26 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:35387 (size: 25.0 MB, free: 1270.4 MB)
13/07/28 00:02:26 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:02:26 INFO local.LocalScheduler: Finished 0
13/07/28 00:02:26 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:02:26 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:02:26 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.314 s
13/07/28 00:02:26 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.35890539 s
res0: Long = 10000

scala> 13/07/28 00:02:26 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:02:26 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:02:26 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:02:26 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:02:26 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:02:26 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:02:26 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:02:26 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:02:28 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:02:28 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:52229
Creating SparkContext...
13/07/28 00:02:37 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:02:38 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:02:38 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:02:38 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000238-9e76
13/07/28 00:02:38 INFO network.ConnectionManager: Bound socket to port 35202 with id = ConnectionManagerId(tachyon-ec2-0,35202)
13/07/28 00:02:38 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:02:38 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:35202 with 1295.4 MB RAM
13/07/28 00:02:38 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:02:38 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:02:38 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:48629
13/07/28 00:02:38 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:48629
13/07/28 00:02:38 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:02:38 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-26a1baa7-f386-4e8c-a1c2-dcd2f36b88cc
13/07/28 00:02:38 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:02:38 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:46303
13/07/28 00:02:38 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:02:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:02:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:02:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:02:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:02:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:02:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:02:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:02:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:02:38 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:02:38 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100000").cache()
13/07/28 00:02:39 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:02:39 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:02:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:02:39 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:02:40 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:02:40 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:02:40 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:02:40 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:02:40 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:02:40 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:02:40 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:02:40 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:02:40 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/28 00:02:40 INFO local.LocalScheduler: Running 0
13/07/28 00:02:40 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:02:40 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:02:40 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100000' for reading
13/07/28 00:02:41 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100000' for reading at position '0'
13/07/28 00:02:47 INFO storage.MemoryStore: ensureFreeSpace(261997239) called with curMem=58415, maxMem=1358297825
13/07/28 00:02:47 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 249.9 MB, free 1045.5 MB)
13/07/28 00:02:47 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:35202 (size: 249.9 MB, free: 1045.5 MB)
13/07/28 00:02:47 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:02:47 INFO local.LocalScheduler: Finished 0
13/07/28 00:02:47 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:02:47 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:02:47 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 7.248 s
13/07/28 00:02:47 INFO spark.SparkContext: Job finished: count at <console>:15, took 7.293049932 s
res0: Long = 100002

scala> 13/07/28 00:02:48 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:02:48 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:02:48 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:02:48 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:02:48 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:02:48 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:02:48 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:02:48 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:02:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:02:50 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:39538
Creating SparkContext...
13/07/28 00:02:59 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:03:00 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:03:00 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:03:00 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000300-5400
13/07/28 00:03:00 INFO network.ConnectionManager: Bound socket to port 38285 with id = ConnectionManagerId(tachyon-ec2-0,38285)
13/07/28 00:03:00 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:03:00 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:38285 with 1295.4 MB RAM
13/07/28 00:03:00 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:03:00 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:03:00 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37631
13/07/28 00:03:00 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:37631
13/07/28 00:03:00 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:03:00 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-7c8b12e0-7bc2-4495-a57e-d513c8f338cf
13/07/28 00:03:00 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:03:00 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:32998
13/07/28 00:03:00 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:03:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:03:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:03:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:03:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:03:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:03:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:03:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:03:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:03:00 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:03:00 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.500000").cache()
13/07/28 00:03:01 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:03:01 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:03:01 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:03:01 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:03:02 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:03:02 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:03:02 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:03:02 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:03:02 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:03:02 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:03:02 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:03:02 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:03:02 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/28 00:03:02 INFO local.LocalScheduler: Running 0
13/07/28 00:03:02 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:03:02 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:03:02 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.500000' for reading
13/07/28 00:03:03 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.500000' for reading at position '0'
13/07/28 00:03:38 INFO storage.MemoryStore: ensureFreeSpace(1288783830) called with curMem=58415, maxMem=1358297825
13/07/28 00:03:38 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1229.1 MB, free 66.2 MB)
13/07/28 00:03:38 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:38285 (size: 1229.1 MB, free: 66.3 MB)
13/07/28 00:03:38 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:03:38 INFO local.LocalScheduler: Finished 0
13/07/28 00:03:38 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:03:38 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:03:38 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 35.514 s
13/07/28 00:03:38 INFO spark.SparkContext: Job finished: count at <console>:15, took 35.560424512 s
res0: Long = 500094

scala> 13/07/28 00:03:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:03:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:03:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:03:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:03:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:03:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:03:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:03:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 6

spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:03:41 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:03:41 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38121
Creating SparkContext...
13/07/28 00:03:50 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:03:50 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:03:50 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:03:50 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000350-8798
13/07/28 00:03:50 INFO network.ConnectionManager: Bound socket to port 59477 with id = ConnectionManagerId(tachyon-ec2-0,59477)
13/07/28 00:03:50 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:03:50 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:59477 with 1295.4 MB RAM
13/07/28 00:03:50 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:03:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:03:50 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:32904
13/07/28 00:03:50 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:32904
13/07/28 00:03:50 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:03:50 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-7e19569e-c863-4d9f-bb35-d287931ce154
13/07/28 00:03:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:03:50 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:57655
13/07/28 00:03:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:03:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:03:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:03:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:03:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:03:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:03:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:03:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:03:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:03:50 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:03:50 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1").cache()
13/07/28 00:03:52 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/28 00:03:52 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:03:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:03:52 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:03:53 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:03:53 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:03:53 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:03:53 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:03:53 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:03:53 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:03:53 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:03:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:03:53 INFO local.LocalTaskSetManager: Size of task 0 is 1492 bytes
13/07/28 00:03:53 INFO local.LocalScheduler: Running 0
13/07/28 00:03:53 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:03:53 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:03:53 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1' for reading
13/07/28 00:03:53 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1' for reading at position '0'
13/07/28 00:03:53 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58407, maxMem=1358297825
13/07/28 00:03:53 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/28 00:03:53 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:59477 (size: 1192.0 B, free: 1295.4 MB)
13/07/28 00:03:53 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:03:53 INFO local.LocalScheduler: Finished 0
13/07/28 00:03:53 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:03:53 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:03:53 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.453 s
13/07/28 00:03:53 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.498615441 s
res0: Long = 1

scala> 13/07/28 00:03:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:03:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:03:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:03:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:03:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:03:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:03:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:03:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:03:56 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:03:56 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:46719
Creating SparkContext...
13/07/28 00:04:05 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:04:05 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:04:05 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:04:05 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000405-dacb
13/07/28 00:04:05 INFO network.ConnectionManager: Bound socket to port 34227 with id = ConnectionManagerId(tachyon-ec2-0,34227)
13/07/28 00:04:05 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:04:05 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:34227 with 1295.4 MB RAM
13/07/28 00:04:05 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:04:05 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:04:05 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:33532
13/07/28 00:04:05 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:33532
13/07/28 00:04:05 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:04:05 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-8f073d87-9570-4a49-9d71-55c4b08340a0
13/07/28 00:04:05 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:04:05 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38188
13/07/28 00:04:05 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:04:05 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:04:05 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:04:05 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:04:05 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:04:05 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:04:05 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:04:05 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:04:05 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:04:05 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:04:05 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100").cache()
13/07/28 00:04:07 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/28 00:04:07 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:04:07 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:04:07 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:04:08 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:04:08 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:04:08 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:04:08 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:04:08 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:04:08 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:04:08 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:04:08 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:04:08 INFO local.LocalTaskSetManager: Size of task 0 is 1494 bytes
13/07/28 00:04:08 INFO local.LocalScheduler: Running 0
13/07/28 00:04:08 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:04:08 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:04:08 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100' for reading
13/07/28 00:04:08 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100' for reading at position '0'
13/07/28 00:04:08 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58407, maxMem=1358297825
13/07/28 00:04:08 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/28 00:04:08 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:34227 (size: 113.4 KB, free: 1295.3 MB)
13/07/28 00:04:08 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:04:08 INFO local.LocalScheduler: Finished 0
13/07/28 00:04:08 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:04:08 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:04:08 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.401 s
13/07/28 00:04:08 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.44608987 s
res0: Long = 100

scala> 13/07/28 00:04:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:04:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:04:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:04:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:04:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:04:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:04:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:04:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:04:11 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:04:11 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:44872
Creating SparkContext...
13/07/28 00:04:20 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:04:20 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:04:20 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:04:20 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000420-e0c0
13/07/28 00:04:20 INFO network.ConnectionManager: Bound socket to port 50284 with id = ConnectionManagerId(tachyon-ec2-0,50284)
13/07/28 00:04:20 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:04:20 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:50284 with 1295.4 MB RAM
13/07/28 00:04:20 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:04:20 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:04:20 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:32942
13/07/28 00:04:20 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:32942
13/07/28 00:04:20 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:04:20 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-5a9d423d-fc13-43b4-9837-84eb8ef3c224
13/07/28 00:04:20 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:04:20 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:45927
13/07/28 00:04:20 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:04:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:04:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:04:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:04:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:04:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:04:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:04:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:04:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:04:20 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:04:20 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1000").cache()
13/07/28 00:04:22 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:04:22 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:04:22 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:04:22 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:04:23 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:04:23 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:04:23 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:04:23 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:04:23 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:04:23 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:04:23 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:04:23 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:04:23 INFO local.LocalTaskSetManager: Size of task 0 is 1495 bytes
13/07/28 00:04:23 INFO local.LocalScheduler: Running 0
13/07/28 00:04:23 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:04:23 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:04:23 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1000' for reading
13/07/28 00:04:23 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1000' for reading at position '0'
13/07/28 00:04:23 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58415, maxMem=1358297825
13/07/28 00:04:23 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/28 00:04:23 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:50284 (size: 1580.2 KB, free: 1293.8 MB)
13/07/28 00:04:23 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:04:23 INFO local.LocalScheduler: Finished 0
13/07/28 00:04:23 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:04:23 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:04:23 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.495 s
13/07/28 00:04:23 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.540989622 s
res0: Long = 1000

scala> 13/07/28 00:04:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:04:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:04:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:04:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:04:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:04:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:04:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:04:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:04:26 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:04:26 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:47306
Creating SparkContext...
13/07/28 00:04:35 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:04:36 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:04:36 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:04:36 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000436-5b82
13/07/28 00:04:36 INFO network.ConnectionManager: Bound socket to port 55033 with id = ConnectionManagerId(tachyon-ec2-0,55033)
13/07/28 00:04:36 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:04:36 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:55033 with 1295.4 MB RAM
13/07/28 00:04:36 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:04:36 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:04:36 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55877
13/07/28 00:04:36 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:55877
13/07/28 00:04:36 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:04:36 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-1463ee46-b0fc-4020-b693-a641e65cd579
13/07/28 00:04:36 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:04:36 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:33343
13/07/28 00:04:36 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:04:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:04:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:04:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:04:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:04:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:04:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:04:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:04:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:04:36 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:04:36 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.10000").cache()
13/07/28 00:04:37 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:04:37 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:04:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:04:37 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:04:38 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:04:38 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:04:38 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:04:38 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:04:38 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:04:38 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:04:38 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:04:38 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:04:38 INFO local.LocalTaskSetManager: Size of task 0 is 1496 bytes
13/07/28 00:04:38 INFO local.LocalScheduler: Running 0
13/07/28 00:04:38 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:04:38 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:04:38 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.10000' for reading
13/07/28 00:04:38 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.10000' for reading at position '0'
13/07/28 00:04:40 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58415, maxMem=1358297825
13/07/28 00:04:40 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/28 00:04:40 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:55033 (size: 25.0 MB, free: 1270.4 MB)
13/07/28 00:04:40 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:04:40 INFO local.LocalScheduler: Finished 0
13/07/28 00:04:40 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:04:40 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:04:40 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.493 s
13/07/28 00:04:40 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.538041869 s
res0: Long = 10000

scala> 13/07/28 00:04:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:04:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:04:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:04:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:04:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:04:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:04:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:04:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:04:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:04:42 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:58429
Creating SparkContext...
13/07/28 00:04:51 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:04:52 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:04:52 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:04:52 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000452-e3f1
13/07/28 00:04:52 INFO network.ConnectionManager: Bound socket to port 51187 with id = ConnectionManagerId(tachyon-ec2-0,51187)
13/07/28 00:04:52 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:04:52 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:51187 with 1295.4 MB RAM
13/07/28 00:04:52 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:04:52 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:04:52 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59290
13/07/28 00:04:52 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:59290
13/07/28 00:04:52 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:04:52 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-e53ea073-dad7-4b70-b031-6b83bf5df87f
13/07/28 00:04:52 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:04:52 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:36170
13/07/28 00:04:52 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:04:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:04:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:04:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:04:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:04:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:04:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:04:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:04:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:04:52 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:04:52 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100000").cache()
13/07/28 00:04:53 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:04:53 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:04:54 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:04:54 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:04:54 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:04:54 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:04:54 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:04:54 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:04:54 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:04:54 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:04:54 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:04:54 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:04:54 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/28 00:04:54 INFO local.LocalScheduler: Running 0
13/07/28 00:04:55 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:04:55 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:04:55 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100000' for reading
13/07/28 00:04:55 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100000' for reading at position '0'
13/07/28 00:05:08 INFO storage.MemoryStore: ensureFreeSpace(261997239) called with curMem=58415, maxMem=1358297825
13/07/28 00:05:08 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 249.9 MB, free 1045.5 MB)
13/07/28 00:05:08 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:51187 (size: 249.9 MB, free: 1045.5 MB)
13/07/28 00:05:08 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:05:08 INFO local.LocalScheduler: Finished 0
13/07/28 00:05:08 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:05:08 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:05:08 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 13.349 s
13/07/28 00:05:08 INFO spark.SparkContext: Job finished: count at <console>:15, took 13.394298743 s
res0: Long = 100002

scala> 13/07/28 00:05:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:05:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:05:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:05:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:05:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:05:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:05:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:05:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:05:10 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:05:10 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37662
Creating SparkContext...
13/07/28 00:05:20 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:05:20 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:05:20 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:05:20 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000520-95ce
13/07/28 00:05:20 INFO network.ConnectionManager: Bound socket to port 42984 with id = ConnectionManagerId(tachyon-ec2-0,42984)
13/07/28 00:05:20 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:05:20 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:42984 with 1295.4 MB RAM
13/07/28 00:05:20 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:05:20 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:05:20 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:45080
13/07/28 00:05:20 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:45080
13/07/28 00:05:20 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:05:20 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-b15f184f-b0cf-45d3-9e4a-6f130d5000ff
13/07/28 00:05:20 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:05:20 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:35310
13/07/28 00:05:20 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:05:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:05:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:05:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:05:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:05:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:05:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:05:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:05:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:05:20 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:05:20 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.500000").cache()
13/07/28 00:05:21 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:05:21 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:05:22 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:05:22 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:05:22 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:05:22 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:05:22 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:05:22 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:05:22 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:05:22 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:05:22 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:05:22 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:05:23 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/28 00:05:23 INFO local.LocalScheduler: Running 0
13/07/28 00:05:23 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:05:23 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:05:23 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.500000' for reading
13/07/28 00:05:23 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.500000' for reading at position '0'
13/07/28 00:06:10 INFO storage.MemoryStore: ensureFreeSpace(1288783830) called with curMem=58415, maxMem=1358297825
13/07/28 00:06:10 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1229.1 MB, free 66.2 MB)
13/07/28 00:06:10 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:42984 (size: 1229.1 MB, free: 66.3 MB)
13/07/28 00:06:10 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:06:10 INFO local.LocalScheduler: Finished 0
13/07/28 00:06:10 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:06:10 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:06:10 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 47.612 s
13/07/28 00:06:10 INFO spark.SparkContext: Job finished: count at <console>:15, took 47.657769451 s
res0: Long = 500094

scala> 13/07/28 00:06:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:06:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:06:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:06:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:06:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:06:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:06:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:06:10 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 7

spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:06:13 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:06:13 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:40258
Creating SparkContext...
13/07/28 00:06:22 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:06:22 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:06:22 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:06:22 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000622-74f6
13/07/28 00:06:22 INFO network.ConnectionManager: Bound socket to port 33236 with id = ConnectionManagerId(tachyon-ec2-0,33236)
13/07/28 00:06:22 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:06:22 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:33236 with 1295.4 MB RAM
13/07/28 00:06:22 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:06:22 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:06:22 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50291
13/07/28 00:06:22 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:50291
13/07/28 00:06:22 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:06:22 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-573109f0-7eeb-4afc-b943-c16106bbc8cd
13/07/28 00:06:22 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:06:22 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:33610
13/07/28 00:06:23 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:06:23 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:06:23 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:06:23 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:06:23 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:06:23 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:06:23 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:06:23 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:06:23 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:06:23 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:06:23 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1").cache()
13/07/28 00:06:24 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/28 00:06:24 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:06:24 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:06:24 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:06:25 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:06:25 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:06:25 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:06:25 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:06:25 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:06:25 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:06:25 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:06:25 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:06:25 INFO local.LocalTaskSetManager: Size of task 0 is 1492 bytes
13/07/28 00:06:25 INFO local.LocalScheduler: Running 0
13/07/28 00:06:25 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:06:25 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:06:25 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1' for reading
13/07/28 00:06:25 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1' for reading at position '0'
13/07/28 00:06:25 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58407, maxMem=1358297825
13/07/28 00:06:25 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/28 00:06:25 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:33236 (size: 1192.0 B, free: 1295.4 MB)
13/07/28 00:06:25 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:06:25 INFO local.LocalScheduler: Finished 0
13/07/28 00:06:25 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:06:25 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:06:25 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.349 s
13/07/28 00:06:25 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.393449848 s
res0: Long = 1

scala> 13/07/28 00:06:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:06:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:06:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:06:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:06:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:06:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:06:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:06:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:06:28 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:06:28 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53904
Creating SparkContext...
13/07/28 00:06:37 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:06:37 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:06:37 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:06:37 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000637-54cf
13/07/28 00:06:37 INFO network.ConnectionManager: Bound socket to port 54227 with id = ConnectionManagerId(tachyon-ec2-0,54227)
13/07/28 00:06:37 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:06:37 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:54227 with 1295.4 MB RAM
13/07/28 00:06:37 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:06:38 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:06:38 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:57246
13/07/28 00:06:38 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:57246
13/07/28 00:06:38 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:06:38 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-42da438d-ee95-4144-8c5b-4e347705a98e
13/07/28 00:06:38 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:06:38 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53376
13/07/28 00:06:38 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:06:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:06:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:06:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:06:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:06:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:06:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:06:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:06:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:06:38 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:06:38 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100").cache()
13/07/28 00:06:39 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/28 00:06:39 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:06:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:06:39 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:06:40 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:06:40 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:06:40 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:06:40 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:06:40 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:06:40 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:06:40 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:06:40 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:06:40 INFO local.LocalTaskSetManager: Size of task 0 is 1494 bytes
13/07/28 00:06:40 INFO local.LocalScheduler: Running 0
13/07/28 00:06:40 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:06:40 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:06:40 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100' for reading
13/07/28 00:06:40 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100' for reading at position '0'
13/07/28 00:06:40 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58407, maxMem=1358297825
13/07/28 00:06:40 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/28 00:06:40 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:54227 (size: 113.4 KB, free: 1295.3 MB)
13/07/28 00:06:40 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:06:40 INFO local.LocalScheduler: Finished 0
13/07/28 00:06:40 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:06:40 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:06:40 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.418 s
13/07/28 00:06:40 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.463503971 s
res0: Long = 100

scala> 13/07/28 00:06:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:06:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:06:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:06:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:06:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:06:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:06:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:06:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:06:43 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:06:43 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:52066
Creating SparkContext...
13/07/28 00:06:52 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:06:53 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:06:53 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:06:53 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000653-2beb
13/07/28 00:06:53 INFO network.ConnectionManager: Bound socket to port 33582 with id = ConnectionManagerId(tachyon-ec2-0,33582)
13/07/28 00:06:53 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:06:53 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:33582 with 1295.4 MB RAM
13/07/28 00:06:53 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:06:53 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:06:53 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:34341
13/07/28 00:06:53 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:34341
13/07/28 00:06:53 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:06:53 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-23eba712-a7b8-424e-ad0c-48cd37f52a68
13/07/28 00:06:53 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:06:53 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:52606
13/07/28 00:06:53 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:06:53 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:06:53 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:06:53 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:06:53 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:06:53 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:06:53 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:06:53 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:06:53 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:06:53 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:06:53 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1000").cache()
13/07/28 00:06:54 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:06:54 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:06:54 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:06:54 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:06:55 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:06:55 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:06:55 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:06:55 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:06:55 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:06:55 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:06:55 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:06:55 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:06:55 INFO local.LocalTaskSetManager: Size of task 0 is 1495 bytes
13/07/28 00:06:55 INFO local.LocalScheduler: Running 0
13/07/28 00:06:55 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:06:55 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:06:55 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1000' for reading
13/07/28 00:06:55 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1000' for reading at position '0'
13/07/28 00:06:56 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58415, maxMem=1358297825
13/07/28 00:06:56 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/28 00:06:56 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:33582 (size: 1580.2 KB, free: 1293.8 MB)
13/07/28 00:06:56 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:06:56 INFO local.LocalScheduler: Finished 0
13/07/28 00:06:56 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:06:56 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:06:56 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.566 s
13/07/28 00:06:56 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.612022569 s
res0: Long = 1000

scala> 13/07/28 00:06:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:06:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:06:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:06:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:06:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:06:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:06:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:06:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:06:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:06:58 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:48063
Creating SparkContext...
13/07/28 00:07:08 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:07:08 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:07:08 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:07:08 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000708-a01f
13/07/28 00:07:08 INFO network.ConnectionManager: Bound socket to port 46720 with id = ConnectionManagerId(tachyon-ec2-0,46720)
13/07/28 00:07:08 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:07:08 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:46720 with 1295.4 MB RAM
13/07/28 00:07:08 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:07:08 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:07:08 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:51931
13/07/28 00:07:08 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:51931
13/07/28 00:07:08 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:07:08 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-626de4cb-d42f-4786-8c43-67050f6ee128
13/07/28 00:07:08 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:07:08 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:44411
13/07/28 00:07:08 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:07:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:07:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:07:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:07:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:07:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:07:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:07:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:07:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:07:08 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:07:08 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.10000").cache()
13/07/28 00:07:09 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:07:09 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:07:10 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:07:10 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:07:11 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:07:11 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:07:11 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:07:11 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:07:11 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:07:11 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:07:11 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:07:11 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:07:11 INFO local.LocalTaskSetManager: Size of task 0 is 1496 bytes
13/07/28 00:07:11 INFO local.LocalScheduler: Running 0
13/07/28 00:07:11 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:07:11 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:07:11 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.10000' for reading
13/07/28 00:07:11 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.10000' for reading at position '0'
13/07/28 00:07:12 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58415, maxMem=1358297825
13/07/28 00:07:12 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/28 00:07:12 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:46720 (size: 25.0 MB, free: 1270.4 MB)
13/07/28 00:07:12 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:07:12 INFO local.LocalScheduler: Finished 0
13/07/28 00:07:12 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:07:12 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:07:12 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.247 s
13/07/28 00:07:12 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.293093944 s
res0: Long = 10000

scala> 13/07/28 00:07:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:07:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:07:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:07:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:07:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:07:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:07:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:07:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:07:14 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:07:14 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:49727
Creating SparkContext...
13/07/28 00:07:24 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:07:24 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:07:24 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:07:24 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000724-39a1
13/07/28 00:07:24 INFO network.ConnectionManager: Bound socket to port 44172 with id = ConnectionManagerId(tachyon-ec2-0,44172)
13/07/28 00:07:24 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:07:24 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:44172 with 1295.4 MB RAM
13/07/28 00:07:24 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:07:24 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:07:24 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:42585
13/07/28 00:07:24 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:42585
13/07/28 00:07:24 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:07:24 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-a31b13a9-ecf9-4898-b1b7-14debf5119bd
13/07/28 00:07:24 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:07:24 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:41293
13/07/28 00:07:24 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:07:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:07:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:07:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:07:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:07:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:07:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:07:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:07:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:07:24 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:07:24 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100000").cache()
13/07/28 00:07:25 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:07:25 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:07:26 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:07:26 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:07:26 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:07:26 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:07:26 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:07:26 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:07:26 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:07:26 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:07:26 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:07:26 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:07:27 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/28 00:07:27 INFO local.LocalScheduler: Running 0
13/07/28 00:07:27 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:07:27 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:07:27 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100000' for reading
13/07/28 00:07:27 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100000' for reading at position '0'
13/07/28 00:07:34 INFO storage.MemoryStore: ensureFreeSpace(261997239) called with curMem=58415, maxMem=1358297825
13/07/28 00:07:34 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 249.9 MB, free 1045.5 MB)
13/07/28 00:07:34 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:44172 (size: 249.9 MB, free: 1045.5 MB)
13/07/28 00:07:34 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:07:34 INFO local.LocalScheduler: Finished 0
13/07/28 00:07:34 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:07:34 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:07:34 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 7.318 s
13/07/28 00:07:34 INFO spark.SparkContext: Job finished: count at <console>:15, took 7.363596579 s
res0: Long = 100002

scala> 13/07/28 00:07:34 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:07:34 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:07:34 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:07:34 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:07:34 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:07:34 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:07:34 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:07:34 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:07:36 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:07:36 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:42895
Creating SparkContext...
13/07/28 00:07:46 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:07:46 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:07:46 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:07:46 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000746-f8d4
13/07/28 00:07:46 INFO network.ConnectionManager: Bound socket to port 39080 with id = ConnectionManagerId(tachyon-ec2-0,39080)
13/07/28 00:07:46 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:07:46 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:39080 with 1295.4 MB RAM
13/07/28 00:07:46 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:07:46 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:07:46 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:57303
13/07/28 00:07:46 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:57303
13/07/28 00:07:46 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:07:46 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-a4cb92fc-93ab-4aa3-a194-386321092343
13/07/28 00:07:46 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:07:46 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60128
13/07/28 00:07:46 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:07:46 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:07:46 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:07:46 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:07:46 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:07:46 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:07:46 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:07:46 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:07:46 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:07:46 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:07:46 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.500000").cache()
13/07/28 00:07:47 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:07:47 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:07:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:07:48 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:07:49 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:07:49 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:07:49 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:07:49 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:07:49 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:07:49 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:07:49 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:07:49 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:07:49 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/28 00:07:49 INFO local.LocalScheduler: Running 0
13/07/28 00:07:49 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:07:49 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:07:49 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.500000' for reading
13/07/28 00:07:49 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.500000' for reading at position '0'
13/07/28 00:08:22 INFO storage.MemoryStore: ensureFreeSpace(1288783830) called with curMem=58415, maxMem=1358297825
13/07/28 00:08:22 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1229.1 MB, free 66.2 MB)
13/07/28 00:08:22 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:39080 (size: 1229.1 MB, free: 66.3 MB)
13/07/28 00:08:22 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:08:22 INFO local.LocalScheduler: Finished 0
13/07/28 00:08:23 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:08:23 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:08:23 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 33.920 s
13/07/28 00:08:23 INFO spark.SparkContext: Job finished: count at <console>:15, took 33.964635846 s
res0: Long = 500094

scala> 13/07/28 00:08:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:08:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:08:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:08:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:08:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:08:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:08:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:08:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 8

spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:08:25 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:08:25 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:34573
Creating SparkContext...
13/07/28 00:08:35 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:08:35 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:08:35 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:08:35 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000835-76ca
13/07/28 00:08:35 INFO network.ConnectionManager: Bound socket to port 43607 with id = ConnectionManagerId(tachyon-ec2-0,43607)
13/07/28 00:08:35 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:08:35 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:43607 with 1295.4 MB RAM
13/07/28 00:08:35 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:08:35 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:08:35 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:43104
13/07/28 00:08:35 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:43104
13/07/28 00:08:35 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:08:35 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-95d9e773-73ba-4acc-a3c1-7fd1b6646cf5
13/07/28 00:08:35 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:08:35 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53169
13/07/28 00:08:35 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:08:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:08:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:08:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:08:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:08:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:08:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:08:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:08:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:08:35 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:08:35 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1").cache()
13/07/28 00:08:36 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/28 00:08:36 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:08:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:08:37 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:08:37 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:08:37 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:08:37 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:08:37 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:08:37 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:08:37 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:08:37 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:08:37 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:08:37 INFO local.LocalTaskSetManager: Size of task 0 is 1492 bytes
13/07/28 00:08:37 INFO local.LocalScheduler: Running 0
13/07/28 00:08:37 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:08:37 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:08:38 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1' for reading
13/07/28 00:08:38 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1' for reading at position '0'
13/07/28 00:08:38 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58407, maxMem=1358297825
13/07/28 00:08:38 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/28 00:08:38 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:43607 (size: 1192.0 B, free: 1295.4 MB)
13/07/28 00:08:38 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:08:38 INFO local.LocalScheduler: Finished 0
13/07/28 00:08:38 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:08:38 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:08:38 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.280 s
13/07/28 00:08:38 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.324885047 s
res0: Long = 1

scala> 13/07/28 00:08:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:08:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:08:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:08:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:08:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:08:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:08:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:08:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:08:40 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:08:40 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:49863
Creating SparkContext...
13/07/28 00:08:50 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:08:50 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:08:50 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:08:50 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000850-a130
13/07/28 00:08:50 INFO network.ConnectionManager: Bound socket to port 45398 with id = ConnectionManagerId(tachyon-ec2-0,45398)
13/07/28 00:08:50 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:08:50 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:45398 with 1295.4 MB RAM
13/07/28 00:08:50 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:08:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:08:50 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:44639
13/07/28 00:08:50 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:44639
13/07/28 00:08:50 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:08:50 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-dbe02995-3ea5-49d1-944a-a23138140e02
13/07/28 00:08:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:08:50 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:56529
13/07/28 00:08:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:08:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:08:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:08:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:08:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:08:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:08:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:08:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:08:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:08:50 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:08:50 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100").cache()
13/07/28 00:08:51 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/28 00:08:51 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:08:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:08:52 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:08:52 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:08:52 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:08:52 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:08:52 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:08:52 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:08:52 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:08:52 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:08:52 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:08:52 INFO local.LocalTaskSetManager: Size of task 0 is 1494 bytes
13/07/28 00:08:52 INFO local.LocalScheduler: Running 0
13/07/28 00:08:53 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:08:53 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:08:53 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100' for reading
13/07/28 00:08:53 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100' for reading at position '0'
13/07/28 00:08:53 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58407, maxMem=1358297825
13/07/28 00:08:53 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/28 00:08:53 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:45398 (size: 113.4 KB, free: 1295.3 MB)
13/07/28 00:08:53 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:08:53 INFO local.LocalScheduler: Finished 0
13/07/28 00:08:53 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:08:53 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:08:53 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.352 s
13/07/28 00:08:53 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.397529622 s
res0: Long = 100

scala> 13/07/28 00:08:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:08:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:08:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:08:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:08:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:08:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:08:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:08:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:08:55 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:08:55 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:45142
Creating SparkContext...
13/07/28 00:09:05 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:09:05 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:09:05 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:09:05 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000905-0de4
13/07/28 00:09:05 INFO network.ConnectionManager: Bound socket to port 40475 with id = ConnectionManagerId(tachyon-ec2-0,40475)
13/07/28 00:09:05 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:09:05 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:40475 with 1295.4 MB RAM
13/07/28 00:09:05 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:09:05 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:09:05 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:47796
13/07/28 00:09:05 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:47796
13/07/28 00:09:05 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:09:05 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-88c9d451-aeb3-497e-9ff2-67233f70000e
13/07/28 00:09:05 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:09:05 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:39011
13/07/28 00:09:05 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:09:05 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:09:05 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:09:05 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:09:05 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:09:05 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:09:05 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:09:05 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:09:05 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:09:05 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:09:05 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1000").cache()
13/07/28 00:09:06 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:09:06 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:09:07 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:09:07 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:09:07 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:09:07 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:09:07 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:09:07 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:09:07 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:09:07 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:09:07 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:09:07 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:09:08 INFO local.LocalTaskSetManager: Size of task 0 is 1495 bytes
13/07/28 00:09:08 INFO local.LocalScheduler: Running 0
13/07/28 00:09:08 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:09:08 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:09:08 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1000' for reading
13/07/28 00:09:08 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1000' for reading at position '0'
13/07/28 00:09:08 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58415, maxMem=1358297825
13/07/28 00:09:08 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/28 00:09:08 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:40475 (size: 1580.2 KB, free: 1293.8 MB)
13/07/28 00:09:08 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:09:08 INFO local.LocalScheduler: Finished 0
13/07/28 00:09:08 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:09:08 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:09:08 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.508 s
13/07/28 00:09:08 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.553454937 s
res0: Long = 1000

scala> 13/07/28 00:09:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:09:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:09:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:09:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:09:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:09:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:09:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:09:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:09:11 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:09:11 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55178
Creating SparkContext...
13/07/28 00:09:20 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:09:20 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:09:20 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:09:20 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000920-8b6f
13/07/28 00:09:20 INFO network.ConnectionManager: Bound socket to port 36377 with id = ConnectionManagerId(tachyon-ec2-0,36377)
13/07/28 00:09:20 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:09:20 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:36377 with 1295.4 MB RAM
13/07/28 00:09:20 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:09:20 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:09:20 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60488
13/07/28 00:09:20 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:60488
13/07/28 00:09:20 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:09:20 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-5f701e99-b6e8-4309-92fd-f8d364c6f55e
13/07/28 00:09:20 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:09:20 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:45620
13/07/28 00:09:20 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:09:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:09:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:09:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:09:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:09:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:09:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:09:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:09:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:09:20 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:09:20 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.10000").cache()
13/07/28 00:09:22 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:09:22 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:09:22 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:09:22 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:09:23 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:09:23 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:09:23 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:09:23 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:09:23 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:09:23 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:09:23 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:09:23 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:09:23 INFO local.LocalTaskSetManager: Size of task 0 is 1496 bytes
13/07/28 00:09:23 INFO local.LocalScheduler: Running 0
13/07/28 00:09:23 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:09:23 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:09:23 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.10000' for reading
13/07/28 00:09:23 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.10000' for reading at position '0'
13/07/28 00:09:24 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58415, maxMem=1358297825
13/07/28 00:09:24 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/28 00:09:24 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:36377 (size: 25.0 MB, free: 1270.4 MB)
13/07/28 00:09:24 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:09:24 INFO local.LocalScheduler: Finished 0
13/07/28 00:09:24 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:09:24 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:09:24 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.153 s
13/07/28 00:09:24 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.198403723 s
res0: Long = 10000

scala> 13/07/28 00:09:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:09:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:09:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:09:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:09:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:09:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:09:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:09:24 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:09:26 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:09:26 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:40072
Creating SparkContext...
13/07/28 00:09:36 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:09:36 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:09:36 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:09:36 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000936-2f68
13/07/28 00:09:36 INFO network.ConnectionManager: Bound socket to port 43381 with id = ConnectionManagerId(tachyon-ec2-0,43381)
13/07/28 00:09:36 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:09:36 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:43381 with 1295.4 MB RAM
13/07/28 00:09:36 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:09:36 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:09:36 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:35704
13/07/28 00:09:36 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:35704
13/07/28 00:09:36 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:09:36 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-8b2af007-3b0f-4784-b5d5-960598168e87
13/07/28 00:09:36 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:09:36 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:44006
13/07/28 00:09:36 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:09:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:09:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:09:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:09:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:09:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:09:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:09:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:09:36 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:09:36 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:09:36 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100000").cache()
13/07/28 00:09:37 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:09:37 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:09:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:09:38 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:09:38 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:09:38 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:09:38 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:09:38 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:09:38 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:09:38 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:09:38 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:09:38 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:09:39 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/28 00:09:39 INFO local.LocalScheduler: Running 0
13/07/28 00:09:39 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:09:39 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:09:39 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100000' for reading
13/07/28 00:09:39 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100000' for reading at position '0'
13/07/28 00:09:44 INFO storage.MemoryStore: ensureFreeSpace(261997239) called with curMem=58415, maxMem=1358297825
13/07/28 00:09:44 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 249.9 MB, free 1045.5 MB)
13/07/28 00:09:44 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:43381 (size: 249.9 MB, free: 1045.5 MB)
13/07/28 00:09:44 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:09:44 INFO local.LocalScheduler: Finished 0
13/07/28 00:09:44 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:09:44 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:09:44 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 5.557 s
13/07/28 00:09:44 INFO spark.SparkContext: Job finished: count at <console>:15, took 5.605285092 s
res0: Long = 100002

scala> 13/07/28 00:09:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:09:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:09:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:09:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:09:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:09:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:09:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:09:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:09:47 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:09:47 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:33542
Creating SparkContext...
13/07/28 00:09:56 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:09:56 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:09:56 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:09:56 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728000956-2b22
13/07/28 00:09:56 INFO network.ConnectionManager: Bound socket to port 59050 with id = ConnectionManagerId(tachyon-ec2-0,59050)
13/07/28 00:09:56 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:09:56 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:59050 with 1295.4 MB RAM
13/07/28 00:09:56 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:09:56 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:09:56 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:49267
13/07/28 00:09:56 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:49267
13/07/28 00:09:56 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:09:56 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-c2174b82-c6bf-4b35-a442-a249675059d4
13/07/28 00:09:56 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:09:56 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:48766
13/07/28 00:09:56 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:09:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:09:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:09:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:09:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:09:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:09:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:09:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:09:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:09:56 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:09:56 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.500000").cache()
13/07/28 00:09:58 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:09:58 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:09:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:09:58 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:09:59 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:09:59 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:09:59 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:09:59 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:09:59 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:09:59 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:09:59 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:09:59 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:09:59 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/28 00:09:59 INFO local.LocalScheduler: Running 0
13/07/28 00:09:59 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:09:59 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:09:59 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.500000' for reading
13/07/28 00:09:59 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.500000' for reading at position '0'
13/07/28 00:10:40 INFO storage.MemoryStore: ensureFreeSpace(1288783830) called with curMem=58415, maxMem=1358297825
13/07/28 00:10:40 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1229.1 MB, free 66.2 MB)
13/07/28 00:10:40 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:59050 (size: 1229.1 MB, free: 66.3 MB)
13/07/28 00:10:40 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:10:40 INFO local.LocalScheduler: Finished 0
13/07/28 00:10:40 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:10:40 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:10:40 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 40.733 s
13/07/28 00:10:40 INFO spark.SparkContext: Job finished: count at <console>:15, took 40.78298404 s
res0: Long = 500094

scala> 13/07/28 00:10:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:10:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:10:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:10:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:10:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:10:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:10:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:10:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 9

spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:10:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:10:42 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:58941
Creating SparkContext...
13/07/28 00:10:52 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:10:52 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:10:52 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:10:52 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728001052-8c84
13/07/28 00:10:52 INFO network.ConnectionManager: Bound socket to port 36605 with id = ConnectionManagerId(tachyon-ec2-0,36605)
13/07/28 00:10:52 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:10:52 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:36605 with 1295.4 MB RAM
13/07/28 00:10:52 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:10:52 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:10:52 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:45146
13/07/28 00:10:52 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:45146
13/07/28 00:10:52 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:10:52 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-cec59f96-c6fa-41be-860e-c7536110e7fb
13/07/28 00:10:52 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:10:52 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:36274
13/07/28 00:10:52 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:10:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:10:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:10:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:10:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:10:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:10:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:10:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:10:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:10:52 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:10:52 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1").cache()
13/07/28 00:10:53 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/28 00:10:53 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:10:54 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:10:54 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:10:55 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:10:55 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:10:55 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:10:55 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:10:55 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:10:55 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:10:55 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:10:55 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:10:55 INFO local.LocalTaskSetManager: Size of task 0 is 1492 bytes
13/07/28 00:10:55 INFO local.LocalScheduler: Running 0
13/07/28 00:10:55 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:10:55 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:10:55 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1' for reading
13/07/28 00:10:55 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1' for reading at position '0'
13/07/28 00:10:55 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58407, maxMem=1358297825
13/07/28 00:10:55 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/28 00:10:55 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:36605 (size: 1192.0 B, free: 1295.4 MB)
13/07/28 00:10:55 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:10:55 INFO local.LocalScheduler: Finished 0
13/07/28 00:10:55 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:10:55 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:10:55 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.303 s
13/07/28 00:10:55 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.348619245 s
res0: Long = 1

scala> 13/07/28 00:10:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:10:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:10:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:10:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:10:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:10:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:10:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:10:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:10:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:10:58 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:58331
Creating SparkContext...
13/07/28 00:11:07 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:11:07 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:11:07 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:11:07 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728001107-4da1
13/07/28 00:11:07 INFO network.ConnectionManager: Bound socket to port 46423 with id = ConnectionManagerId(tachyon-ec2-0,46423)
13/07/28 00:11:07 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:11:07 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:46423 with 1295.4 MB RAM
13/07/28 00:11:07 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:11:07 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:11:07 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59254
13/07/28 00:11:07 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:59254
13/07/28 00:11:07 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:11:07 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-54c4baaa-3699-4718-8b6e-fe385a5d8d39
13/07/28 00:11:07 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:11:07 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59305
13/07/28 00:11:08 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:11:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:11:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:11:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:11:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:11:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:11:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:11:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:11:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:11:08 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:11:08 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100").cache()
13/07/28 00:11:09 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/28 00:11:09 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:11:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:11:09 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:11:10 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:11:10 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:11:10 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:11:10 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:11:10 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:11:10 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:11:10 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:11:10 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:11:10 INFO local.LocalTaskSetManager: Size of task 0 is 1494 bytes
13/07/28 00:11:10 INFO local.LocalScheduler: Running 0
13/07/28 00:11:10 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:11:10 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:11:10 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100' for reading
13/07/28 00:11:10 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100' for reading at position '0'
13/07/28 00:11:10 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58407, maxMem=1358297825
13/07/28 00:11:10 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/28 00:11:10 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:46423 (size: 113.4 KB, free: 1295.3 MB)
13/07/28 00:11:10 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:11:10 INFO local.LocalScheduler: Finished 0
13/07/28 00:11:10 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:11:10 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:11:10 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.376 s
13/07/28 00:11:10 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.425004008 s
res0: Long = 100

scala> 13/07/28 00:11:11 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:11:11 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:11:11 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:11:11 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:11:11 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:11:11 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:11:11 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:11:11 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:11:13 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:11:13 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:58208
Creating SparkContext...
13/07/28 00:11:23 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:11:23 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:11:23 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:11:23 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728001123-cd59
13/07/28 00:11:23 INFO network.ConnectionManager: Bound socket to port 38333 with id = ConnectionManagerId(tachyon-ec2-0,38333)
13/07/28 00:11:23 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:11:23 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:38333 with 1295.4 MB RAM
13/07/28 00:11:23 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:11:23 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:11:23 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:46724
13/07/28 00:11:23 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:46724
13/07/28 00:11:23 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:11:23 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-74336ac3-bcad-4f11-9216-99bbefbd53b9
13/07/28 00:11:23 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:11:23 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:56932
13/07/28 00:11:23 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:11:23 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:11:23 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:11:23 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:11:23 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:11:23 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:11:23 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:11:23 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:11:23 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:11:23 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:11:23 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1000").cache()
13/07/28 00:11:25 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:11:25 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:11:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:11:25 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:11:26 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:11:26 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:11:26 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:11:26 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:11:26 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:11:26 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:11:26 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:11:26 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:11:26 INFO local.LocalTaskSetManager: Size of task 0 is 1495 bytes
13/07/28 00:11:26 INFO local.LocalScheduler: Running 0
13/07/28 00:11:26 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:11:26 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:11:26 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1000' for reading
13/07/28 00:11:26 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1000' for reading at position '0'
13/07/28 00:11:26 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58415, maxMem=1358297825
13/07/28 00:11:26 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/28 00:11:26 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:38333 (size: 1580.2 KB, free: 1293.8 MB)
13/07/28 00:11:26 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:11:26 INFO local.LocalScheduler: Finished 0
13/07/28 00:11:26 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:11:26 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:11:26 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.576 s
13/07/28 00:11:26 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.62326255 s
res0: Long = 1000

scala> 13/07/28 00:11:26 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:11:26 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:11:26 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:11:26 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:11:26 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:11:26 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:11:26 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:11:26 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:11:29 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:11:29 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55926
Creating SparkContext...
13/07/28 00:11:38 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:11:39 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:11:39 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:11:39 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728001139-f65a
13/07/28 00:11:39 INFO network.ConnectionManager: Bound socket to port 47853 with id = ConnectionManagerId(tachyon-ec2-0,47853)
13/07/28 00:11:39 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:11:39 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:47853 with 1295.4 MB RAM
13/07/28 00:11:39 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:11:39 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:11:39 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59050
13/07/28 00:11:39 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:59050
13/07/28 00:11:39 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:11:39 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-b4ba8d2c-a7df-402f-a8f0-409ed3cb9e0e
13/07/28 00:11:39 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:11:39 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:56423
13/07/28 00:11:39 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:11:39 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:11:39 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:11:39 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:11:39 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:11:39 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:11:39 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:11:39 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:11:39 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:11:39 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:11:39 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.10000").cache()
13/07/28 00:11:40 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:11:40 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:11:40 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:11:40 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:11:41 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:11:41 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:11:41 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:11:41 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:11:41 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:11:41 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:11:41 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:11:41 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:11:41 INFO local.LocalTaskSetManager: Size of task 0 is 1496 bytes
13/07/28 00:11:41 INFO local.LocalScheduler: Running 0
13/07/28 00:11:41 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:11:41 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:11:41 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.10000' for reading
13/07/28 00:11:41 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.10000' for reading at position '0'
13/07/28 00:11:42 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58415, maxMem=1358297825
13/07/28 00:11:42 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/28 00:11:42 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:47853 (size: 25.0 MB, free: 1270.4 MB)
13/07/28 00:11:42 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:11:42 INFO local.LocalScheduler: Finished 0
13/07/28 00:11:42 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:11:42 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:11:42 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.301 s
13/07/28 00:11:42 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.34711608 s
res0: Long = 10000

scala> 13/07/28 00:11:43 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:11:43 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:11:43 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:11:43 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:11:43 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:11:43 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:11:43 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:11:43 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:11:45 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:11:45 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:54418
Creating SparkContext...
13/07/28 00:11:54 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:11:55 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:11:55 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:11:55 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728001155-0557
13/07/28 00:11:55 INFO network.ConnectionManager: Bound socket to port 40642 with id = ConnectionManagerId(tachyon-ec2-0,40642)
13/07/28 00:11:55 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:11:55 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:40642 with 1295.4 MB RAM
13/07/28 00:11:55 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:11:55 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:11:55 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:54705
13/07/28 00:11:55 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:54705
13/07/28 00:11:55 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:11:55 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-f1ba2fde-8363-42e8-bc64-d19861e75731
13/07/28 00:11:55 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:11:55 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37264
13/07/28 00:11:55 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:11:55 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:11:55 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:11:55 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:11:55 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:11:55 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:11:55 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:11:55 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:11:55 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:11:55 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:11:55 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100000").cache()
13/07/28 00:11:56 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:11:56 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:11:56 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:11:56 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:11:57 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:11:57 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:11:57 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:11:57 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:11:57 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:11:57 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:11:57 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:11:57 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:11:57 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/28 00:11:57 INFO local.LocalScheduler: Running 0
13/07/28 00:11:57 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:11:57 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:11:57 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100000' for reading
13/07/28 00:11:58 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100000' for reading at position '0'
13/07/28 00:12:05 INFO storage.MemoryStore: ensureFreeSpace(261997239) called with curMem=58415, maxMem=1358297825
13/07/28 00:12:05 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 249.9 MB, free 1045.5 MB)
13/07/28 00:12:05 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:40642 (size: 249.9 MB, free: 1045.5 MB)
13/07/28 00:12:05 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:12:05 INFO local.LocalScheduler: Finished 0
13/07/28 00:12:05 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:12:05 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:12:05 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 7.341 s
13/07/28 00:12:05 INFO spark.SparkContext: Job finished: count at <console>:15, took 7.385906564 s
res0: Long = 100002

scala> 13/07/28 00:12:05 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:12:05 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:12:05 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:12:05 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:12:05 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:12:05 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:12:05 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:12:05 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:12:07 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:12:07 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60608
Creating SparkContext...
13/07/28 00:12:17 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:12:17 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:12:17 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:12:17 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728001217-b919
13/07/28 00:12:17 INFO network.ConnectionManager: Bound socket to port 43919 with id = ConnectionManagerId(tachyon-ec2-0,43919)
13/07/28 00:12:17 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:12:17 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:43919 with 1295.4 MB RAM
13/07/28 00:12:17 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:12:17 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:12:17 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:43023
13/07/28 00:12:17 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:43023
13/07/28 00:12:17 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:12:17 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-587ad667-56ab-4a6a-8540-7ea935a9305a
13/07/28 00:12:17 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:12:17 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:45432
13/07/28 00:12:17 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:12:17 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:12:17 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:12:17 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:12:17 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:12:17 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:12:17 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:12:17 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:12:17 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:12:17 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:12:17 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.500000").cache()
13/07/28 00:12:18 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:12:18 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:12:19 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:12:19 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:12:19 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:12:19 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:12:19 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:12:19 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:12:19 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:12:20 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:12:20 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:12:20 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:12:20 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/28 00:12:20 INFO local.LocalScheduler: Running 0
13/07/28 00:12:20 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:12:20 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:12:20 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.500000' for reading
13/07/28 00:12:20 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.500000' for reading at position '0'
13/07/28 00:20:47 INFO storage.MemoryStore: ensureFreeSpace(1288783830) called with curMem=58415, maxMem=1358297825
13/07/28 00:20:47 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1229.1 MB, free 66.2 MB)
13/07/28 00:20:47 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:43919 (size: 1229.1 MB, free: 66.3 MB)
13/07/28 00:20:47 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:20:47 INFO local.LocalScheduler: Finished 0
13/07/28 00:20:47 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:20:47 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:20:47 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 507.286 s
13/07/28 00:20:47 INFO spark.SparkContext: Job finished: count at <console>:15, took 507.332290635 s
res0: Long = 500094

scala> 13/07/28 00:20:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:20:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:20:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:20:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:20:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:20:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:20:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:20:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run11:

spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:20:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:20:50 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:49390
Creating SparkContext...
13/07/28 00:20:59 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:21:00 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:21:00 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:21:00 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728002100-bb6c
13/07/28 00:21:00 INFO network.ConnectionManager: Bound socket to port 44818 with id = ConnectionManagerId(tachyon-ec2-0,44818)
13/07/28 00:21:00 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:21:00 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:44818 with 1295.4 MB RAM
13/07/28 00:21:00 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:21:00 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:21:00 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:36689
13/07/28 00:21:00 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:36689
13/07/28 00:21:00 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:21:00 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-a1d607d1-08f7-45c9-b942-f76ca86ab1ac
13/07/28 00:21:00 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:21:00 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55852
13/07/28 00:21:00 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:21:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:21:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:21:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:21:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:21:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:21:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:21:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:21:00 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:21:00 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:21:00 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1").cache()
13/07/28 00:21:01 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/28 00:21:01 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:21:02 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:21:02 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:21:03 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:21:03 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:03 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:03 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:21:03 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:03 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:03 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:03 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:03 INFO local.LocalTaskSetManager: Size of task 0 is 1492 bytes
13/07/28 00:21:03 INFO local.LocalScheduler: Running 0
13/07/28 00:21:03 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:03 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:21:03 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1' for reading
13/07/28 00:21:03 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1' for reading at position '0'
13/07/28 00:21:03 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58407, maxMem=1358297825
13/07/28 00:21:03 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/28 00:21:03 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:44818 (size: 1192.0 B, free: 1295.4 MB)
13/07/28 00:21:03 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:21:03 INFO local.LocalScheduler: Finished 0
13/07/28 00:21:03 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:21:03 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:21:03 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.346 s
13/07/28 00:21:03 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.398264052 s
res0: Long = 1

scala> s.count()
13/07/28 00:21:03 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:03 INFO scheduler.DAGScheduler: Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:03 INFO scheduler.DAGScheduler: Final stage: Stage 1 (count at <console>:15)
13/07/28 00:21:03 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:03 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:03 INFO scheduler.DAGScheduler: Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:03 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:03 INFO local.LocalTaskSetManager: Size of task 1 is 1493 bytes
13/07/28 00:21:03 INFO local.LocalScheduler: Running 1
13/07/28 00:21:03 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:03 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:03 INFO local.LocalScheduler: Finished 1
13/07/28 00:21:03 INFO scheduler.DAGScheduler: Completed ResultTask(1, 0)
13/07/28 00:21:03 INFO local.LocalScheduler: Remove TaskSet 1.0 from pool 
13/07/28 00:21:03 INFO scheduler.DAGScheduler: Stage 1 (count at <console>:15) finished in 0.046 s
13/07/28 00:21:03 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.049365805 s
res1: Long = 1

scala> s.count()
13/07/28 00:21:04 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Final stage: Stage 2 (count at <console>:15)
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:04 INFO local.LocalTaskSetManager: Size of task 2 is 1493 bytes
13/07/28 00:21:04 INFO local.LocalScheduler: Running 2
13/07/28 00:21:04 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:04 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:04 INFO local.LocalScheduler: Finished 2
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Completed ResultTask(2, 0)
13/07/28 00:21:04 INFO local.LocalScheduler: Remove TaskSet 2.0 from pool 
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Stage 2 (count at <console>:15) finished in 0.039 s
13/07/28 00:21:04 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.042158754 s
res2: Long = 1

scala> s.count()
13/07/28 00:21:04 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Final stage: Stage 3 (count at <console>:15)
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:04 INFO local.LocalTaskSetManager: Size of task 3 is 1493 bytes
13/07/28 00:21:04 INFO local.LocalScheduler: Running 3
13/07/28 00:21:04 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:04 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:04 INFO local.LocalScheduler: Finished 3
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Completed ResultTask(3, 0)
13/07/28 00:21:04 INFO local.LocalScheduler: Remove TaskSet 3.0 from pool 
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Stage 3 (count at <console>:15) finished in 0.035 s
13/07/28 00:21:04 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.037666845 s
res3: Long = 1

scala> s.count()
13/07/28 00:21:04 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Final stage: Stage 4 (count at <console>:15)
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:04 INFO local.LocalTaskSetManager: Size of task 4 is 1493 bytes
13/07/28 00:21:04 INFO local.LocalScheduler: Running 4
13/07/28 00:21:04 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:04 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:04 INFO local.LocalScheduler: Finished 4
13/07/28 00:21:04 INFO local.LocalScheduler: Remove TaskSet 4.0 from pool 
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Completed ResultTask(4, 0)
13/07/28 00:21:04 INFO scheduler.DAGScheduler: Stage 4 (count at <console>:15) finished in 0.032 s
13/07/28 00:21:04 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.034548663 s
res4: Long = 1

scala> s.count()
13/07/28 00:21:05 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Got job 5 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Final stage: Stage 5 (count at <console>:15)
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Submitting Stage 5 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 5 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:05 INFO local.LocalTaskSetManager: Size of task 5 is 1493 bytes
13/07/28 00:21:05 INFO local.LocalScheduler: Running 5
13/07/28 00:21:05 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:05 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:05 INFO local.LocalScheduler: Finished 5
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Completed ResultTask(5, 0)
13/07/28 00:21:05 INFO local.LocalScheduler: Remove TaskSet 5.0 from pool 
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Stage 5 (count at <console>:15) finished in 0.032 s
13/07/28 00:21:05 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.034709656 s
res5: Long = 1

scala> s.count()
13/07/28 00:21:05 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Got job 6 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Final stage: Stage 6 (count at <console>:15)
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Submitting Stage 6 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 6 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:05 INFO local.LocalTaskSetManager: Size of task 6 is 1493 bytes
13/07/28 00:21:05 INFO local.LocalScheduler: Running 6
13/07/28 00:21:05 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:05 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:05 INFO local.LocalScheduler: Finished 6
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Completed ResultTask(6, 0)
13/07/28 00:21:05 INFO local.LocalScheduler: Remove TaskSet 6.0 from pool 
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Stage 6 (count at <console>:15) finished in 0.032 s
13/07/28 00:21:05 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.034785981 s
res6: Long = 1

scala> s.count()
13/07/28 00:21:05 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Got job 7 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Final stage: Stage 7 (count at <console>:15)
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Submitting Stage 7 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 7 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:05 INFO local.LocalTaskSetManager: Size of task 7 is 1493 bytes
13/07/28 00:21:05 INFO local.LocalScheduler: Running 7
13/07/28 00:21:05 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:05 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:05 INFO local.LocalScheduler: Finished 7
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Completed ResultTask(7, 0)
13/07/28 00:21:05 INFO local.LocalScheduler: Remove TaskSet 7.0 from pool 
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Stage 7 (count at <console>:15) finished in 0.033 s
13/07/28 00:21:05 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.036649423 s
res7: Long = 1

scala> s.count()
13/07/28 00:21:05 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Got job 8 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Final stage: Stage 8 (count at <console>:15)
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Submitting Stage 8 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 8 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:05 INFO local.LocalTaskSetManager: Size of task 8 is 1493 bytes
13/07/28 00:21:05 INFO local.LocalScheduler: Running 8
13/07/28 00:21:05 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:05 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:05 INFO local.LocalScheduler: Finished 8
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Completed ResultTask(8, 0)
13/07/28 00:21:05 INFO local.LocalScheduler: Remove TaskSet 8.0 from pool 
13/07/28 00:21:05 INFO scheduler.DAGScheduler: Stage 8 (count at <console>:15) finished in 0.032 s
13/07/28 00:21:05 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.034828179 s
res8: Long = 1

scala> s.count()
13/07/28 00:21:06 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:06 INFO scheduler.DAGScheduler: Got job 9 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:06 INFO scheduler.DAGScheduler: Final stage: Stage 9 (count at <console>:15)
13/07/28 00:21:06 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:06 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:06 INFO scheduler.DAGScheduler: Submitting Stage 9 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:06 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 9 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:06 INFO local.LocalTaskSetManager: Size of task 9 is 1493 bytes
13/07/28 00:21:06 INFO local.LocalScheduler: Running 9
13/07/28 00:21:06 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:06 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:06 INFO local.LocalScheduler: Finished 9
13/07/28 00:21:06 INFO scheduler.DAGScheduler: Completed ResultTask(9, 0)
13/07/28 00:21:06 INFO local.LocalScheduler: Remove TaskSet 9.0 from pool 
13/07/28 00:21:06 INFO scheduler.DAGScheduler: Stage 9 (count at <console>:15) finished in 0.034 s
13/07/28 00:21:06 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.037004129 s
res9: Long = 1

scala> s.count()
13/07/28 00:21:06 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:06 INFO scheduler.DAGScheduler: Got job 10 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:06 INFO scheduler.DAGScheduler: Final stage: Stage 10 (count at <console>:15)
13/07/28 00:21:06 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:06 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:06 INFO scheduler.DAGScheduler: Submitting Stage 10 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:06 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 10 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:06 INFO local.LocalTaskSetManager: Size of task 10 is 1493 bytes
13/07/28 00:21:06 INFO local.LocalScheduler: Running 10
13/07/28 00:21:06 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:06 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:06 INFO local.LocalScheduler: Finished 10
13/07/28 00:21:06 INFO scheduler.DAGScheduler: Completed ResultTask(10, 0)
13/07/28 00:21:06 INFO local.LocalScheduler: Remove TaskSet 10.0 from pool 
13/07/28 00:21:06 INFO scheduler.DAGScheduler: Stage 10 (count at <console>:15) finished in 0.024 s
13/07/28 00:21:06 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.02624768 s
res10: Long = 1

scala> 13/07/28 00:21:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:21:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:21:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:21:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:21:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:21:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:21:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:21:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:21:09 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:21:09 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50520
Creating SparkContext...
13/07/28 00:21:18 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:21:19 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:21:19 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:21:19 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728002119-ef6c
13/07/28 00:21:19 INFO network.ConnectionManager: Bound socket to port 52198 with id = ConnectionManagerId(tachyon-ec2-0,52198)
13/07/28 00:21:19 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:21:19 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:52198 with 1295.4 MB RAM
13/07/28 00:21:19 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:21:19 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:21:19 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37497
13/07/28 00:21:19 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:37497
13/07/28 00:21:19 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:21:19 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-fff99724-135f-4578-aaf5-f41fe31799e2
13/07/28 00:21:19 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:21:19 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:56753
13/07/28 00:21:19 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:21:19 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:21:19 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:21:19 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:21:19 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:21:19 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:21:19 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:21:19 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:21:19 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:21:19 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:21:19 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100").cache()
13/07/28 00:21:20 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/28 00:21:20 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:21:21 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:21:21 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:21:22 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:21:22 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:22 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:22 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:21:22 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:22 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:22 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:22 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:22 INFO local.LocalTaskSetManager: Size of task 0 is 1494 bytes
13/07/28 00:21:22 INFO local.LocalScheduler: Running 0
13/07/28 00:21:22 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:22 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:21:22 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100' for reading
13/07/28 00:21:22 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100' for reading at position '0'
13/07/28 00:21:22 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58407, maxMem=1358297825
13/07/28 00:21:22 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/28 00:21:22 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:52198 (size: 113.4 KB, free: 1295.3 MB)
13/07/28 00:21:22 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:21:22 INFO local.LocalScheduler: Finished 0
13/07/28 00:21:22 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:21:22 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:21:22 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.398 s
13/07/28 00:21:22 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.449864071 s
res0: Long = 100

scala> s.count()
13/07/28 00:21:22 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:22 INFO scheduler.DAGScheduler: Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:22 INFO scheduler.DAGScheduler: Final stage: Stage 1 (count at <console>:15)
13/07/28 00:21:22 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:22 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:22 INFO scheduler.DAGScheduler: Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:22 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:22 INFO local.LocalTaskSetManager: Size of task 1 is 1495 bytes
13/07/28 00:21:22 INFO local.LocalScheduler: Running 1
13/07/28 00:21:22 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:22 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:22 INFO local.LocalScheduler: Finished 1
13/07/28 00:21:22 INFO scheduler.DAGScheduler: Completed ResultTask(1, 0)
13/07/28 00:21:22 INFO local.LocalScheduler: Remove TaskSet 1.0 from pool 
13/07/28 00:21:22 INFO scheduler.DAGScheduler: Stage 1 (count at <console>:15) finished in 0.048 s
13/07/28 00:21:22 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.051603738 s
res1: Long = 100

scala> s.count()
13/07/28 00:21:23 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Final stage: Stage 2 (count at <console>:15)
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:23 INFO local.LocalTaskSetManager: Size of task 2 is 1495 bytes
13/07/28 00:21:23 INFO local.LocalScheduler: Running 2
13/07/28 00:21:23 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:23 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:23 INFO local.LocalScheduler: Finished 2
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Completed ResultTask(2, 0)
13/07/28 00:21:23 INFO local.LocalScheduler: Remove TaskSet 2.0 from pool 
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Stage 2 (count at <console>:15) finished in 0.044 s
13/07/28 00:21:23 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.046690492 s
res2: Long = 100

scala> s.count()
13/07/28 00:21:23 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Final stage: Stage 3 (count at <console>:15)
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:23 INFO local.LocalTaskSetManager: Size of task 3 is 1495 bytes
13/07/28 00:21:23 INFO local.LocalScheduler: Running 3
13/07/28 00:21:23 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:23 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:23 INFO local.LocalScheduler: Finished 3
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Completed ResultTask(3, 0)
13/07/28 00:21:23 INFO local.LocalScheduler: Remove TaskSet 3.0 from pool 
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Stage 3 (count at <console>:15) finished in 0.037 s
13/07/28 00:21:23 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.040433711 s
res3: Long = 100

scala> s.count()
13/07/28 00:21:23 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Final stage: Stage 4 (count at <console>:15)
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:23 INFO local.LocalTaskSetManager: Size of task 4 is 1495 bytes
13/07/28 00:21:23 INFO local.LocalScheduler: Running 4
13/07/28 00:21:23 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:23 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:23 INFO local.LocalScheduler: Finished 4
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Completed ResultTask(4, 0)
13/07/28 00:21:23 INFO local.LocalScheduler: Remove TaskSet 4.0 from pool 
13/07/28 00:21:23 INFO scheduler.DAGScheduler: Stage 4 (count at <console>:15) finished in 0.039 s
13/07/28 00:21:23 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.041569633 s
res4: Long = 100

scala> s.count()
13/07/28 00:21:24 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Got job 5 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Final stage: Stage 5 (count at <console>:15)
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Submitting Stage 5 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 5 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:24 INFO local.LocalTaskSetManager: Size of task 5 is 1495 bytes
13/07/28 00:21:24 INFO local.LocalScheduler: Running 5
13/07/28 00:21:24 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:24 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:24 INFO local.LocalScheduler: Finished 5
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Completed ResultTask(5, 0)
13/07/28 00:21:24 INFO local.LocalScheduler: Remove TaskSet 5.0 from pool 
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Stage 5 (count at <console>:15) finished in 0.033 s
13/07/28 00:21:24 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.036639973 s
res5: Long = 100

scala> s.count()
13/07/28 00:21:24 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Got job 6 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Final stage: Stage 6 (count at <console>:15)
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Submitting Stage 6 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 6 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:24 INFO local.LocalTaskSetManager: Size of task 6 is 1495 bytes
13/07/28 00:21:24 INFO local.LocalScheduler: Running 6
13/07/28 00:21:24 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:24 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:24 INFO local.LocalScheduler: Finished 6
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Completed ResultTask(6, 0)
13/07/28 00:21:24 INFO local.LocalScheduler: Remove TaskSet 6.0 from pool 
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Stage 6 (count at <console>:15) finished in 0.034 s
13/07/28 00:21:24 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.037228033 s
res6: Long = 100

scala> s.count()
13/07/28 00:21:24 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Got job 7 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Final stage: Stage 7 (count at <console>:15)
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Submitting Stage 7 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 7 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:24 INFO local.LocalTaskSetManager: Size of task 7 is 1495 bytes
13/07/28 00:21:24 INFO local.LocalScheduler: Running 7
13/07/28 00:21:24 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:24 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:24 INFO local.LocalScheduler: Finished 7
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Completed ResultTask(7, 0)
13/07/28 00:21:24 INFO local.LocalScheduler: Remove TaskSet 7.0 from pool 
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Stage 7 (count at <console>:15) finished in 0.036 s
13/07/28 00:21:24 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.039155582 s
res7: Long = 100

scala> s.count()
13/07/28 00:21:24 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Got job 8 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Final stage: Stage 8 (count at <console>:15)
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Submitting Stage 8 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 8 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:24 INFO local.LocalTaskSetManager: Size of task 8 is 1495 bytes
13/07/28 00:21:24 INFO local.LocalScheduler: Running 8
13/07/28 00:21:24 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:24 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:24 INFO local.LocalScheduler: Finished 8
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Completed ResultTask(8, 0)
13/07/28 00:21:24 INFO local.LocalScheduler: Remove TaskSet 8.0 from pool 
13/07/28 00:21:24 INFO scheduler.DAGScheduler: Stage 8 (count at <console>:15) finished in 0.030 s
13/07/28 00:21:24 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.034170836 s
res8: Long = 100

scala> s.count()
13/07/28 00:21:25 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:25 INFO scheduler.DAGScheduler: Got job 9 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:25 INFO scheduler.DAGScheduler: Final stage: Stage 9 (count at <console>:15)
13/07/28 00:21:25 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:25 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:25 INFO scheduler.DAGScheduler: Submitting Stage 9 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:25 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 9 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:25 INFO local.LocalTaskSetManager: Size of task 9 is 1495 bytes
13/07/28 00:21:25 INFO local.LocalScheduler: Running 9
13/07/28 00:21:25 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:25 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:25 INFO local.LocalScheduler: Finished 9
13/07/28 00:21:25 INFO scheduler.DAGScheduler: Completed ResultTask(9, 0)
13/07/28 00:21:25 INFO local.LocalScheduler: Remove TaskSet 9.0 from pool 
13/07/28 00:21:25 INFO scheduler.DAGScheduler: Stage 9 (count at <console>:15) finished in 0.033 s
13/07/28 00:21:25 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.035744147 s
res9: Long = 100

scala> s.count()
13/07/28 00:21:25 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:25 INFO scheduler.DAGScheduler: Got job 10 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:25 INFO scheduler.DAGScheduler: Final stage: Stage 10 (count at <console>:15)
13/07/28 00:21:25 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:25 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:25 INFO scheduler.DAGScheduler: Submitting Stage 10 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:25 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 10 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:25 INFO local.LocalTaskSetManager: Size of task 10 is 1495 bytes
13/07/28 00:21:25 INFO local.LocalScheduler: Running 10
13/07/28 00:21:25 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:25 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:25 INFO local.LocalScheduler: Finished 10
13/07/28 00:21:25 INFO scheduler.DAGScheduler: Completed ResultTask(10, 0)
13/07/28 00:21:25 INFO local.LocalScheduler: Remove TaskSet 10.0 from pool 
13/07/28 00:21:25 INFO scheduler.DAGScheduler: Stage 10 (count at <console>:15) finished in 0.023 s
13/07/28 00:21:25 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.026431745 s
res10: Long = 100

scala> 13/07/28 00:21:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:21:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:21:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:21:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:21:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:21:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:21:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:21:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:21:28 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:21:28 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:40707
Creating SparkContext...
13/07/28 00:21:38 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:21:38 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:21:38 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:21:38 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728002138-7d54
13/07/28 00:21:38 INFO network.ConnectionManager: Bound socket to port 37998 with id = ConnectionManagerId(tachyon-ec2-0,37998)
13/07/28 00:21:38 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:21:38 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:37998 with 1295.4 MB RAM
13/07/28 00:21:38 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:21:38 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:21:38 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:54059
13/07/28 00:21:38 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:54059
13/07/28 00:21:38 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:21:38 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-e8998694-2e9f-400d-839f-91338077d061
13/07/28 00:21:38 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:21:38 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37255
13/07/28 00:21:38 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:21:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:21:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:21:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:21:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:21:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:21:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:21:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:21:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:21:38 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:21:38 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.1000").cache()
13/07/28 00:21:40 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:21:40 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:21:40 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:21:40 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:21:41 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:21:41 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:41 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:41 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:21:41 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:41 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:41 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:41 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:41 INFO local.LocalTaskSetManager: Size of task 0 is 1495 bytes
13/07/28 00:21:41 INFO local.LocalScheduler: Running 0
13/07/28 00:21:41 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:41 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:21:41 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.1000' for reading
13/07/28 00:21:41 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.1000' for reading at position '0'
13/07/28 00:21:41 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58415, maxMem=1358297825
13/07/28 00:21:41 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/28 00:21:41 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:37998 (size: 1580.2 KB, free: 1293.8 MB)
13/07/28 00:21:41 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:21:41 INFO local.LocalScheduler: Finished 0
13/07/28 00:21:41 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:21:41 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:21:41 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.552 s
13/07/28 00:21:41 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.601250821 s
res0: Long = 1000

scala> s.count()
13/07/28 00:21:42 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Final stage: Stage 1 (count at <console>:15)
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:42 INFO local.LocalTaskSetManager: Size of task 1 is 1496 bytes
13/07/28 00:21:42 INFO local.LocalScheduler: Running 1
13/07/28 00:21:42 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:42 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:42 INFO local.LocalScheduler: Finished 1
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Completed ResultTask(1, 0)
13/07/28 00:21:42 INFO local.LocalScheduler: Remove TaskSet 1.0 from pool 
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Stage 1 (count at <console>:15) finished in 0.044 s
13/07/28 00:21:42 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.047305185 s
res1: Long = 1000

scala> s.count()
13/07/28 00:21:42 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Final stage: Stage 2 (count at <console>:15)
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:42 INFO local.LocalTaskSetManager: Size of task 2 is 1496 bytes
13/07/28 00:21:42 INFO local.LocalScheduler: Running 2
13/07/28 00:21:42 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:42 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:42 INFO local.LocalScheduler: Finished 2
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Completed ResultTask(2, 0)
13/07/28 00:21:42 INFO local.LocalScheduler: Remove TaskSet 2.0 from pool 
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Stage 2 (count at <console>:15) finished in 0.041 s
13/07/28 00:21:42 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.044301148 s
res2: Long = 1000

scala> s.count()
13/07/28 00:21:42 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Final stage: Stage 3 (count at <console>:15)
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:42 INFO local.LocalTaskSetManager: Size of task 3 is 1496 bytes
13/07/28 00:21:42 INFO local.LocalScheduler: Running 3
13/07/28 00:21:42 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:42 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:42 INFO local.LocalScheduler: Finished 3
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Completed ResultTask(3, 0)
13/07/28 00:21:42 INFO local.LocalScheduler: Remove TaskSet 3.0 from pool 
13/07/28 00:21:42 INFO scheduler.DAGScheduler: Stage 3 (count at <console>:15) finished in 0.036 s
13/07/28 00:21:42 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.038939539 s
res3: Long = 1000

scala> s.count()
13/07/28 00:21:43 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Final stage: Stage 4 (count at <console>:15)
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:43 INFO local.LocalTaskSetManager: Size of task 4 is 1496 bytes
13/07/28 00:21:43 INFO local.LocalScheduler: Running 4
13/07/28 00:21:43 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:43 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:43 INFO local.LocalScheduler: Finished 4
13/07/28 00:21:43 INFO local.LocalScheduler: Remove TaskSet 4.0 from pool 
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Completed ResultTask(4, 0)
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Stage 4 (count at <console>:15) finished in 0.034 s
13/07/28 00:21:43 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.03696991 s
res4: Long = 1000

scala> s.count()
13/07/28 00:21:43 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Got job 5 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Final stage: Stage 5 (count at <console>:15)
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Submitting Stage 5 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 5 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:43 INFO local.LocalTaskSetManager: Size of task 5 is 1496 bytes
13/07/28 00:21:43 INFO local.LocalScheduler: Running 5
13/07/28 00:21:43 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:43 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:43 INFO local.LocalScheduler: Finished 5
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Completed ResultTask(5, 0)
13/07/28 00:21:43 INFO local.LocalScheduler: Remove TaskSet 5.0 from pool 
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Stage 5 (count at <console>:15) finished in 0.035 s
13/07/28 00:21:43 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.036918815 s
res5: Long = 1000

scala> s.count()
13/07/28 00:21:43 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Got job 6 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Final stage: Stage 6 (count at <console>:15)
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Submitting Stage 6 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 6 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:43 INFO local.LocalTaskSetManager: Size of task 6 is 1496 bytes
13/07/28 00:21:43 INFO local.LocalScheduler: Running 6
13/07/28 00:21:43 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:43 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:43 INFO local.LocalScheduler: Finished 6
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Completed ResultTask(6, 0)
13/07/28 00:21:43 INFO local.LocalScheduler: Remove TaskSet 6.0 from pool 
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Stage 6 (count at <console>:15) finished in 0.033 s
13/07/28 00:21:43 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.035555405 s
res6: Long = 1000

scala> s.count()
13/07/28 00:21:43 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Got job 7 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Final stage: Stage 7 (count at <console>:15)
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Submitting Stage 7 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 7 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:43 INFO local.LocalTaskSetManager: Size of task 7 is 1496 bytes
13/07/28 00:21:43 INFO local.LocalScheduler: Running 7
13/07/28 00:21:43 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:43 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:43 INFO local.LocalScheduler: Finished 7
13/07/28 00:21:43 INFO local.LocalScheduler: Remove TaskSet 7.0 from pool 
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Completed ResultTask(7, 0)
13/07/28 00:21:43 INFO scheduler.DAGScheduler: Stage 7 (count at <console>:15) finished in 0.036 s
13/07/28 00:21:43 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.039704339 s
res7: Long = 1000

scala> s.count()
13/07/28 00:21:44 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Got job 8 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Final stage: Stage 8 (count at <console>:15)
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Submitting Stage 8 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 8 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:44 INFO local.LocalTaskSetManager: Size of task 8 is 1496 bytes
13/07/28 00:21:44 INFO local.LocalScheduler: Running 8
13/07/28 00:21:44 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:44 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:44 INFO local.LocalScheduler: Finished 8
13/07/28 00:21:44 INFO local.LocalScheduler: Remove TaskSet 8.0 from pool 
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Completed ResultTask(8, 0)
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Stage 8 (count at <console>:15) finished in 0.031 s
13/07/28 00:21:44 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.034561356 s
res8: Long = 1000

scala> s.count()
13/07/28 00:21:44 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Got job 9 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Final stage: Stage 9 (count at <console>:15)
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Submitting Stage 9 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 9 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:44 INFO local.LocalTaskSetManager: Size of task 9 is 1496 bytes
13/07/28 00:21:44 INFO local.LocalScheduler: Running 9
13/07/28 00:21:44 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:44 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:44 INFO local.LocalScheduler: Finished 9
13/07/28 00:21:44 INFO local.LocalScheduler: Remove TaskSet 9.0 from pool 
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Completed ResultTask(9, 0)
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Stage 9 (count at <console>:15) finished in 0.036 s
13/07/28 00:21:44 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.0386812 s
res9: Long = 1000

scala> s.count()
13/07/28 00:21:44 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Got job 10 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Final stage: Stage 10 (count at <console>:15)
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Submitting Stage 10 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 10 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:21:44 INFO local.LocalTaskSetManager: Size of task 10 is 1496 bytes
13/07/28 00:21:44 INFO local.LocalScheduler: Running 10
13/07/28 00:21:44 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:21:44 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:21:44 INFO local.LocalScheduler: Finished 10
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Completed ResultTask(10, 0)
13/07/28 00:21:44 INFO local.LocalScheduler: Remove TaskSet 10.0 from pool 
13/07/28 00:21:44 INFO scheduler.DAGScheduler: Stage 10 (count at <console>:15) finished in 0.025 s
13/07/28 00:21:44 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.027273312 s
res10: Long = 1000

scala> 13/07/28 00:21:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:21:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:21:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:21:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:21:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:21:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:21:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:21:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:21:47 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:21:47 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50651
Creating SparkContext...
13/07/28 00:21:57 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:21:57 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:21:57 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:21:57 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728002157-843b
13/07/28 00:21:57 INFO network.ConnectionManager: Bound socket to port 36699 with id = ConnectionManagerId(tachyon-ec2-0,36699)
13/07/28 00:21:57 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:21:57 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:36699 with 1295.4 MB RAM
13/07/28 00:21:57 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:21:57 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:21:57 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:40838
13/07/28 00:21:57 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:40838
13/07/28 00:21:57 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:21:57 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-1be5f115-d958-43b2-b464-2c869ee23056
13/07/28 00:21:57 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:21:57 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55197
13/07/28 00:21:57 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:21:57 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:21:57 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:21:57 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:21:57 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:21:57 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:21:57 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:21:57 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:21:57 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:21:57 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:21:57 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.10000").cache()
13/07/28 00:21:58 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:21:58 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:21:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:21:59 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:22:00 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:22:00 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:00 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:00 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:22:00 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:00 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:00 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:00 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:00 INFO local.LocalTaskSetManager: Size of task 0 is 1496 bytes
13/07/28 00:22:00 INFO local.LocalScheduler: Running 0
13/07/28 00:22:00 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:00 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:22:00 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.10000' for reading
13/07/28 00:22:00 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.10000' for reading at position '0'
13/07/28 00:22:01 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58415, maxMem=1358297825
13/07/28 00:22:01 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/28 00:22:01 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:36699 (size: 25.0 MB, free: 1270.4 MB)
13/07/28 00:22:01 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:22:01 INFO local.LocalScheduler: Finished 0
13/07/28 00:22:01 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:22:01 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:22:01 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.460 s
13/07/28 00:22:01 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.509447828 s
res0: Long = 10000

scala> s.count()
13/07/28 00:22:01 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:01 INFO scheduler.DAGScheduler: Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:01 INFO scheduler.DAGScheduler: Final stage: Stage 1 (count at <console>:15)
13/07/28 00:22:01 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:01 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:01 INFO scheduler.DAGScheduler: Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:01 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:01 INFO local.LocalTaskSetManager: Size of task 1 is 1497 bytes
13/07/28 00:22:01 INFO local.LocalScheduler: Running 1
13/07/28 00:22:02 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:02 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:02 INFO local.LocalScheduler: Finished 1
13/07/28 00:22:02 INFO local.LocalScheduler: Remove TaskSet 1.0 from pool 
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Completed ResultTask(1, 0)
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Stage 1 (count at <console>:15) finished in 0.047 s
13/07/28 00:22:02 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.050605197 s
res1: Long = 10000

scala> s.count()
13/07/28 00:22:02 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Final stage: Stage 2 (count at <console>:15)
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:02 INFO local.LocalTaskSetManager: Size of task 2 is 1497 bytes
13/07/28 00:22:02 INFO local.LocalScheduler: Running 2
13/07/28 00:22:02 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:02 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:02 INFO local.LocalScheduler: Finished 2
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Completed ResultTask(2, 0)
13/07/28 00:22:02 INFO local.LocalScheduler: Remove TaskSet 2.0 from pool 
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Stage 2 (count at <console>:15) finished in 0.047 s
13/07/28 00:22:02 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.05009803 s
res2: Long = 10000

scala> s.count()
13/07/28 00:22:02 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Final stage: Stage 3 (count at <console>:15)
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:02 INFO local.LocalTaskSetManager: Size of task 3 is 1497 bytes
13/07/28 00:22:02 INFO local.LocalScheduler: Running 3
13/07/28 00:22:02 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:02 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:02 INFO local.LocalScheduler: Finished 3
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Completed ResultTask(3, 0)
13/07/28 00:22:02 INFO local.LocalScheduler: Remove TaskSet 3.0 from pool 
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Stage 3 (count at <console>:15) finished in 0.037 s
13/07/28 00:22:02 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.041445049 s
res3: Long = 10000

scala> s.count()
13/07/28 00:22:02 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Final stage: Stage 4 (count at <console>:15)
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:02 INFO local.LocalTaskSetManager: Size of task 4 is 1497 bytes
13/07/28 00:22:02 INFO local.LocalScheduler: Running 4
13/07/28 00:22:02 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:02 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:02 INFO local.LocalScheduler: Finished 4
13/07/28 00:22:02 INFO local.LocalScheduler: Remove TaskSet 4.0 from pool 
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Completed ResultTask(4, 0)
13/07/28 00:22:02 INFO scheduler.DAGScheduler: Stage 4 (count at <console>:15) finished in 0.035 s
13/07/28 00:22:02 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.037836046 s
res4: Long = 10000

scala> s.count()
13/07/28 00:22:03 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Got job 5 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Final stage: Stage 5 (count at <console>:15)
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Submitting Stage 5 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 5 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:03 INFO local.LocalTaskSetManager: Size of task 5 is 1497 bytes
13/07/28 00:22:03 INFO local.LocalScheduler: Running 5
13/07/28 00:22:03 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:03 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:03 INFO local.LocalScheduler: Finished 5
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Completed ResultTask(5, 0)
13/07/28 00:22:03 INFO local.LocalScheduler: Remove TaskSet 5.0 from pool 
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Stage 5 (count at <console>:15) finished in 0.032 s
13/07/28 00:22:03 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.035291404 s
res5: Long = 10000

scala> s.count()
13/07/28 00:22:03 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Got job 6 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Final stage: Stage 6 (count at <console>:15)
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Submitting Stage 6 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 6 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:03 INFO local.LocalTaskSetManager: Size of task 6 is 1497 bytes
13/07/28 00:22:03 INFO local.LocalScheduler: Running 6
13/07/28 00:22:03 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:03 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:03 INFO local.LocalScheduler: Finished 6
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Completed ResultTask(6, 0)
13/07/28 00:22:03 INFO local.LocalScheduler: Remove TaskSet 6.0 from pool 
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Stage 6 (count at <console>:15) finished in 0.033 s
13/07/28 00:22:03 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.035404545 s
res6: Long = 10000

scala> s.count()
13/07/28 00:22:03 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Got job 7 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Final stage: Stage 7 (count at <console>:15)
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Submitting Stage 7 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 7 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:03 INFO local.LocalTaskSetManager: Size of task 7 is 1497 bytes
13/07/28 00:22:03 INFO local.LocalScheduler: Running 7
13/07/28 00:22:03 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:03 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:03 INFO local.LocalScheduler: Finished 7
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Completed ResultTask(7, 0)
13/07/28 00:22:03 INFO local.LocalScheduler: Remove TaskSet 7.0 from pool 
13/07/28 00:22:03 INFO scheduler.DAGScheduler: Stage 7 (count at <console>:15) finished in 0.034 s
13/07/28 00:22:03 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.037870012 s
res7: Long = 10000

scala> s.count()
13/07/28 00:22:04 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Got job 8 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Final stage: Stage 8 (count at <console>:15)
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Submitting Stage 8 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 8 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:04 INFO local.LocalTaskSetManager: Size of task 8 is 1497 bytes
13/07/28 00:22:04 INFO local.LocalScheduler: Running 8
13/07/28 00:22:04 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:04 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:04 INFO local.LocalScheduler: Finished 8
13/07/28 00:22:04 INFO local.LocalScheduler: Remove TaskSet 8.0 from pool 
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Completed ResultTask(8, 0)
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Stage 8 (count at <console>:15) finished in 0.032 s
13/07/28 00:22:04 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.036075185 s
res8: Long = 10000

scala> s.count()
13/07/28 00:22:04 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Got job 9 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Final stage: Stage 9 (count at <console>:15)
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Submitting Stage 9 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 9 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:04 INFO local.LocalTaskSetManager: Size of task 9 is 1497 bytes
13/07/28 00:22:04 INFO local.LocalScheduler: Running 9
13/07/28 00:22:04 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:04 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:04 INFO local.LocalScheduler: Finished 9
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Completed ResultTask(9, 0)
13/07/28 00:22:04 INFO local.LocalScheduler: Remove TaskSet 9.0 from pool 
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Stage 9 (count at <console>:15) finished in 0.033 s
13/07/28 00:22:04 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.036083138 s
res9: Long = 10000

scala> s.count()
13/07/28 00:22:04 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Got job 10 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Final stage: Stage 10 (count at <console>:15)
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Submitting Stage 10 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 10 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:04 INFO local.LocalTaskSetManager: Size of task 10 is 1497 bytes
13/07/28 00:22:04 INFO local.LocalScheduler: Running 10
13/07/28 00:22:04 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:04 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:04 INFO local.LocalScheduler: Finished 10
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Completed ResultTask(10, 0)
13/07/28 00:22:04 INFO local.LocalScheduler: Remove TaskSet 10.0 from pool 
13/07/28 00:22:04 INFO scheduler.DAGScheduler: Stage 10 (count at <console>:15) finished in 0.025 s
13/07/28 00:22:04 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.028010095 s
res10: Long = 10000

scala> 13/07/28 00:22:04 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:22:04 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:22:04 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:22:04 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:22:04 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:22:04 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:22:04 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:22:04 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:22:07 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:22:07 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60369
Creating SparkContext...
13/07/28 00:22:17 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:22:17 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:22:17 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:22:17 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728002217-6ae9
13/07/28 00:22:17 INFO network.ConnectionManager: Bound socket to port 54070 with id = ConnectionManagerId(tachyon-ec2-0,54070)
13/07/28 00:22:17 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:22:17 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:54070 with 1295.4 MB RAM
13/07/28 00:22:17 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:22:17 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:22:17 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:58996
13/07/28 00:22:17 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:58996
13/07/28 00:22:17 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:22:17 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-7b59883b-b2af-4d39-b139-0d0a8c031f74
13/07/28 00:22:17 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:22:17 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:49389
13/07/28 00:22:18 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:22:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:22:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:22:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:22:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:22:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:22:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:22:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:22:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:22:18 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:22:18 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.100000").cache()
13/07/28 00:22:19 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:22:19 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:22:19 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:22:19 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:22:20 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:22:20 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:20 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:20 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:22:20 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:20 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:20 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:20 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:20 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/28 00:22:20 INFO local.LocalScheduler: Running 0
13/07/28 00:22:20 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:20 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:22:21 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.100000' for reading
13/07/28 00:22:21 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.100000' for reading at position '0'
13/07/28 00:22:26 INFO storage.MemoryStore: ensureFreeSpace(261997239) called with curMem=58415, maxMem=1358297825
13/07/28 00:22:26 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 249.9 MB, free 1045.5 MB)
13/07/28 00:22:26 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:54070 (size: 249.9 MB, free: 1045.5 MB)
13/07/28 00:22:26 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:22:26 INFO local.LocalScheduler: Finished 0
13/07/28 00:22:26 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 5.450 s
13/07/28 00:22:26 INFO spark.SparkContext: Job finished: count at <console>:15, took 5.501765835 s
res0: Long = 100002

scala> s.count()
13/07/28 00:22:26 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Final stage: Stage 1 (count at <console>:15)
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:26 INFO local.LocalTaskSetManager: Size of task 1 is 1498 bytes
13/07/28 00:22:26 INFO local.LocalScheduler: Running 1
13/07/28 00:22:26 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:26 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:26 INFO local.LocalScheduler: Finished 1
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Completed ResultTask(1, 0)
13/07/28 00:22:26 INFO local.LocalScheduler: Remove TaskSet 1.0 from pool 
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Stage 1 (count at <console>:15) finished in 0.052 s
13/07/28 00:22:26 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.054903133 s
res1: Long = 100002

scala> s.count()
13/07/28 00:22:26 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Final stage: Stage 2 (count at <console>:15)
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:26 INFO local.LocalTaskSetManager: Size of task 2 is 1498 bytes
13/07/28 00:22:26 INFO local.LocalScheduler: Running 2
13/07/28 00:22:26 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:26 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:26 INFO local.LocalScheduler: Finished 2
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Completed ResultTask(2, 0)
13/07/28 00:22:26 INFO local.LocalScheduler: Remove TaskSet 2.0 from pool 
13/07/28 00:22:26 INFO scheduler.DAGScheduler: Stage 2 (count at <console>:15) finished in 0.044 s
13/07/28 00:22:26 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.04665347 s
res2: Long = 100002

scala> s.count()
13/07/28 00:22:27 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Final stage: Stage 3 (count at <console>:15)
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:27 INFO local.LocalTaskSetManager: Size of task 3 is 1498 bytes
13/07/28 00:22:27 INFO local.LocalScheduler: Running 3
13/07/28 00:22:27 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:27 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:27 INFO local.LocalScheduler: Finished 3
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Completed ResultTask(3, 0)
13/07/28 00:22:27 INFO local.LocalScheduler: Remove TaskSet 3.0 from pool 
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Stage 3 (count at <console>:15) finished in 0.042 s
13/07/28 00:22:27 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.044700261 s
res3: Long = 100002

scala> s.count()
13/07/28 00:22:27 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Final stage: Stage 4 (count at <console>:15)
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:27 INFO local.LocalTaskSetManager: Size of task 4 is 1498 bytes
13/07/28 00:22:27 INFO local.LocalScheduler: Running 4
13/07/28 00:22:27 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:27 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:27 INFO local.LocalScheduler: Finished 4
13/07/28 00:22:27 INFO local.LocalScheduler: Remove TaskSet 4.0 from pool 
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Completed ResultTask(4, 0)
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Stage 4 (count at <console>:15) finished in 0.040 s
13/07/28 00:22:27 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.042293272 s
res4: Long = 100002

scala> s.count()
13/07/28 00:22:27 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Got job 5 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Final stage: Stage 5 (count at <console>:15)
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Submitting Stage 5 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 5 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:27 INFO local.LocalTaskSetManager: Size of task 5 is 1498 bytes
13/07/28 00:22:27 INFO local.LocalScheduler: Running 5
13/07/28 00:22:27 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:27 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:27 INFO local.LocalScheduler: Finished 5
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Completed ResultTask(5, 0)
13/07/28 00:22:27 INFO local.LocalScheduler: Remove TaskSet 5.0 from pool 
13/07/28 00:22:27 INFO scheduler.DAGScheduler: Stage 5 (count at <console>:15) finished in 0.034 s
13/07/28 00:22:27 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.036490482 s
res5: Long = 100002

scala> s.count()
13/07/28 00:22:28 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Got job 6 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Final stage: Stage 6 (count at <console>:15)
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Submitting Stage 6 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 6 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:28 INFO local.LocalTaskSetManager: Size of task 6 is 1498 bytes
13/07/28 00:22:28 INFO local.LocalScheduler: Running 6
13/07/28 00:22:28 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:28 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:28 INFO local.LocalScheduler: Finished 6
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Completed ResultTask(6, 0)
13/07/28 00:22:28 INFO local.LocalScheduler: Remove TaskSet 6.0 from pool 
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Stage 6 (count at <console>:15) finished in 0.032 s
13/07/28 00:22:28 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.035540962 s
res6: Long = 100002

scala> s.count()
13/07/28 00:22:28 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Got job 7 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Final stage: Stage 7 (count at <console>:15)
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Submitting Stage 7 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 7 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:28 INFO local.LocalTaskSetManager: Size of task 7 is 1498 bytes
13/07/28 00:22:28 INFO local.LocalScheduler: Running 7
13/07/28 00:22:28 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:28 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:28 INFO local.LocalScheduler: Finished 7
13/07/28 00:22:28 INFO local.LocalScheduler: Remove TaskSet 7.0 from pool 
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Completed ResultTask(7, 0)
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Stage 7 (count at <console>:15) finished in 0.036 s
13/07/28 00:22:28 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.039488088 s
res7: Long = 100002

scala> s.count()
13/07/28 00:22:28 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Got job 8 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Final stage: Stage 8 (count at <console>:15)
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Submitting Stage 8 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 8 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:28 INFO local.LocalTaskSetManager: Size of task 8 is 1498 bytes
13/07/28 00:22:28 INFO local.LocalScheduler: Running 8
13/07/28 00:22:28 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:28 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:28 INFO local.LocalScheduler: Finished 8
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Completed ResultTask(8, 0)
13/07/28 00:22:28 INFO local.LocalScheduler: Remove TaskSet 8.0 from pool 
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Stage 8 (count at <console>:15) finished in 0.033 s
13/07/28 00:22:28 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.036086408 s
res8: Long = 100002

scala> s.count()
13/07/28 00:22:28 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Got job 9 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Final stage: Stage 9 (count at <console>:15)
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Submitting Stage 9 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 9 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:28 INFO local.LocalTaskSetManager: Size of task 9 is 1498 bytes
13/07/28 00:22:28 INFO local.LocalScheduler: Running 9
13/07/28 00:22:28 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:28 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:28 INFO local.LocalScheduler: Finished 9
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Completed ResultTask(9, 0)
13/07/28 00:22:28 INFO local.LocalScheduler: Remove TaskSet 9.0 from pool 
13/07/28 00:22:28 INFO scheduler.DAGScheduler: Stage 9 (count at <console>:15) finished in 0.034 s
13/07/28 00:22:28 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.036645978 s
res9: Long = 100002

scala> s.count()
13/07/28 00:22:29 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:29 INFO scheduler.DAGScheduler: Got job 10 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:29 INFO scheduler.DAGScheduler: Final stage: Stage 10 (count at <console>:15)
13/07/28 00:22:29 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:29 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:29 INFO scheduler.DAGScheduler: Submitting Stage 10 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:29 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 10 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:29 INFO local.LocalTaskSetManager: Size of task 10 is 1498 bytes
13/07/28 00:22:29 INFO local.LocalScheduler: Running 10
13/07/28 00:22:29 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:29 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:22:29 INFO local.LocalScheduler: Finished 10
13/07/28 00:22:29 INFO scheduler.DAGScheduler: Completed ResultTask(10, 0)
13/07/28 00:22:29 INFO local.LocalScheduler: Remove TaskSet 10.0 from pool 
13/07/28 00:22:29 INFO scheduler.DAGScheduler: Stage 10 (count at <console>:15) finished in 0.027 s
13/07/28 00:22:29 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.030886155 s
res10: Long = 100002

scala> 13/07/28 00:22:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:22:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:22:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:22:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:22:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:22:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:22:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:22:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count
25034 tachyon.Master
25061 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/28 00:22:31 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:22:32 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:41419
Creating SparkContext...
13/07/28 00:22:41 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/28 00:22:42 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/28 00:22:42 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/28 00:22:42 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130728002242-682e
13/07/28 00:22:42 INFO network.ConnectionManager: Bound socket to port 57716 with id = ConnectionManagerId(tachyon-ec2-0,57716)
13/07/28 00:22:42 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/28 00:22:42 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:57716 with 1295.4 MB RAM
13/07/28 00:22:42 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/28 00:22:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:22:42 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:42696
13/07/28 00:22:42 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:42696
13/07/28 00:22:42 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/28 00:22:42 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-254b342f-ef41-49ce-9b86-713388f2e017
13/07/28 00:22:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:22:42 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:36078
13/07/28 00:22:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/28 00:22:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/28 00:22:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:22:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:22:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:22:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:22:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:22:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:22:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:22:42 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/28 00:22:42 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("s3n://2012-05-19-sample/hit_data.tsv.500000").cache()
13/07/28 00:22:43 INFO storage.MemoryStore: ensureFreeSpace(58415) called with curMem=0, maxMem=1358297825
13/07/28 00:22:43 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/28 00:22:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/28 00:22:43 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/28 00:22:44 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/28 00:22:44 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:22:44 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:22:44 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/28 00:22:44 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:22:44 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:22:44 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:22:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:22:44 INFO local.LocalTaskSetManager: Size of task 0 is 1497 bytes
13/07/28 00:22:45 INFO local.LocalScheduler: Running 0
13/07/28 00:22:45 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:22:45 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/28 00:22:45 INFO s3native.NativeS3FileSystem: Opening 's3n://2012-05-19-sample/hit_data.tsv.500000' for reading
13/07/28 00:22:45 INFO s3native.NativeS3FileSystem: Opening key 'hit_data.tsv.500000' for reading at position '0'
13/07/28 00:23:17 INFO storage.MemoryStore: ensureFreeSpace(1288783830) called with curMem=58415, maxMem=1358297825
13/07/28 00:23:17 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1229.1 MB, free 66.2 MB)
13/07/28 00:23:17 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:57716 (size: 1229.1 MB, free: 66.3 MB)
13/07/28 00:23:17 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/28 00:23:17 INFO local.LocalScheduler: Finished 0
13/07/28 00:23:17 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 32.193 s
13/07/28 00:23:17 INFO spark.SparkContext: Job finished: count at <console>:15, took 32.245582851 s
res0: Long = 500094

scala> s.count()
13/07/28 00:23:17 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Final stage: Stage 1 (count at <console>:15)
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:23:17 INFO local.LocalTaskSetManager: Size of task 1 is 1498 bytes
13/07/28 00:23:17 INFO local.LocalScheduler: Running 1
13/07/28 00:23:17 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:23:17 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:23:17 INFO local.LocalScheduler: Finished 1
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Completed ResultTask(1, 0)
13/07/28 00:23:17 INFO local.LocalScheduler: Remove TaskSet 1.0 from pool 
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Stage 1 (count at <console>:15) finished in 0.054 s
13/07/28 00:23:17 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.056824165 s
res1: Long = 500094

scala> s.count()
13/07/28 00:23:17 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Final stage: Stage 2 (count at <console>:15)
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:23:17 INFO local.LocalTaskSetManager: Size of task 2 is 1498 bytes
13/07/28 00:23:17 INFO local.LocalScheduler: Running 2
13/07/28 00:23:17 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:23:17 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:23:17 INFO local.LocalScheduler: Finished 2
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Completed ResultTask(2, 0)
13/07/28 00:23:17 INFO local.LocalScheduler: Remove TaskSet 2.0 from pool 
13/07/28 00:23:17 INFO scheduler.DAGScheduler: Stage 2 (count at <console>:15) finished in 0.044 s
13/07/28 00:23:17 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.046939501 s
res2: Long = 500094

scala> s.count()
13/07/28 00:23:18 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Final stage: Stage 3 (count at <console>:15)
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:23:18 INFO local.LocalTaskSetManager: Size of task 3 is 1498 bytes
13/07/28 00:23:18 INFO local.LocalScheduler: Running 3
13/07/28 00:23:18 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:23:18 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:23:18 INFO local.LocalScheduler: Finished 3
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Completed ResultTask(3, 0)
13/07/28 00:23:18 INFO local.LocalScheduler: Remove TaskSet 3.0 from pool 
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Stage 3 (count at <console>:15) finished in 0.043 s
13/07/28 00:23:18 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.046616665 s
res3: Long = 500094

scala> s.count()
13/07/28 00:23:18 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Final stage: Stage 4 (count at <console>:15)
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:23:18 INFO local.LocalTaskSetManager: Size of task 4 is 1498 bytes
13/07/28 00:23:18 INFO local.LocalScheduler: Running 4
13/07/28 00:23:18 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:23:18 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:23:18 INFO local.LocalScheduler: Finished 4
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Completed ResultTask(4, 0)
13/07/28 00:23:18 INFO local.LocalScheduler: Remove TaskSet 4.0 from pool 
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Stage 4 (count at <console>:15) finished in 0.039 s
13/07/28 00:23:18 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.04163129 s
res4: Long = 500094

scala> s.count()
13/07/28 00:23:18 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Got job 5 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Final stage: Stage 5 (count at <console>:15)
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Submitting Stage 5 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 5 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:23:18 INFO local.LocalTaskSetManager: Size of task 5 is 1498 bytes
13/07/28 00:23:18 INFO local.LocalScheduler: Running 5
13/07/28 00:23:18 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:23:18 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:23:18 INFO local.LocalScheduler: Finished 5
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Completed ResultTask(5, 0)
13/07/28 00:23:18 INFO local.LocalScheduler: Remove TaskSet 5.0 from pool 
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Stage 5 (count at <console>:15) finished in 0.037 s
13/07/28 00:23:18 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.040517755 s
res5: Long = 500094

scala> s.count()
13/07/28 00:23:18 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Got job 6 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Final stage: Stage 6 (count at <console>:15)
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Submitting Stage 6 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 6 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:23:18 INFO local.LocalTaskSetManager: Size of task 6 is 1498 bytes
13/07/28 00:23:18 INFO local.LocalScheduler: Running 6
13/07/28 00:23:18 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:23:18 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:23:18 INFO local.LocalScheduler: Finished 6
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Completed ResultTask(6, 0)
13/07/28 00:23:18 INFO local.LocalScheduler: Remove TaskSet 6.0 from pool 
13/07/28 00:23:18 INFO scheduler.DAGScheduler: Stage 6 (count at <console>:15) finished in 0.036 s
13/07/28 00:23:18 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.038475063 s
res6: Long = 500094

scala> s.count()
13/07/28 00:23:19 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Got job 7 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Final stage: Stage 7 (count at <console>:15)
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Submitting Stage 7 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 7 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:23:19 INFO local.LocalTaskSetManager: Size of task 7 is 1498 bytes
13/07/28 00:23:19 INFO local.LocalScheduler: Running 7
13/07/28 00:23:19 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:23:19 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:23:19 INFO local.LocalScheduler: Finished 7
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Completed ResultTask(7, 0)
13/07/28 00:23:19 INFO local.LocalScheduler: Remove TaskSet 7.0 from pool 
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Stage 7 (count at <console>:15) finished in 0.039 s
13/07/28 00:23:19 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.041480218 s
res7: Long = 500094

scala> s.count()
13/07/28 00:23:19 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Got job 8 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Final stage: Stage 8 (count at <console>:15)
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Submitting Stage 8 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 8 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:23:19 INFO local.LocalTaskSetManager: Size of task 8 is 1498 bytes
13/07/28 00:23:19 INFO local.LocalScheduler: Running 8
13/07/28 00:23:19 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:23:19 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:23:19 INFO local.LocalScheduler: Finished 8
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Completed ResultTask(8, 0)
13/07/28 00:23:19 INFO local.LocalScheduler: Remove TaskSet 8.0 from pool 
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Stage 8 (count at <console>:15) finished in 0.036 s
13/07/28 00:23:19 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.039787908 s
res8: Long = 500094

scala> s.count()
13/07/28 00:23:19 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Got job 9 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Final stage: Stage 9 (count at <console>:15)
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Submitting Stage 9 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 9 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:23:19 INFO local.LocalTaskSetManager: Size of task 9 is 1498 bytes
13/07/28 00:23:19 INFO local.LocalScheduler: Running 9
13/07/28 00:23:19 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:23:19 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:23:19 INFO local.LocalScheduler: Finished 9
13/07/28 00:23:19 INFO local.LocalScheduler: Remove TaskSet 9.0 from pool 
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Completed ResultTask(9, 0)
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Stage 9 (count at <console>:15) finished in 0.038 s
13/07/28 00:23:19 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.041006705 s
res9: Long = 500094

scala> s.count()
13/07/28 00:23:19 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Got job 10 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Final stage: Stage 10 (count at <console>:15)
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Submitting Stage 10 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/28 00:23:19 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 10 (MappedRDD[1] at textFile at <console>:12)
13/07/28 00:23:19 INFO local.LocalTaskSetManager: Size of task 10 is 1498 bytes
13/07/28 00:23:19 INFO local.LocalScheduler: Running 10
13/07/28 00:23:20 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/28 00:23:20 INFO spark.CacheManager: Found partition in cache!
13/07/28 00:23:20 INFO local.LocalScheduler: Finished 10
13/07/28 00:23:20 INFO scheduler.DAGScheduler: Completed ResultTask(10, 0)
13/07/28 00:23:20 INFO local.LocalScheduler: Remove TaskSet 10.0 from pool 
13/07/28 00:23:20 INFO scheduler.DAGScheduler: Stage 10 (count at <console>:15) finished in 0.030 s
13/07/28 00:23:20 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.03228354 s
res10: Long = 500094

scala> 13/07/28 00:23:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/28 00:23:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/28 00:23:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/28 00:23:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/28 00:23:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/28 00:23:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/28 00:23:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/28 00:23:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
