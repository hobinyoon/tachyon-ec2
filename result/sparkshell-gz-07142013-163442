run #: 0

spark-shell count

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-163503.708 SS Slf4jEventHandler started
0714-163504.423 SS Registered BlockManagerMaster Actor
0714-163504.548 SS MemoryStore started with capacity 326.7 MB.
0714-163504.571 SS Created local directory at /tmp/spark-local-20130714163504-6ec7
0714-163504.662 SS Bound socket to port 51902 with id = ConnectionManagerId(tachyon-ec2-0,51902)
0714-163504.693 SS Trying to register BlockManager
0714-163504.698 SS Registering block manager tachyon-ec2-0:51902 with 326.7 MB RAM
0714-163504.700 SS Registered BlockManager
0714-163504.766 SS Broadcast server started at http://10.190.33.193:36850
0714-163504.781 SS Registered MapOutputTrackerActor actor
0714-163504.804 SS HTTP File server directory is /tmp/spark-acd6156f-acdb-4d85-8d09-212a8be0ff57
0714-163505.318 SS IoWorker thread 'spray-io-worker-0' started
0714-163506.573 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:33796
0714-163506.576 SS Started BlockManager web UI at http://tachyon-ec2-0:33796
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/data/hit_data.tsv.100.gz")
0714-163509.368 SS ensureFreeSpace(58415) called with curMem=0, maxMem=342526525
0714-163509.373 SS Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-163510.063 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-163510.063 SS Snappy native library not loaded
0714-163510.098 SS Total input paths to process : 1
0714-163510.139 SS Starting job: count at <console>:15
0714-163510.161 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163510.171 SS Final stage: Stage 0 (textFile at <console>:12)
0714-163510.173 SS Parents of final stage: List()
0714-163510.187 SS Missing parents: List()
0714-163510.198 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163510.215 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-163510.224 SS Running ResultTask(0, 0)
0714-163510.410 SS Size of task 0 is 1427 bytes
0714-163510.601 SS Got brand-new decompressor
0714-163510.690 SS Finished ResultTask(0, 0)
0714-163510.693 SS Completed ResultTask(0, 0)
0714-163510.696 SS Stage 0 (textFile at <console>:12) finished in 0.472 s
0714-163510.698 SS Job finished: count at <console>:15, took 0.558389905 s
res0: Long = 100

scala> s.count()
0714-163511.359 SS Starting job: count at <console>:15
0714-163511.360 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163511.360 SS Final stage: Stage 1 (textFile at <console>:12)
0714-163511.360 SS Parents of final stage: List()
0714-163511.362 SS Missing parents: List()
0714-163511.362 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163511.363 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-163511.363 SS Running ResultTask(1, 0)
0714-163511.365 SS Size of task 0 is 1430 bytes
0714-163511.445 SS Got brand-new decompressor
0714-163511.455 SS Finished ResultTask(1, 0)
0714-163511.456 SS Completed ResultTask(1, 0)
0714-163511.456 SS Stage 1 (textFile at <console>:12) finished in 0.089 s
0714-163511.456 SS Job finished: count at <console>:15, took 0.096538912 s
res1: Long = 100

scala> s.count()
0714-163511.917 SS Starting job: count at <console>:15
0714-163511.918 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163511.918 SS Final stage: Stage 2 (textFile at <console>:12)
0714-163511.918 SS Parents of final stage: List()
0714-163511.920 SS Missing parents: List()
0714-163511.921 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163511.921 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-163511.922 SS Running ResultTask(2, 0)
0714-163511.924 SS Size of task 0 is 1430 bytes
0714-163511.999 SS Got brand-new decompressor
0714-163512.015 SS Finished ResultTask(2, 0)
0714-163512.016 SS Completed ResultTask(2, 0)
0714-163512.016 SS Stage 2 (textFile at <console>:12) finished in 0.092 s
0714-163512.016 SS Job finished: count at <console>:15, took 0.098326665 s
res2: Long = 100

scala> s.count()
0714-163512.666 SS Starting job: count at <console>:15
0714-163512.667 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163512.667 SS Final stage: Stage 3 (textFile at <console>:12)
0714-163512.667 SS Parents of final stage: List()
0714-163512.670 SS Missing parents: List()
0714-163512.670 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163512.671 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-163512.671 SS Running ResultTask(3, 0)
0714-163512.673 SS Size of task 0 is 1430 bytes
0714-163512.713 SS Got brand-new decompressor
0714-163512.715 SS Finished ResultTask(3, 0)
0714-163512.716 SS Completed ResultTask(3, 0)
0714-163512.716 SS Stage 3 (textFile at <console>:12) finished in 0.041 s
0714-163512.716 SS Job finished: count at <console>:15, took 0.049376115 s
res3: Long = 100

scala> s.count()
0714-163513.001 SS Starting job: count at <console>:15
0714-163513.001 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163513.002 SS Final stage: Stage 4 (textFile at <console>:12)
0714-163513.002 SS Parents of final stage: List()
0714-163513.003 SS Missing parents: List()
0714-163513.004 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163513.005 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-163513.005 SS Running ResultTask(4, 0)
0714-163513.007 SS Size of task 0 is 1430 bytes
0714-163513.049 SS Got brand-new decompressor
0714-163513.052 SS Finished ResultTask(4, 0)
0714-163513.052 SS Completed ResultTask(4, 0)
0714-163513.053 SS Stage 4 (textFile at <console>:12) finished in 0.045 s
0714-163513.053 SS Job finished: count at <console>:15, took 0.051485951 s
res4: Long = 100

scala> restaring tachyon
Killed 0 processes
Killed 0 processes
localhost: Killed 0 processes
Mounting ramfs on Linux...
TACHYON_RAM_FOLDER was not set. Using the default one: /mnt/ramdisk
Formatting RamFS: /mnt/ramdisk
Starting master @ localhost
Starting worker @ tachyon-ec2-0

spark-shell count
15805 tachyon.Master
15818 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-163534.944 SS Slf4jEventHandler started
0714-163535.632 SS Registered BlockManagerMaster Actor
0714-163535.679 SS MemoryStore started with capacity 326.7 MB.
0714-163535.691 SS Created local directory at /tmp/spark-local-20130714163535-9490
0714-163535.753 SS Bound socket to port 59501 with id = ConnectionManagerId(tachyon-ec2-0,59501)
0714-163535.778 SS Trying to register BlockManager
0714-163535.782 SS Registering block manager tachyon-ec2-0:59501 with 326.7 MB RAM
0714-163535.788 SS Registered BlockManager
0714-163535.860 SS Broadcast server started at http://10.190.33.193:56213
0714-163535.875 SS Registered MapOutputTrackerActor actor
0714-163535.883 SS HTTP File server directory is /tmp/spark-54a7721d-be73-4a2a-870b-1101fbec9189
0714-163536.328 SS IoWorker thread 'spray-io-worker-0' started
0714-163537.560 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:36900
0714-163537.562 SS Started BlockManager web UI at http://tachyon-ec2-0:36900
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("tachyon://localhost:19998/hit_data.tsv.100.gz")
0714-163540.197 SS ensureFreeSpace(58439) called with curMem=0, maxMem=342526525
0714-163540.199 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-163540.935 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-163540.936 SS Snappy native library not loaded
0714-163540.978 SS 15866 62 Thread-37 |        Trying to connect master @ localhost/127.0.0.1:19998
0714-163541.044 SS 15866 62 Thread-37 |          User registered at the master localhost/127.0.0.1:19998 got UserId 1
0714-163541.045 SS 15866 62 Thread-37 |        Trying to get local worker host : tachyon-ec2-0
0714-163541.065 SS 15866 62 Thread-37 |        Connecting local worker @ tachyon-ec2-0/10.190.33.193:29998
0714-163542.881 SS Total input paths to process : 1
0714-163545.163 SS Starting job: count at <console>:15
0714-163545.172 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163545.176 SS Final stage: Stage 0 (textFile at <console>:12)
0714-163545.176 SS Parents of final stage: List()
0714-163545.183 SS Missing parents: List()
0714-163545.185 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163545.191 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-163545.196 SS Running ResultTask(0, 0)
0714-163545.258 SS Size of task 0 is 1438 bytes
0714-163545.367 SS 15866 65 pool-1-thread-1 |          /mnt/ramdisk/tachyonworker/3 is not on local disk.
0714-163545.384 SS 15866 65 pool-1-thread-1 |          Try to find and read from remote workers.
0714-163545.548 SS 15866 65 pool-1-thread-1 |          fileLocations: [NetAddress(mHost:localhost, mPort:-1)]
0714-163545.658 SS Opening 's3n://2012-05-19-sample/hit_data.tsv.100.gz' for reading
0714-163545.800 SS 15866 65 pool-1-thread-1 |          Folder /mnt/ramdisk/tachyonworker/users/1 was created!
0714-163545.801 SS 15866 65 pool-1-thread-1 |        File /mnt/ramdisk/tachyonworker/users/1/3 was created!
0714-163545.889 SS Got brand-new decompressor
0714-163545.945 SS Finished ResultTask(0, 0)
0714-163545.950 SS Completed ResultTask(0, 0)
0714-163545.952 SS Stage 0 (textFile at <console>:12) finished in 0.756 s
0714-163545.954 SS Job finished: count at <console>:15, took 0.790091991 s
res0: Long = 100

scala> s.count()
0714-163546.350 SS Starting job: count at <console>:15
0714-163546.351 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163546.351 SS Final stage: Stage 1 (textFile at <console>:12)
0714-163546.351 SS Parents of final stage: List()
0714-163546.353 SS Missing parents: List()
0714-163546.354 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163546.354 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-163546.355 SS Running ResultTask(1, 0)
0714-163546.357 SS Size of task 0 is 1441 bytes
0714-163546.420 SS Got brand-new decompressor
0714-163546.425 SS Finished ResultTask(1, 0)
0714-163546.426 SS Completed ResultTask(1, 0)
0714-163546.426 SS Stage 1 (textFile at <console>:12) finished in 0.069 s
0714-163546.426 SS Job finished: count at <console>:15, took 0.075363334 s
res1: Long = 100

scala> s.count()
0714-163546.759 SS Starting job: count at <console>:15
0714-163546.760 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163546.760 SS Final stage: Stage 2 (textFile at <console>:12)
0714-163546.760 SS Parents of final stage: List()
0714-163546.762 SS Missing parents: List()
0714-163546.763 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163546.764 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-163546.764 SS Running ResultTask(2, 0)
0714-163546.766 SS Size of task 0 is 1441 bytes
0714-163546.809 SS Got brand-new decompressor
0714-163546.815 SS Finished ResultTask(2, 0)
0714-163546.815 SS Completed ResultTask(2, 0)
0714-163546.815 SS Stage 2 (textFile at <console>:12) finished in 0.048 s
0714-163546.816 SS Job finished: count at <console>:15, took 0.055988944 s
res2: Long = 100

scala> s.count()
0714-163547.323 SS Starting job: count at <console>:15
0714-163547.324 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163547.324 SS Final stage: Stage 3 (textFile at <console>:12)
0714-163547.324 SS Parents of final stage: List()
0714-163547.326 SS Missing parents: List()
0714-163547.327 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163547.327 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-163547.328 SS Running ResultTask(3, 0)
0714-163547.330 SS Size of task 0 is 1441 bytes
0714-163547.360 SS Got brand-new decompressor
0714-163547.366 SS Finished ResultTask(3, 0)
0714-163547.366 SS Completed ResultTask(3, 0)
0714-163547.367 SS Stage 3 (textFile at <console>:12) finished in 0.036 s
0714-163547.367 SS Job finished: count at <console>:15, took 0.043290375 s
res3: Long = 100

scala> s.count()
0714-163547.648 SS Starting job: count at <console>:15
0714-163547.649 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163547.649 SS Final stage: Stage 4 (textFile at <console>:12)
0714-163547.649 SS Parents of final stage: List()
0714-163547.651 SS Missing parents: List()
0714-163547.652 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163547.652 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-163547.653 SS Running ResultTask(4, 0)
0714-163547.655 SS Size of task 0 is 1441 bytes
0714-163547.685 SS Got brand-new decompressor
0714-163547.690 SS Finished ResultTask(4, 0)
0714-163547.691 SS Completed ResultTask(4, 0)
0714-163547.691 SS Stage 4 (textFile at <console>:12) finished in 0.036 s
0714-163547.691 SS Job finished: count at <console>:15, took 0.042587682 s
res4: Long = 100

scala> Killed 1 processes
Killed 1 processes
localhost: Killed 0 processes
Formatting Tachyon @ localhost
0714-163549.303 TU Deleting /mnt/tachyon/tachyon/tachyon_checkpoint.data
0714-163549.306 TU Deleting /mnt/tachyon/tachyon/tachyon_log.data
0714-163550.337 TU Formatting s3n://2012-05-19-sample/tachyon/data
0714-163551.675 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-163551.849 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-163551.872 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-163551.930 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-163551.962 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-163551.988 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-163552.035 TU Formatting s3n://2012-05-19-sample/tachyon/workers
0714-163552.073 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-163552.212 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-163552.234 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200
0714-163552.276 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-163552.322 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-163552.346 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200

spark-shell count

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-163609.923 SS Slf4jEventHandler started
0714-163610.592 SS Registered BlockManagerMaster Actor
0714-163610.657 SS MemoryStore started with capacity 326.7 MB.
0714-163610.667 SS Created local directory at /tmp/spark-local-20130714163610-ccc1
0714-163610.718 SS Bound socket to port 45175 with id = ConnectionManagerId(tachyon-ec2-0,45175)
0714-163610.742 SS Trying to register BlockManager
0714-163610.749 SS Registering block manager tachyon-ec2-0:45175 with 326.7 MB RAM
0714-163610.750 SS Registered BlockManager
0714-163610.795 SS Broadcast server started at http://10.190.33.193:37077
0714-163610.807 SS Registered MapOutputTrackerActor actor
0714-163610.826 SS HTTP File server directory is /tmp/spark-6e102d99-9908-46b8-9078-6db8096b6551
0714-163611.239 SS IoWorker thread 'spray-io-worker-0' started
0714-163612.407 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:57722
0714-163612.409 SS Started BlockManager web UI at http://tachyon-ec2-0:57722
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/data/hit_data.tsv.1000.gz")
0714-163614.978 SS ensureFreeSpace(58415) called with curMem=0, maxMem=342526525
0714-163614.980 SS Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-163615.588 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-163615.595 SS Snappy native library not loaded
0714-163615.613 SS Total input paths to process : 1
0714-163615.637 SS Starting job: count at <console>:15
0714-163615.649 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163615.649 SS Final stage: Stage 0 (textFile at <console>:12)
0714-163615.650 SS Parents of final stage: List()
0714-163615.659 SS Missing parents: List()
0714-163615.661 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163615.673 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-163615.690 SS Running ResultTask(0, 0)
0714-163615.906 SS Size of task 0 is 1428 bytes
0714-163616.098 SS Got brand-new decompressor
0714-163616.165 SS Finished ResultTask(0, 0)
0714-163616.167 SS Completed ResultTask(0, 0)
0714-163616.169 SS Stage 0 (textFile at <console>:12) finished in 0.479 s
0714-163616.171 SS Job finished: count at <console>:15, took 0.533508717 s
res0: Long = 1000

scala> s.count()
0714-163616.578 SS Starting job: count at <console>:15
0714-163616.580 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163616.580 SS Final stage: Stage 1 (textFile at <console>:12)
0714-163616.580 SS Parents of final stage: List()
0714-163616.581 SS Missing parents: List()
0714-163616.581 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163616.582 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-163616.582 SS Running ResultTask(1, 0)
0714-163616.584 SS Size of task 0 is 1431 bytes
0714-163616.661 SS Got brand-new decompressor
0714-163616.700 SS Finished ResultTask(1, 0)
0714-163616.700 SS Completed ResultTask(1, 0)
0714-163616.701 SS Stage 1 (textFile at <console>:12) finished in 0.116 s
0714-163616.701 SS Job finished: count at <console>:15, took 0.121470918 s
res1: Long = 1000

scala> s.count()
0714-163617.022 SS Starting job: count at <console>:15
0714-163617.023 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163617.023 SS Final stage: Stage 2 (textFile at <console>:12)
0714-163617.023 SS Parents of final stage: List()
0714-163617.024 SS Missing parents: List()
0714-163617.024 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163617.025 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-163617.025 SS Running ResultTask(2, 0)
0714-163617.027 SS Size of task 0 is 1431 bytes
0714-163617.103 SS Got brand-new decompressor
0714-163617.164 SS Finished ResultTask(2, 0)
0714-163617.164 SS Completed ResultTask(2, 0)
0714-163617.164 SS Stage 2 (textFile at <console>:12) finished in 0.137 s
0714-163617.164 SS Job finished: count at <console>:15, took 0.142003923 s
res2: Long = 1000

scala> s.count()
0714-163617.864 SS Starting job: count at <console>:15
0714-163617.864 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163617.864 SS Final stage: Stage 3 (textFile at <console>:12)
0714-163617.864 SS Parents of final stage: List()
0714-163617.866 SS Missing parents: List()
0714-163617.867 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163617.867 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-163617.867 SS Running ResultTask(3, 0)
0714-163617.869 SS Size of task 0 is 1431 bytes
0714-163617.902 SS Got brand-new decompressor
0714-163617.917 SS Finished ResultTask(3, 0)
0714-163617.917 SS Completed ResultTask(3, 0)
0714-163617.917 SS Stage 3 (textFile at <console>:12) finished in 0.047 s
0714-163617.918 SS Job finished: count at <console>:15, took 0.053460166 s
res3: Long = 1000

scala> s.count()
0714-163618.235 SS Starting job: count at <console>:15
0714-163618.235 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163618.235 SS Final stage: Stage 4 (textFile at <console>:12)
0714-163618.236 SS Parents of final stage: List()
0714-163618.237 SS Missing parents: List()
0714-163618.237 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163618.238 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-163618.238 SS Running ResultTask(4, 0)
0714-163618.240 SS Size of task 0 is 1431 bytes
0714-163618.296 SS Got brand-new decompressor
0714-163618.312 SS Finished ResultTask(4, 0)
0714-163618.313 SS Completed ResultTask(4, 0)
0714-163618.313 SS Stage 4 (textFile at <console>:12) finished in 0.071 s
0714-163618.313 SS Job finished: count at <console>:15, took 0.07813595 s
res4: Long = 1000

scala> restaring tachyon
Killed 0 processes
Killed 0 processes
localhost: Killed 0 processes
Mounting ramfs on Linux...
TACHYON_RAM_FOLDER was not set. Using the default one: /mnt/ramdisk
Formatting RamFS: /mnt/ramdisk
Starting master @ localhost
Starting worker @ tachyon-ec2-0

spark-shell count
16454 tachyon.Master
16467 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-163639.501 SS Slf4jEventHandler started
0714-163640.180 SS Registered BlockManagerMaster Actor
0714-163640.245 SS MemoryStore started with capacity 326.7 MB.
0714-163640.255 SS Created local directory at /tmp/spark-local-20130714163640-bd4e
0714-163640.307 SS Bound socket to port 42128 with id = ConnectionManagerId(tachyon-ec2-0,42128)
0714-163640.334 SS Trying to register BlockManager
0714-163640.337 SS Registering block manager tachyon-ec2-0:42128 with 326.7 MB RAM
0714-163640.338 SS Registered BlockManager
0714-163640.384 SS Broadcast server started at http://10.190.33.193:32894
0714-163640.396 SS Registered MapOutputTrackerActor actor
0714-163640.407 SS HTTP File server directory is /tmp/spark-fba6fed1-5953-4eb2-bbf4-6e5fdcb523a1
0714-163640.836 SS IoWorker thread 'spray-io-worker-0' started
0714-163642.032 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:60070
0714-163642.034 SS Started BlockManager web UI at http://tachyon-ec2-0:60070
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("tachyon://localhost:19998/hit_data.tsv.1000.gz")
0714-163644.685 SS ensureFreeSpace(58439) called with curMem=0, maxMem=342526525
0714-163644.688 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-163645.325 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-163645.325 SS Snappy native library not loaded
0714-163645.363 SS 16515 61 Thread-37 |        Trying to connect master @ localhost/127.0.0.1:19998
0714-163645.428 SS 16515 61 Thread-37 |          User registered at the master localhost/127.0.0.1:19998 got UserId 1
0714-163645.428 SS 16515 61 Thread-37 |        Trying to get local worker host : tachyon-ec2-0
0714-163645.443 SS 16515 61 Thread-37 |        Connecting local worker @ tachyon-ec2-0/10.190.33.193:29998
0714-163647.109 SS Total input paths to process : 1
0714-163649.421 SS Starting job: count at <console>:15
0714-163649.432 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163649.433 SS Final stage: Stage 0 (textFile at <console>:12)
0714-163649.433 SS Parents of final stage: List()
0714-163649.447 SS Missing parents: List()
0714-163649.456 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163649.466 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-163649.474 SS Running ResultTask(0, 0)
0714-163649.533 SS Size of task 0 is 1439 bytes
0714-163649.666 SS 16515 64 pool-1-thread-1 |          /mnt/ramdisk/tachyonworker/2 is not on local disk.
0714-163649.675 SS 16515 64 pool-1-thread-1 |          Try to find and read from remote workers.
0714-163649.796 SS 16515 64 pool-1-thread-1 |          fileLocations: [NetAddress(mHost:localhost, mPort:-1)]
0714-163649.972 SS Opening 's3n://2012-05-19-sample/hit_data.tsv.1000.gz' for reading
0714-163650.044 SS 16515 64 pool-1-thread-1 |          Folder /mnt/ramdisk/tachyonworker/users/1 was created!
0714-163650.046 SS 16515 64 pool-1-thread-1 |        File /mnt/ramdisk/tachyonworker/users/1/2 was created!
0714-163650.247 SS Got brand-new decompressor
0714-163650.355 SS Finished ResultTask(0, 0)
0714-163650.359 SS Completed ResultTask(0, 0)
0714-163650.362 SS Stage 0 (textFile at <console>:12) finished in 0.888 s
0714-163650.363 SS Job finished: count at <console>:15, took 0.941856359 s
res0: Long = 1000

scala> s.count()
0714-163650.772 SS Starting job: count at <console>:15
0714-163650.773 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163650.773 SS Final stage: Stage 1 (textFile at <console>:12)
0714-163650.773 SS Parents of final stage: List()
0714-163650.780 SS Missing parents: List()
0714-163650.780 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163650.780 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-163650.781 SS Running ResultTask(1, 0)
0714-163650.782 SS Size of task 0 is 1442 bytes
0714-163650.874 SS Got brand-new decompressor
0714-163650.897 SS Finished ResultTask(1, 0)
0714-163650.897 SS Completed ResultTask(1, 0)
0714-163650.898 SS Stage 1 (textFile at <console>:12) finished in 0.114 s
0714-163650.898 SS Job finished: count at <console>:15, took 0.124732904 s
res1: Long = 1000

scala> s.count()
0714-163651.187 SS Starting job: count at <console>:15
0714-163651.187 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163651.187 SS Final stage: Stage 2 (textFile at <console>:12)
0714-163651.187 SS Parents of final stage: List()
0714-163651.189 SS Missing parents: List()
0714-163651.189 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163651.190 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-163651.190 SS Running ResultTask(2, 0)
0714-163651.192 SS Size of task 0 is 1442 bytes
0714-163651.229 SS Got brand-new decompressor
0714-163651.254 SS Finished ResultTask(2, 0)
0714-163651.254 SS Completed ResultTask(2, 0)
0714-163651.255 SS Stage 2 (textFile at <console>:12) finished in 0.063 s
0714-163651.255 SS Job finished: count at <console>:15, took 0.067968947 s
res2: Long = 1000

scala> s.count()
0714-163651.765 SS Starting job: count at <console>:15
0714-163651.766 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163651.766 SS Final stage: Stage 3 (textFile at <console>:12)
0714-163651.766 SS Parents of final stage: List()
0714-163651.767 SS Missing parents: List()
0714-163651.768 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163651.768 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-163651.768 SS Running ResultTask(3, 0)
0714-163651.770 SS Size of task 0 is 1442 bytes
0714-163651.800 SS Got brand-new decompressor
0714-163651.845 SS Finished ResultTask(3, 0)
0714-163651.846 SS Completed ResultTask(3, 0)
0714-163651.846 SS Stage 3 (textFile at <console>:12) finished in 0.075 s
0714-163651.846 SS Job finished: count at <console>:15, took 0.080684888 s
res3: Long = 1000

scala> s.count()
0714-163652.221 SS Starting job: count at <console>:15
0714-163652.221 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163652.222 SS Final stage: Stage 4 (textFile at <console>:12)
0714-163652.222 SS Parents of final stage: List()
0714-163652.223 SS Missing parents: List()
0714-163652.223 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163652.223 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-163652.224 SS Running ResultTask(4, 0)
0714-163652.225 SS Size of task 0 is 1442 bytes
0714-163652.255 SS Got brand-new decompressor
0714-163652.275 SS Finished ResultTask(4, 0)
0714-163652.275 SS Completed ResultTask(4, 0)
0714-163652.276 SS Stage 4 (textFile at <console>:12) finished in 0.049 s
0714-163652.276 SS Job finished: count at <console>:15, took 0.054692756 s
res4: Long = 1000

scala> Killed 1 processes
Killed 1 processes
localhost: Killed 0 processes
Formatting Tachyon @ localhost
0714-163653.883 TU Deleting /mnt/tachyon/tachyon/tachyon_checkpoint.data
0714-163653.889 TU Deleting /mnt/tachyon/tachyon/tachyon_log.data
0714-163654.893 TU Formatting s3n://2012-05-19-sample/tachyon/data
0714-163656.259 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-163656.403 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-163656.418 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-163656.455 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-163656.486 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-163656.503 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-163656.556 TU Formatting s3n://2012-05-19-sample/tachyon/workers
0714-163656.571 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-163656.690 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-163656.704 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200
0714-163656.756 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-163656.802 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-163656.824 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200

spark-shell count

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-163750.294 SS Slf4jEventHandler started
0714-163750.960 SS Registered BlockManagerMaster Actor
0714-163751.026 SS MemoryStore started with capacity 326.7 MB.
0714-163751.031 SS Created local directory at /tmp/spark-local-20130714163751-eebd
0714-163751.090 SS Bound socket to port 42805 with id = ConnectionManagerId(tachyon-ec2-0,42805)
0714-163751.114 SS Trying to register BlockManager
0714-163751.118 SS Registering block manager tachyon-ec2-0:42805 with 326.7 MB RAM
0714-163751.119 SS Registered BlockManager
0714-163751.164 SS Broadcast server started at http://10.190.33.193:46925
0714-163751.176 SS Registered MapOutputTrackerActor actor
0714-163751.188 SS HTTP File server directory is /tmp/spark-bedda606-bb45-4163-9ccd-dd24292db4e2
0714-163751.621 SS IoWorker thread 'spray-io-worker-0' started
0714-163752.805 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:35023
0714-163752.807 SS Started BlockManager web UI at http://tachyon-ec2-0:35023
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/data/hit_data.tsv.10000.gz")
0714-163755.266 SS ensureFreeSpace(58415) called with curMem=0, maxMem=342526525
0714-163755.269 SS Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-163755.916 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-163755.916 SS Snappy native library not loaded
0714-163755.939 SS Total input paths to process : 1
0714-163755.964 SS Starting job: count at <console>:15
0714-163755.976 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163755.977 SS Final stage: Stage 0 (textFile at <console>:12)
0714-163755.977 SS Parents of final stage: List()
0714-163755.986 SS Missing parents: List()
0714-163755.989 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163756.002 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-163756.018 SS Running ResultTask(0, 0)
0714-163756.247 SS Size of task 0 is 1429 bytes
0714-163756.432 SS Got brand-new decompressor
0714-163756.828 SS Finished ResultTask(0, 0)
0714-163756.836 SS Completed ResultTask(0, 0)
0714-163756.841 SS Stage 0 (textFile at <console>:12) finished in 0.822 s
0714-163756.842 SS Job finished: count at <console>:15, took 0.877789707 s
res0: Long = 10000

scala> s.count()
0714-163757.332 SS Starting job: count at <console>:15
0714-163757.333 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163757.333 SS Final stage: Stage 1 (textFile at <console>:12)
0714-163757.333 SS Parents of final stage: List()
0714-163757.335 SS Missing parents: List()
0714-163757.335 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163757.336 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-163757.336 SS Running ResultTask(1, 0)
0714-163757.338 SS Size of task 0 is 1432 bytes
0714-163757.408 SS Got brand-new decompressor
0714-163757.557 SS Finished ResultTask(1, 0)
0714-163757.558 SS Completed ResultTask(1, 0)
0714-163757.558 SS Stage 1 (textFile at <console>:12) finished in 0.219 s
0714-163757.558 SS Job finished: count at <console>:15, took 0.225890704 s
res1: Long = 10000

scala> s.count()
0714-163757.905 SS Starting job: count at <console>:15
0714-163757.906 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163757.906 SS Final stage: Stage 2 (textFile at <console>:12)
0714-163757.906 SS Parents of final stage: List()
0714-163757.908 SS Missing parents: List()
0714-163757.909 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163757.909 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-163757.910 SS Running ResultTask(2, 0)
0714-163757.912 SS Size of task 0 is 1432 bytes
0714-163757.983 SS Got brand-new decompressor
0714-163758.209 SS Finished ResultTask(2, 0)
0714-163758.211 SS Completed ResultTask(2, 0)
0714-163758.212 SS Stage 2 (textFile at <console>:12) finished in 0.299 s
0714-163758.212 SS Job finished: count at <console>:15, took 0.306091971 s
res2: Long = 10000

scala> s.count()
0714-163758.761 SS Starting job: count at <console>:15
0714-163758.762 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163758.762 SS Final stage: Stage 3 (textFile at <console>:12)
0714-163758.762 SS Parents of final stage: List()
0714-163758.764 SS Missing parents: List()
0714-163758.765 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163758.765 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-163758.766 SS Running ResultTask(3, 0)
0714-163758.768 SS Size of task 0 is 1432 bytes
0714-163758.800 SS Got brand-new decompressor
0714-163758.923 SS Finished ResultTask(3, 0)
0714-163758.924 SS Completed ResultTask(3, 0)
0714-163758.924 SS Stage 3 (textFile at <console>:12) finished in 0.156 s
0714-163758.925 SS Job finished: count at <console>:15, took 0.162838816 s
res3: Long = 10000

scala> s.count()
0714-163759.209 SS Starting job: count at <console>:15
0714-163759.210 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163759.210 SS Final stage: Stage 4 (textFile at <console>:12)
0714-163759.210 SS Parents of final stage: List()
0714-163759.212 SS Missing parents: List()
0714-163759.213 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163759.213 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-163759.214 SS Running ResultTask(4, 0)
0714-163759.216 SS Size of task 0 is 1432 bytes
0714-163759.262 SS Got brand-new decompressor
0714-163759.391 SS Finished ResultTask(4, 0)
0714-163759.392 SS Completed ResultTask(4, 0)
0714-163759.392 SS Stage 4 (textFile at <console>:12) finished in 0.176 s
0714-163759.392 SS Job finished: count at <console>:15, took 0.182385377 s
res4: Long = 10000

scala> restaring tachyon
Killed 0 processes
Killed 0 processes
localhost: Killed 0 processes
Mounting ramfs on Linux...
TACHYON_RAM_FOLDER was not set. Using the default one: /mnt/ramdisk
Formatting RamFS: /mnt/ramdisk
Starting master @ localhost
Starting worker @ tachyon-ec2-0

spark-shell count
17100 tachyon.Master
17113 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-163820.611 SS Slf4jEventHandler started
0714-163821.280 SS Registered BlockManagerMaster Actor
0714-163821.350 SS MemoryStore started with capacity 326.7 MB.
0714-163821.355 SS Created local directory at /tmp/spark-local-20130714163821-f32c
0714-163821.444 SS Bound socket to port 53708 with id = ConnectionManagerId(tachyon-ec2-0,53708)
0714-163821.464 SS Trying to register BlockManager
0714-163821.469 SS Registering block manager tachyon-ec2-0:53708 with 326.7 MB RAM
0714-163821.470 SS Registered BlockManager
0714-163821.520 SS Broadcast server started at http://10.190.33.193:33233
0714-163821.530 SS Registered MapOutputTrackerActor actor
0714-163821.538 SS HTTP File server directory is /tmp/spark-d4a0a057-639e-4b9a-9eed-eda5a67ca1e1
0714-163821.948 SS IoWorker thread 'spray-io-worker-0' started
0714-163823.141 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:40128
0714-163823.143 SS Started BlockManager web UI at http://tachyon-ec2-0:40128
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("tachyon://localhost:19998/hit_data.tsv.10000.gz")
0714-163825.772 SS ensureFreeSpace(58439) called with curMem=0, maxMem=342526525
0714-163825.775 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-163826.468 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-163826.469 SS Snappy native library not loaded
0714-163826.527 SS 17161 62 Thread-37 |        Trying to connect master @ localhost/127.0.0.1:19998
0714-163826.588 SS 17161 62 Thread-37 |          User registered at the master localhost/127.0.0.1:19998 got UserId 1
0714-163826.588 SS 17161 62 Thread-37 |        Trying to get local worker host : tachyon-ec2-0
0714-163826.604 SS 17161 62 Thread-37 |        Connecting local worker @ tachyon-ec2-0/10.190.33.193:29998
0714-163828.250 SS Total input paths to process : 1
0714-163830.535 SS Starting job: count at <console>:15
0714-163830.550 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163830.556 SS Final stage: Stage 0 (textFile at <console>:12)
0714-163830.556 SS Parents of final stage: List()
0714-163830.570 SS Missing parents: List()
0714-163830.572 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163830.585 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-163830.591 SS Running ResultTask(0, 0)
0714-163830.654 SS Size of task 0 is 1440 bytes
0714-163830.751 SS 17161 65 pool-1-thread-1 |          /mnt/ramdisk/tachyonworker/2 is not on local disk.
0714-163830.760 SS 17161 65 pool-1-thread-1 |          Try to find and read from remote workers.
0714-163830.882 SS 17161 65 pool-1-thread-1 |          fileLocations: [NetAddress(mHost:localhost, mPort:-1)]
0714-163831.104 SS Opening 's3n://2012-05-19-sample/hit_data.tsv.10000.gz' for reading
0714-163831.210 SS 17161 65 pool-1-thread-1 |          Folder /mnt/ramdisk/tachyonworker/users/1 was created!
0714-163831.212 SS 17161 65 pool-1-thread-1 |        File /mnt/ramdisk/tachyonworker/users/1/2 was created!
0714-163831.636 SS Got brand-new decompressor
0714-163831.984 SS Finished ResultTask(0, 0)
0714-163831.987 SS Completed ResultTask(0, 0)
0714-163831.989 SS Stage 0 (textFile at <console>:12) finished in 1.397 s
0714-163831.992 SS Job finished: count at <console>:15, took 1.448557549 s
res0: Long = 10000

scala> s.count()
0714-163832.414 SS Starting job: count at <console>:15
0714-163832.415 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163832.415 SS Final stage: Stage 1 (textFile at <console>:12)
0714-163832.415 SS Parents of final stage: List()
0714-163832.417 SS Missing parents: List()
0714-163832.418 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163832.418 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-163832.419 SS Running ResultTask(1, 0)
0714-163832.421 SS Size of task 0 is 1443 bytes
0714-163832.485 SS Got brand-new decompressor
0714-163832.673 SS Finished ResultTask(1, 0)
0714-163832.673 SS Completed ResultTask(1, 0)
0714-163832.674 SS Stage 1 (textFile at <console>:12) finished in 0.250 s
0714-163832.674 SS Job finished: count at <console>:15, took 0.259027022 s
res1: Long = 10000

scala> s.count()
0714-163833.006 SS Starting job: count at <console>:15
0714-163833.007 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163833.007 SS Final stage: Stage 2 (textFile at <console>:12)
0714-163833.007 SS Parents of final stage: List()
0714-163833.009 SS Missing parents: List()
0714-163833.010 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163833.011 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-163833.011 SS Running ResultTask(2, 0)
0714-163833.013 SS Size of task 0 is 1443 bytes
0714-163833.051 SS Got brand-new decompressor
0714-163833.175 SS Finished ResultTask(2, 0)
0714-163833.176 SS Completed ResultTask(2, 0)
0714-163833.176 SS Stage 2 (textFile at <console>:12) finished in 0.161 s
0714-163833.177 SS Job finished: count at <console>:15, took 0.169754983 s
res2: Long = 10000

scala> s.count()
0714-163833.692 SS Starting job: count at <console>:15
0714-163833.692 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163833.692 SS Final stage: Stage 3 (textFile at <console>:12)
0714-163833.692 SS Parents of final stage: List()
0714-163833.694 SS Missing parents: List()
0714-163833.695 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163833.695 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-163833.696 SS Running ResultTask(3, 0)
0714-163833.698 SS Size of task 0 is 1443 bytes
0714-163833.729 SS Got brand-new decompressor
0714-163833.858 SS Finished ResultTask(3, 0)
0714-163833.859 SS Completed ResultTask(3, 0)
0714-163833.859 SS Stage 3 (textFile at <console>:12) finished in 0.157 s
0714-163833.859 SS Job finished: count at <console>:15, took 0.167204731 s
res3: Long = 10000

scala> s.count()
0714-163834.215 SS Starting job: count at <console>:15
0714-163834.215 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163834.215 SS Final stage: Stage 4 (textFile at <console>:12)
0714-163834.215 SS Parents of final stage: List()
0714-163834.217 SS Missing parents: List()
0714-163834.218 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163834.218 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-163834.219 SS Running ResultTask(4, 0)
0714-163834.221 SS Size of task 0 is 1443 bytes
0714-163834.273 SS Got brand-new decompressor
0714-163834.404 SS Finished ResultTask(4, 0)
0714-163834.405 SS Completed ResultTask(4, 0)
0714-163834.405 SS Stage 4 (textFile at <console>:12) finished in 0.184 s
0714-163834.406 SS Job finished: count at <console>:15, took 0.190339922 s
res4: Long = 10000

scala> Killed 1 processes
Killed 1 processes
localhost: Killed 0 processes
Formatting Tachyon @ localhost
0714-163835.931 TU Deleting /mnt/tachyon/tachyon/tachyon_checkpoint.data
0714-163835.938 TU Deleting /mnt/tachyon/tachyon/tachyon_log.data
0714-163836.951 TU Formatting s3n://2012-05-19-sample/tachyon/data
0714-163838.224 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-163838.414 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-163838.430 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-163838.472 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-163838.510 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-163838.526 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-163838.581 TU Formatting s3n://2012-05-19-sample/tachyon/workers
0714-163838.598 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-163838.708 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-163838.720 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200
0714-163838.764 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-163838.822 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-163838.840 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200

spark-shell count

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-163854.739 SS Slf4jEventHandler started
0714-163855.412 SS Registered BlockManagerMaster Actor
0714-163855.457 SS MemoryStore started with capacity 326.7 MB.
0714-163855.466 SS Created local directory at /tmp/spark-local-20130714163855-c833
0714-163855.553 SS Bound socket to port 60176 with id = ConnectionManagerId(tachyon-ec2-0,60176)
0714-163855.574 SS Trying to register BlockManager
0714-163855.582 SS Registering block manager tachyon-ec2-0:60176 with 326.7 MB RAM
0714-163855.583 SS Registered BlockManager
0714-163855.632 SS Broadcast server started at http://10.190.33.193:48329
0714-163855.642 SS Registered MapOutputTrackerActor actor
0714-163855.650 SS HTTP File server directory is /tmp/spark-c087fa9c-6a6c-4cc9-a40d-a701fbeed16b
0714-163856.071 SS IoWorker thread 'spray-io-worker-0' started
0714-163857.242 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:39278
0714-163857.244 SS Started BlockManager web UI at http://tachyon-ec2-0:39278
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/data/hit_data.tsv.100000.gz")
0714-163859.551 SS ensureFreeSpace(58423) called with curMem=0, maxMem=342526525
0714-163859.554 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-163900.206 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-163900.206 SS Snappy native library not loaded
0714-163900.237 SS Total input paths to process : 1
0714-163900.260 SS Starting job: count at <console>:15
0714-163900.272 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163900.273 SS Final stage: Stage 0 (textFile at <console>:12)
0714-163900.274 SS Parents of final stage: List()
0714-163900.283 SS Missing parents: List()
0714-163900.286 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163900.301 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-163900.317 SS Running ResultTask(0, 0)
0714-163900.538 SS Size of task 0 is 1430 bytes
0714-163900.722 SS Got brand-new decompressor
0714-163902.372 SS Finished ResultTask(0, 0)
0714-163902.375 SS Completed ResultTask(0, 0)
0714-163902.377 SS Stage 0 (textFile at <console>:12) finished in 2.060 s
0714-163902.378 SS Job finished: count at <console>:15, took 2.118020096 s
res0: Long = 100002

scala> s.count()
0714-163902.780 SS Starting job: count at <console>:15
0714-163902.781 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163902.781 SS Final stage: Stage 1 (textFile at <console>:12)
0714-163902.781 SS Parents of final stage: List()
0714-163902.787 SS Missing parents: List()
0714-163902.788 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163902.788 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-163902.789 SS Running ResultTask(1, 0)
0714-163902.791 SS Size of task 0 is 1433 bytes
0714-163902.870 SS Got brand-new decompressor
0714-163904.066 SS Finished ResultTask(1, 0)
0714-163904.067 SS Completed ResultTask(1, 0)
0714-163904.068 SS Stage 1 (textFile at <console>:12) finished in 1.276 s
0714-163904.068 SS Job finished: count at <console>:15, took 1.287172728 s
res1: Long = 100002

scala> s.count()
0714-163904.427 SS Starting job: count at <console>:15
0714-163904.428 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163904.428 SS Final stage: Stage 2 (textFile at <console>:12)
0714-163904.428 SS Parents of final stage: List()
0714-163904.430 SS Missing parents: List()
0714-163904.431 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163904.431 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-163904.432 SS Running ResultTask(2, 0)
0714-163904.434 SS Size of task 0 is 1433 bytes
0714-163904.509 SS Got brand-new decompressor
0714-163905.948 SS Finished ResultTask(2, 0)
0714-163905.948 SS Completed ResultTask(2, 0)
0714-163905.949 SS Stage 2 (textFile at <console>:12) finished in 1.513 s
0714-163905.949 SS Job finished: count at <console>:15, took 1.52114737 s
res2: Long = 100002

scala> s.count()
0714-163906.377 SS Starting job: count at <console>:15
0714-163906.378 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163906.378 SS Final stage: Stage 3 (textFile at <console>:12)
0714-163906.378 SS Parents of final stage: List()
0714-163906.380 SS Missing parents: List()
0714-163906.380 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163906.381 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-163906.381 SS Running ResultTask(3, 0)
0714-163906.383 SS Size of task 0 is 1433 bytes
0714-163906.415 SS Got brand-new decompressor
0714-163907.570 SS Finished ResultTask(3, 0)
0714-163907.571 SS Completed ResultTask(3, 0)
0714-163907.572 SS Stage 3 (textFile at <console>:12) finished in 1.184 s
0714-163907.572 SS Job finished: count at <console>:15, took 1.194260342 s
res3: Long = 100002

scala> s.count()
0714-163907.876 SS Starting job: count at <console>:15
0714-163907.877 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163907.877 SS Final stage: Stage 4 (textFile at <console>:12)
0714-163907.877 SS Parents of final stage: List()
0714-163907.889 SS Missing parents: List()
0714-163907.889 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163907.890 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-163907.891 SS Running ResultTask(4, 0)
0714-163907.893 SS Size of task 0 is 1433 bytes
0714-163907.934 SS Got brand-new decompressor
0714-163909.156 SS Finished ResultTask(4, 0)
0714-163909.157 SS Completed ResultTask(4, 0)
0714-163909.158 SS Stage 4 (textFile at <console>:12) finished in 1.262 s
0714-163909.158 SS Job finished: count at <console>:15, took 1.28098498 s
res4: Long = 100002

scala> restaring tachyon
Killed 0 processes
Killed 0 processes
localhost: Killed 0 processes
Mounting ramfs on Linux...
TACHYON_RAM_FOLDER was not set. Using the default one: /mnt/ramdisk
Formatting RamFS: /mnt/ramdisk
Starting master @ localhost
Starting worker @ tachyon-ec2-0

spark-shell count
17753 tachyon.Master
17767 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-163930.500 SS Slf4jEventHandler started
0714-163931.200 SS Registered BlockManagerMaster Actor
0714-163931.251 SS MemoryStore started with capacity 326.7 MB.
0714-163931.265 SS Created local directory at /tmp/spark-local-20130714163931-39a5
0714-163931.326 SS Bound socket to port 57891 with id = ConnectionManagerId(tachyon-ec2-0,57891)
0714-163931.348 SS Trying to register BlockManager
0714-163931.351 SS Registering block manager tachyon-ec2-0:57891 with 326.7 MB RAM
0714-163931.352 SS Registered BlockManager
0714-163931.397 SS Broadcast server started at http://10.190.33.193:40618
0714-163931.410 SS Registered MapOutputTrackerActor actor
0714-163931.419 SS HTTP File server directory is /tmp/spark-ca97fe2e-83be-49c9-857b-91ae87a04ce7
0714-163931.879 SS IoWorker thread 'spray-io-worker-0' started
0714-163933.058 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:37530
0714-163933.061 SS Started BlockManager web UI at http://tachyon-ec2-0:37530
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("tachyon://localhost:19998/hit_data.tsv.100000.gz")
0714-163935.711 SS ensureFreeSpace(58439) called with curMem=0, maxMem=342526525
0714-163935.714 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-163936.323 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-163936.323 SS Snappy native library not loaded
0714-163936.363 SS 17814 62 Thread-37 |        Trying to connect master @ localhost/127.0.0.1:19998
0714-163936.426 SS 17814 62 Thread-37 |          User registered at the master localhost/127.0.0.1:19998 got UserId 1
0714-163936.427 SS 17814 62 Thread-37 |        Trying to get local worker host : tachyon-ec2-0
0714-163936.450 SS 17814 62 Thread-37 |        Connecting local worker @ tachyon-ec2-0/10.190.33.193:29998
0714-163938.140 SS Total input paths to process : 1
0714-163940.455 SS Starting job: count at <console>:15
0714-163940.465 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163940.468 SS Final stage: Stage 0 (textFile at <console>:12)
0714-163940.472 SS Parents of final stage: List()
0714-163940.477 SS Missing parents: List()
0714-163940.479 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163940.485 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-163940.490 SS Running ResultTask(0, 0)
0714-163940.548 SS Size of task 0 is 1441 bytes
0714-163940.649 SS 17814 65 pool-1-thread-1 |          /mnt/ramdisk/tachyonworker/2 is not on local disk.
0714-163940.666 SS 17814 65 pool-1-thread-1 |          Try to find and read from remote workers.
0714-163940.805 SS 17814 65 pool-1-thread-1 |          fileLocations: [NetAddress(mHost:localhost, mPort:-1)]
0714-163940.952 SS Opening 's3n://2012-05-19-sample/hit_data.tsv.100000.gz' for reading
0714-163941.110 SS 17814 65 pool-1-thread-1 |          Folder /mnt/ramdisk/tachyonworker/users/1 was created!
0714-163941.111 SS 17814 65 pool-1-thread-1 |        File /mnt/ramdisk/tachyonworker/users/1/2 was created!
0714-163941.913 SS Got brand-new decompressor
0714-163943.609 SS Finished ResultTask(0, 0)
0714-163943.615 SS Completed ResultTask(0, 0)
0714-163943.618 SS Stage 0 (textFile at <console>:12) finished in 3.128 s
0714-163943.619 SS Job finished: count at <console>:15, took 3.160974447 s
res0: Long = 100002

scala> s.count()
0714-163944.035 SS Starting job: count at <console>:15
0714-163944.036 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163944.036 SS Final stage: Stage 1 (textFile at <console>:12)
0714-163944.036 SS Parents of final stage: List()
0714-163944.038 SS Missing parents: List()
0714-163944.039 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163944.039 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-163944.040 SS Running ResultTask(1, 0)
0714-163944.042 SS Size of task 0 is 1444 bytes
0714-163944.156 SS Got brand-new decompressor
0714-163945.549 SS Finished ResultTask(1, 0)
0714-163945.549 SS Completed ResultTask(1, 0)
0714-163945.550 SS Stage 1 (textFile at <console>:12) finished in 1.506 s
0714-163945.550 SS Job finished: count at <console>:15, took 1.514072787 s
res1: Long = 100002

scala> s.count()
0714-163945.845 SS Starting job: count at <console>:15
0714-163945.846 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163945.846 SS Final stage: Stage 2 (textFile at <console>:12)
0714-163945.846 SS Parents of final stage: List()
0714-163945.848 SS Missing parents: List()
0714-163945.849 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163945.849 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-163945.850 SS Running ResultTask(2, 0)
0714-163945.852 SS Size of task 0 is 1444 bytes
0714-163945.895 SS Got brand-new decompressor
0714-163947.335 SS Finished ResultTask(2, 0)
0714-163947.336 SS Completed ResultTask(2, 0)
0714-163947.336 SS Stage 2 (textFile at <console>:12) finished in 1.481 s
0714-163947.336 SS Job finished: count at <console>:15, took 1.490905759 s
res2: Long = 100002

scala> s.count()
0714-163947.776 SS Starting job: count at <console>:15
0714-163947.777 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163947.777 SS Final stage: Stage 3 (textFile at <console>:12)
0714-163947.777 SS Parents of final stage: List()
0714-163947.783 SS Missing parents: List()
0714-163947.784 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163947.784 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-163947.785 SS Running ResultTask(3, 0)
0714-163947.787 SS Size of task 0 is 1444 bytes
0714-163947.847 SS Got brand-new decompressor
0714-163949.177 SS Finished ResultTask(3, 0)
0714-163949.178 SS Completed ResultTask(3, 0)
0714-163949.178 SS Stage 3 (textFile at <console>:12) finished in 1.389 s
0714-163949.178 SS Job finished: count at <console>:15, took 1.401487355 s
res3: Long = 100002

scala> s.count()
0714-163949.439 SS Starting job: count at <console>:15
0714-163949.440 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-163949.440 SS Final stage: Stage 4 (textFile at <console>:12)
0714-163949.440 SS Parents of final stage: List()
0714-163949.443 SS Missing parents: List()
0714-163949.444 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-163949.444 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-163949.445 SS Running ResultTask(4, 0)
0714-163949.446 SS Size of task 0 is 1444 bytes
0714-163949.476 SS Got brand-new decompressor
0714-163950.926 SS Finished ResultTask(4, 0)
0714-163950.926 SS Completed ResultTask(4, 0)
0714-163950.927 SS Stage 4 (textFile at <console>:12) finished in 1.479 s
0714-163950.927 SS Job finished: count at <console>:15, took 1.487136484 s
res4: Long = 100002

scala> Killed 1 processes
Killed 1 processes
localhost: Killed 0 processes
Formatting Tachyon @ localhost
0714-163952.487 TU Deleting /mnt/tachyon/tachyon/tachyon_checkpoint.data
0714-163952.489 TU Deleting /mnt/tachyon/tachyon/tachyon_log.data
0714-163953.500 TU Formatting s3n://2012-05-19-sample/tachyon/data
0714-163954.824 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-163955.401 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-163955.481 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-163955.522 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-163955.555 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-163955.583 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-163955.652 TU Formatting s3n://2012-05-19-sample/tachyon/workers
0714-163955.678 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-163955.868 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-163955.895 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200
0714-163955.953 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-163956.005 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-163956.026 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200

spark-shell count

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-164013.097 SS Slf4jEventHandler started
0714-164013.760 SS Registered BlockManagerMaster Actor
0714-164013.822 SS MemoryStore started with capacity 326.7 MB.
0714-164013.831 SS Created local directory at /tmp/spark-local-20130714164013-20dc
0714-164013.886 SS Bound socket to port 48676 with id = ConnectionManagerId(tachyon-ec2-0,48676)
0714-164013.906 SS Trying to register BlockManager
0714-164013.913 SS Registering block manager tachyon-ec2-0:48676 with 326.7 MB RAM
0714-164013.914 SS Registered BlockManager
0714-164013.981 SS Broadcast server started at http://10.190.33.193:52829
0714-164013.992 SS Registered MapOutputTrackerActor actor
0714-164014.003 SS HTTP File server directory is /tmp/spark-4074effd-f13f-4969-a58f-2e41c4fd76a0
0714-164014.414 SS IoWorker thread 'spray-io-worker-0' started
0714-164015.633 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:40146
0714-164015.635 SS Started BlockManager web UI at http://tachyon-ec2-0:40146
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/data/hit_data.tsv.1000000.gz")
0714-164018.085 SS ensureFreeSpace(58423) called with curMem=0, maxMem=342526525
0714-164018.088 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-164018.638 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-164018.643 SS Snappy native library not loaded
0714-164018.667 SS Total input paths to process : 1
0714-164018.691 SS Starting job: count at <console>:15
0714-164018.698 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164018.704 SS Final stage: Stage 0 (textFile at <console>:12)
0714-164018.704 SS Parents of final stage: List()
0714-164018.711 SS Missing parents: List()
0714-164018.714 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164018.729 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-164018.745 SS Running ResultTask(0, 0)
0714-164018.955 SS Size of task 0 is 1431 bytes
0714-164019.136 SS Got brand-new decompressor
0714-164031.153 SS Finished ResultTask(0, 0)
0714-164031.156 SS Completed ResultTask(0, 0)
0714-164031.158 SS Stage 0 (textFile at <console>:12) finished in 12.413 s
0714-164031.160 SS Job finished: count at <console>:15, took 12.468099609 s
res0: Long = 1000135

scala> s.count()
0714-164031.534 SS Starting job: count at <console>:15
0714-164031.550 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164031.550 SS Final stage: Stage 1 (textFile at <console>:12)
0714-164031.550 SS Parents of final stage: List()
0714-164031.556 SS Missing parents: List()
0714-164031.557 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164031.558 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-164031.558 SS Running ResultTask(1, 0)
0714-164031.560 SS Size of task 0 is 1434 bytes
0714-164031.653 SS Got brand-new decompressor
0714-164042.934 SS Finished ResultTask(1, 0)
0714-164042.935 SS Completed ResultTask(1, 0)
0714-164042.936 SS Stage 1 (textFile at <console>:12) finished in 11.364 s
0714-164042.936 SS Job finished: count at <console>:15, took 11.386196428 s
res1: Long = 1000135

scala> s.count()
0714-164043.229 SS Starting job: count at <console>:15
0714-164043.229 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164043.229 SS Final stage: Stage 2 (textFile at <console>:12)
0714-164043.229 SS Parents of final stage: List()
0714-164043.231 SS Missing parents: List()
0714-164043.232 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164043.233 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-164043.233 SS Running ResultTask(2, 0)
0714-164043.235 SS Size of task 0 is 1434 bytes
0714-164043.316 SS Got brand-new decompressor
0714-164054.832 SS Finished ResultTask(2, 0)
0714-164054.832 SS Completed ResultTask(2, 0)
0714-164054.833 SS Stage 2 (textFile at <console>:12) finished in 11.597 s
0714-164054.833 SS Job finished: count at <console>:15, took 11.603729561 s
res2: Long = 1000135

scala> s.count()
0714-164055.098 SS Starting job: count at <console>:15
0714-164055.098 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164055.098 SS Final stage: Stage 3 (textFile at <console>:12)
0714-164055.098 SS Parents of final stage: List()
0714-164055.100 SS Missing parents: List()
0714-164055.101 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164055.102 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-164055.102 SS Running ResultTask(3, 0)
0714-164055.104 SS Size of task 0 is 1434 bytes
0714-164055.147 SS Got brand-new decompressor
0714-164106.391 SS Finished ResultTask(3, 0)
0714-164106.391 SS Completed ResultTask(3, 0)
0714-164106.392 SS Stage 3 (textFile at <console>:12) finished in 11.284 s
0714-164106.392 SS Job finished: count at <console>:15, took 11.293690668 s
res3: Long = 1000135

scala> s.count()
0714-164106.630 SS Starting job: count at <console>:15
0714-164106.631 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164106.631 SS Final stage: Stage 4 (textFile at <console>:12)
0714-164106.631 SS Parents of final stage: List()
0714-164106.633 SS Missing parents: List()
0714-164106.633 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164106.634 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-164106.634 SS Running ResultTask(4, 0)
0714-164106.636 SS Size of task 0 is 1434 bytes
0714-164106.662 SS Got brand-new decompressor
0714-164117.853 SS Finished ResultTask(4, 0)
0714-164117.854 SS Completed ResultTask(4, 0)
0714-164117.854 SS Stage 4 (textFile at <console>:12) finished in 11.215 s
0714-164117.854 SS Job finished: count at <console>:15, took 11.223804073 s
res4: Long = 1000135

scala> restaring tachyon
Killed 0 processes
Killed 0 processes
localhost: Killed 0 processes
Mounting ramfs on Linux...
TACHYON_RAM_FOLDER was not set. Using the default one: /mnt/ramdisk
Formatting RamFS: /mnt/ramdisk
Starting master @ localhost
Starting worker @ tachyon-ec2-0

spark-shell count
18430 tachyon.Master
18443 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-164138.809 SS Slf4jEventHandler started
0714-164139.480 SS Registered BlockManagerMaster Actor
0714-164139.535 SS MemoryStore started with capacity 326.7 MB.
0714-164139.559 SS Created local directory at /tmp/spark-local-20130714164139-6ba1
0714-164139.638 SS Bound socket to port 43323 with id = ConnectionManagerId(tachyon-ec2-0,43323)
0714-164139.662 SS Trying to register BlockManager
0714-164139.666 SS Registering block manager tachyon-ec2-0:43323 with 326.7 MB RAM
0714-164139.667 SS Registered BlockManager
0714-164139.716 SS Broadcast server started at http://10.190.33.193:57992
0714-164139.726 SS Registered MapOutputTrackerActor actor
0714-164139.734 SS HTTP File server directory is /tmp/spark-7f4f33ad-a80f-4f2e-8b9b-640f3899002c
0714-164140.162 SS IoWorker thread 'spray-io-worker-0' started
0714-164141.361 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:52143
0714-164141.364 SS Started BlockManager web UI at http://tachyon-ec2-0:52143
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("tachyon://localhost:19998/hit_data.tsv.1000000.gz")
0714-164143.824 SS ensureFreeSpace(58447) called with curMem=0, maxMem=342526525
0714-164143.827 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-164144.425 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-164144.426 SS Snappy native library not loaded
0714-164144.467 SS 18491 61 Thread-37 |        Trying to connect master @ localhost/127.0.0.1:19998
0714-164144.528 SS 18491 61 Thread-37 |          User registered at the master localhost/127.0.0.1:19998 got UserId 1
0714-164144.528 SS 18491 61 Thread-37 |        Trying to get local worker host : tachyon-ec2-0
0714-164144.546 SS 18491 61 Thread-37 |        Connecting local worker @ tachyon-ec2-0/10.190.33.193:29998
0714-164146.227 SS Total input paths to process : 1
0714-164148.538 SS Starting job: count at <console>:15
0714-164148.552 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164148.553 SS Final stage: Stage 0 (textFile at <console>:12)
0714-164148.553 SS Parents of final stage: List()
0714-164148.562 SS Missing parents: List()
0714-164148.565 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164148.571 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-164148.576 SS Running ResultTask(0, 0)
0714-164148.676 SS Size of task 0 is 1442 bytes
0714-164148.771 SS 18491 64 pool-1-thread-1 |          /mnt/ramdisk/tachyonworker/2 is not on local disk.
0714-164148.788 SS 18491 64 pool-1-thread-1 |          Try to find and read from remote workers.
0714-164149.013 SS 18491 64 pool-1-thread-1 |          fileLocations: [NetAddress(mHost:localhost, mPort:-1)]
0714-164149.135 SS Opening 's3n://2012-05-19-sample/hit_data.tsv.1000000.gz' for reading
0714-164149.266 SS 18491 64 pool-1-thread-1 |          Folder /mnt/ramdisk/tachyonworker/users/1 was created!
0714-164149.268 SS 18491 64 pool-1-thread-1 |        File /mnt/ramdisk/tachyonworker/users/1/2 was created!
0714-164156.573 SS Got brand-new decompressor
0714-164210.401 SS Finished ResultTask(0, 0)
0714-164210.404 SS Completed ResultTask(0, 0)
0714-164210.406 SS Stage 0 (textFile at <console>:12) finished in 21.831 s
0714-164210.408 SS Job finished: count at <console>:15, took 21.869062881 s
res0: Long = 1000135

scala> s.count()
0714-164210.794 SS Starting job: count at <console>:15
0714-164210.800 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164210.800 SS Final stage: Stage 1 (textFile at <console>:12)
0714-164210.800 SS Parents of final stage: List()
0714-164210.803 SS Missing parents: List()
0714-164210.804 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164210.804 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-164210.805 SS Running ResultTask(1, 0)
0714-164210.807 SS Size of task 0 is 1445 bytes
0714-164210.870 SS Got brand-new decompressor
0714-164224.006 SS Finished ResultTask(1, 0)
0714-164224.008 SS Completed ResultTask(1, 0)
0714-164224.008 SS Stage 1 (textFile at <console>:12) finished in 13.197 s
0714-164224.008 SS Job finished: count at <console>:15, took 13.208718812 s
res1: Long = 1000135

scala> s.count()
0714-164224.273 SS Starting job: count at <console>:15
0714-164224.274 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164224.274 SS Final stage: Stage 2 (textFile at <console>:12)
0714-164224.274 SS Parents of final stage: List()
0714-164224.276 SS Missing parents: List()
0714-164224.277 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164224.277 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-164224.278 SS Running ResultTask(2, 0)
0714-164224.280 SS Size of task 0 is 1445 bytes
0714-164224.318 SS Got brand-new decompressor
0714-164236.816 SS Finished ResultTask(2, 0)
0714-164236.817 SS Completed ResultTask(2, 0)
0714-164236.817 SS Stage 2 (textFile at <console>:12) finished in 12.534 s
0714-164236.817 SS Job finished: count at <console>:15, took 12.543493609 s
res2: Long = 1000135

scala> s.count()
0714-164237.139 SS Starting job: count at <console>:15
0714-164237.140 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164237.140 SS Final stage: Stage 3 (textFile at <console>:12)
0714-164237.140 SS Parents of final stage: List()
0714-164237.142 SS Missing parents: List()
0714-164237.142 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164237.143 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-164237.143 SS Running ResultTask(3, 0)
0714-164237.145 SS Size of task 0 is 1445 bytes
0714-164237.176 SS Got brand-new decompressor
0714-164249.781 SS Finished ResultTask(3, 0)
0714-164249.782 SS Completed ResultTask(3, 0)
0714-164249.782 SS Stage 3 (textFile at <console>:12) finished in 12.635 s
0714-164249.782 SS Job finished: count at <console>:15, took 12.642804842 s
res3: Long = 1000135

scala> s.count()
0714-164250.025 SS Starting job: count at <console>:15
0714-164250.025 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164250.026 SS Final stage: Stage 4 (textFile at <console>:12)
0714-164250.026 SS Parents of final stage: List()
0714-164250.027 SS Missing parents: List()
0714-164250.028 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164250.029 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-164250.029 SS Running ResultTask(4, 0)
0714-164250.031 SS Size of task 0 is 1445 bytes
0714-164250.067 SS Got brand-new decompressor
0714-164302.655 SS Finished ResultTask(4, 0)
0714-164302.656 SS Completed ResultTask(4, 0)
0714-164302.656 SS Stage 4 (textFile at <console>:12) finished in 12.625 s
0714-164302.656 SS Job finished: count at <console>:15, took 12.630880121 s
res4: Long = 1000135

scala> Killed 1 processes
Killed 1 processes
localhost: Killed 0 processes
Formatting Tachyon @ localhost
0714-164304.235 TU Deleting /mnt/tachyon/tachyon/tachyon_checkpoint.data
0714-164304.241 TU Deleting /mnt/tachyon/tachyon/tachyon_log.data
0714-164305.240 TU Formatting s3n://2012-05-19-sample/tachyon/data
0714-164306.525 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-164306.776 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-164306.800 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-164306.847 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-164306.905 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-164306.924 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-164306.975 TU Formatting s3n://2012-05-19-sample/tachyon/workers
0714-164307.003 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-164307.162 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-164307.187 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200
0714-164307.251 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-164307.302 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-164307.323 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200

spark-shell count

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-164324.794 SS Slf4jEventHandler started
0714-164325.480 SS Registered BlockManagerMaster Actor
0714-164325.526 SS MemoryStore started with capacity 326.7 MB.
0714-164325.535 SS Created local directory at /tmp/spark-local-20130714164325-4b28
0714-164325.604 SS Bound socket to port 42325 with id = ConnectionManagerId(tachyon-ec2-0,42325)
0714-164325.624 SS Trying to register BlockManager
0714-164325.627 SS Registering block manager tachyon-ec2-0:42325 with 326.7 MB RAM
0714-164325.628 SS Registered BlockManager
0714-164325.676 SS Broadcast server started at http://10.190.33.193:58533
0714-164325.688 SS Registered MapOutputTrackerActor actor
0714-164325.695 SS HTTP File server directory is /tmp/spark-bb6462dd-83f2-4a2a-b438-c094cbddccd6
0714-164326.163 SS IoWorker thread 'spray-io-worker-0' started
0714-164327.313 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:58209
0714-164327.316 SS Started BlockManager web UI at http://tachyon-ec2-0:58209
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/data/hit_data.tsv.2000000.gz")
0714-164329.976 SS ensureFreeSpace(58423) called with curMem=0, maxMem=342526525
0714-164329.979 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-164330.574 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-164330.579 SS Snappy native library not loaded
0714-164330.607 SS Total input paths to process : 1
0714-164330.625 SS Starting job: count at <console>:15
0714-164330.636 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164330.640 SS Final stage: Stage 0 (textFile at <console>:12)
0714-164330.640 SS Parents of final stage: List()
0714-164330.647 SS Missing parents: List()
0714-164330.653 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164330.667 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-164330.680 SS Running ResultTask(0, 0)
0714-164330.884 SS Size of task 0 is 1431 bytes
0714-164331.091 SS Got brand-new decompressor
0714-164354.579 SS Finished ResultTask(0, 0)
0714-164354.581 SS Completed ResultTask(0, 0)
0714-164354.584 SS Stage 0 (textFile at <console>:12) finished in 23.904 s
0714-164354.585 SS Job finished: count at <console>:15, took 23.958093279 s
res0: Long = 2000298

scala> s.count()
0714-164354.911 SS Starting job: count at <console>:15
0714-164354.915 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164354.915 SS Final stage: Stage 1 (textFile at <console>:12)
0714-164354.915 SS Parents of final stage: List()
0714-164354.918 SS Missing parents: List()
0714-164354.919 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164354.919 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-164354.920 SS Running ResultTask(1, 0)
0714-164354.922 SS Size of task 0 is 1434 bytes
0714-164354.980 SS Got brand-new decompressor
0714-164417.481 SS Finished ResultTask(1, 0)
0714-164417.482 SS Completed ResultTask(1, 0)
0714-164417.482 SS Stage 1 (textFile at <console>:12) finished in 22.559 s
0714-164417.482 SS Job finished: count at <console>:15, took 22.570410533 s
res1: Long = 2000298

scala> s.count()
0714-164417.776 SS Starting job: count at <console>:15
0714-164417.777 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164417.777 SS Final stage: Stage 2 (textFile at <console>:12)
0714-164417.777 SS Parents of final stage: List()
0714-164417.779 SS Missing parents: List()
0714-164417.779 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164417.780 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-164417.780 SS Running ResultTask(2, 0)
0714-164417.782 SS Size of task 0 is 1434 bytes
0714-164417.837 SS Got brand-new decompressor
0714-164441.033 SS Finished ResultTask(2, 0)
0714-164441.034 SS Completed ResultTask(2, 0)
0714-164441.034 SS Stage 2 (textFile at <console>:12) finished in 23.251 s
0714-164441.035 SS Job finished: count at <console>:15, took 23.257917978 s
res2: Long = 2000298

scala> s.count()
0714-164441.327 SS Starting job: count at <console>:15
0714-164441.328 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164441.328 SS Final stage: Stage 3 (textFile at <console>:12)
0714-164441.328 SS Parents of final stage: List()
0714-164441.330 SS Missing parents: List()
0714-164441.330 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164441.331 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-164441.331 SS Running ResultTask(3, 0)
0714-164441.333 SS Size of task 0 is 1434 bytes
0714-164441.363 SS Got brand-new decompressor
0714-164503.804 SS Finished ResultTask(3, 0)
0714-164503.804 SS Completed ResultTask(3, 0)
0714-164503.805 SS Stage 3 (textFile at <console>:12) finished in 22.469 s
0714-164503.805 SS Job finished: count at <console>:15, took 22.477328417 s
res3: Long = 2000298

scala> s.count()
0714-164504.044 SS Starting job: count at <console>:15
0714-164504.045 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164504.045 SS Final stage: Stage 4 (textFile at <console>:12)
0714-164504.045 SS Parents of final stage: List()
0714-164504.047 SS Missing parents: List()
0714-164504.047 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164504.048 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-164504.048 SS Running ResultTask(4, 0)
0714-164504.050 SS Size of task 0 is 1434 bytes
0714-164504.080 SS Got brand-new decompressor
0714-164526.429 SS Finished ResultTask(4, 0)
0714-164526.429 SS Completed ResultTask(4, 0)
0714-164526.430 SS Stage 4 (textFile at <console>:12) finished in 22.378 s
0714-164526.430 SS Job finished: count at <console>:15, took 22.384951981 s
res4: Long = 2000298

scala> restaring tachyon
Killed 0 processes
Killed 0 processes
localhost: Killed 0 processes
Mounting ramfs on Linux...
TACHYON_RAM_FOLDER was not set. Using the default one: /mnt/ramdisk
Formatting RamFS: /mnt/ramdisk
Starting master @ localhost
Starting worker @ tachyon-ec2-0

spark-shell count
19267 tachyon.Master
19280 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-164547.767 SS Slf4jEventHandler started
0714-164548.456 SS Registered BlockManagerMaster Actor
0714-164548.509 SS MemoryStore started with capacity 326.7 MB.
0714-164548.519 SS Created local directory at /tmp/spark-local-20130714164548-9d19
0714-164548.585 SS Bound socket to port 59660 with id = ConnectionManagerId(tachyon-ec2-0,59660)
0714-164548.610 SS Trying to register BlockManager
0714-164548.614 SS Registering block manager tachyon-ec2-0:59660 with 326.7 MB RAM
0714-164548.615 SS Registered BlockManager
0714-164548.677 SS Broadcast server started at http://10.190.33.193:46565
0714-164548.702 SS Registered MapOutputTrackerActor actor
0714-164548.714 SS HTTP File server directory is /tmp/spark-5d5f2912-dd70-485e-a3cc-eb9e86832084
0714-164549.146 SS IoWorker thread 'spray-io-worker-0' started
0714-164550.361 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:41054
0714-164550.369 SS Started BlockManager web UI at http://tachyon-ec2-0:41054
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("tachyon://localhost:19998/hit_data.tsv.2000000.gz")
0714-164553.017 SS ensureFreeSpace(58447) called with curMem=0, maxMem=342526525
0714-164553.020 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-164553.708 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-164553.714 SS Snappy native library not loaded
0714-164553.770 SS 19328 62 Thread-37 |        Trying to connect master @ localhost/127.0.0.1:19998
0714-164553.857 SS 19328 62 Thread-37 |          User registered at the master localhost/127.0.0.1:19998 got UserId 1
0714-164553.858 SS 19328 62 Thread-37 |        Trying to get local worker host : tachyon-ec2-0
0714-164553.873 SS 19328 62 Thread-37 |        Connecting local worker @ tachyon-ec2-0/10.190.33.193:29998
0714-164555.576 SS Total input paths to process : 1
0714-164557.905 SS Starting job: count at <console>:15
0714-164557.913 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164557.914 SS Final stage: Stage 0 (textFile at <console>:12)
0714-164557.914 SS Parents of final stage: List()
0714-164557.923 SS Missing parents: List()
0714-164557.926 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164557.941 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-164557.947 SS Running ResultTask(0, 0)
0714-164558.010 SS Size of task 0 is 1442 bytes
0714-164558.113 SS 19328 65 pool-1-thread-1 |          /mnt/ramdisk/tachyonworker/2 is not on local disk.
0714-164558.123 SS 19328 65 pool-1-thread-1 |          Try to find and read from remote workers.
0714-164558.244 SS 19328 65 pool-1-thread-1 |          fileLocations: [NetAddress(mHost:localhost, mPort:-1)]
0714-164558.450 SS Opening 's3n://2012-05-19-sample/hit_data.tsv.2000000.gz' for reading
0714-164558.596 SS 19328 65 pool-1-thread-1 |          Folder /mnt/ramdisk/tachyonworker/users/1 was created!
0714-164558.600 SS 19328 65 pool-1-thread-1 |        File /mnt/ramdisk/tachyonworker/users/1/2 was created!
0714-164611.315 SS Got brand-new decompressor
0714-164637.894 SS Finished ResultTask(0, 0)
0714-164637.900 SS Completed ResultTask(0, 0)
0714-164637.902 SS Stage 0 (textFile at <console>:12) finished in 39.955 s
0714-164637.904 SS Job finished: count at <console>:15, took 39.997567844 s
res0: Long = 2000298

scala> s.count()
0714-164638.226 SS Starting job: count at <console>:15
0714-164638.227 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164638.227 SS Final stage: Stage 1 (textFile at <console>:12)
0714-164638.227 SS Parents of final stage: List()
0714-164638.229 SS Missing parents: List()
0714-164638.229 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164638.230 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-164638.230 SS Running ResultTask(1, 0)
0714-164638.232 SS Size of task 0 is 1445 bytes
0714-164638.264 SS Got brand-new decompressor
0714-164704.267 SS Finished ResultTask(1, 0)
0714-164704.268 SS Completed ResultTask(1, 0)
0714-164704.269 SS Stage 1 (textFile at <console>:12) finished in 26.035 s
0714-164704.269 SS Job finished: count at <console>:15, took 26.042202076 s
res1: Long = 2000298

scala> s.count()
0714-164704.524 SS Starting job: count at <console>:15
0714-164704.525 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164704.525 SS Final stage: Stage 2 (textFile at <console>:12)
0714-164704.525 SS Parents of final stage: List()
0714-164704.527 SS Missing parents: List()
0714-164704.527 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164704.528 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-164704.528 SS Running ResultTask(2, 0)
0714-164704.530 SS Size of task 0 is 1445 bytes
0714-164704.597 SS Got brand-new decompressor
0714-164730.003 SS Finished ResultTask(2, 0)
0714-164730.003 SS Completed ResultTask(2, 0)
0714-164730.004 SS Stage 2 (textFile at <console>:12) finished in 25.472 s
0714-164730.004 SS Job finished: count at <console>:15, took 25.479223095 s
res2: Long = 2000298

scala> s.count()
0714-164730.268 SS Starting job: count at <console>:15
0714-164730.268 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164730.268 SS Final stage: Stage 3 (textFile at <console>:12)
0714-164730.269 SS Parents of final stage: List()
0714-164730.271 SS Missing parents: List()
0714-164730.271 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164730.272 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-164730.272 SS Running ResultTask(3, 0)
0714-164730.274 SS Size of task 0 is 1445 bytes
0714-164730.304 SS Got brand-new decompressor
0714-164755.605 SS Finished ResultTask(3, 0)
0714-164755.606 SS Completed ResultTask(3, 0)
0714-164755.606 SS Stage 3 (textFile at <console>:12) finished in 25.331 s
0714-164755.606 SS Job finished: count at <console>:15, took 25.337942141 s
res3: Long = 2000298

scala> s.count()
0714-164755.853 SS Starting job: count at <console>:15
0714-164755.854 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164755.854 SS Final stage: Stage 4 (textFile at <console>:12)
0714-164755.854 SS Parents of final stage: List()
0714-164755.856 SS Missing parents: List()
0714-164755.857 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164755.858 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-164755.858 SS Running ResultTask(4, 0)
0714-164755.860 SS Size of task 0 is 1445 bytes
0714-164755.890 SS Got brand-new decompressor
0714-164821.453 SS Finished ResultTask(4, 0)
0714-164821.455 SS Completed ResultTask(4, 0)
0714-164821.456 SS Stage 4 (textFile at <console>:12) finished in 25.595 s
0714-164821.456 SS Job finished: count at <console>:15, took 25.602245213 s
res4: Long = 2000298

scala> Killed 1 processes
Killed 1 processes
localhost: Killed 0 processes
Formatting Tachyon @ localhost
0714-164823.075 TU Deleting /mnt/tachyon/tachyon/tachyon_checkpoint.data
0714-164823.084 TU Deleting /mnt/tachyon/tachyon/tachyon_log.data
0714-164824.107 TU Formatting s3n://2012-05-19-sample/tachyon/data
0714-164825.406 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-164825.610 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-164825.623 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-164825.658 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-164825.685 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-164825.740 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-164825.789 TU Formatting s3n://2012-05-19-sample/tachyon/workers
0714-164825.803 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-164825.904 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-164825.918 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200
0714-164825.951 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-164825.984 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-164826.001 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200

spark-shell count

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-164841.951 SS Slf4jEventHandler started
0714-164842.642 SS Registered BlockManagerMaster Actor
0714-164842.689 SS MemoryStore started with capacity 326.7 MB.
0714-164842.699 SS Created local directory at /tmp/spark-local-20130714164842-c1c9
0714-164842.764 SS Bound socket to port 58830 with id = ConnectionManagerId(tachyon-ec2-0,58830)
0714-164842.784 SS Trying to register BlockManager
0714-164842.787 SS Registering block manager tachyon-ec2-0:58830 with 326.7 MB RAM
0714-164842.788 SS Registered BlockManager
0714-164842.840 SS Broadcast server started at http://10.190.33.193:50102
0714-164842.852 SS Registered MapOutputTrackerActor actor
0714-164842.856 SS HTTP File server directory is /tmp/spark-029ad490-e2f3-427d-a8b5-3ea37783e453
0714-164843.312 SS IoWorker thread 'spray-io-worker-0' started
0714-164844.489 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:55835
0714-164844.492 SS Started BlockManager web UI at http://tachyon-ec2-0:55835
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/data/hit_data.tsv.3000000.gz")
0714-164846.789 SS ensureFreeSpace(58423) called with curMem=0, maxMem=342526525
0714-164846.792 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-164847.442 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-164847.447 SS Snappy native library not loaded
0714-164847.492 SS Total input paths to process : 1
0714-164847.508 SS Starting job: count at <console>:15
0714-164847.520 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164847.521 SS Final stage: Stage 0 (textFile at <console>:12)
0714-164847.524 SS Parents of final stage: List()
0714-164847.531 SS Missing parents: List()
0714-164847.534 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164847.549 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-164847.565 SS Running ResultTask(0, 0)
0714-164847.752 SS Size of task 0 is 1431 bytes
0714-164847.930 SS Got brand-new decompressor
0714-164922.377 SS Finished ResultTask(0, 0)
0714-164922.379 SS Completed ResultTask(0, 0)
0714-164922.382 SS Stage 0 (textFile at <console>:12) finished in 34.817 s
0714-164922.383 SS Job finished: count at <console>:15, took 34.872238833 s
res0: Long = 3000314

scala> s.count()
0714-164922.687 SS Starting job: count at <console>:15
0714-164922.688 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164922.688 SS Final stage: Stage 1 (textFile at <console>:12)
0714-164922.688 SS Parents of final stage: List()
0714-164922.690 SS Missing parents: List()
0714-164922.690 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164922.691 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-164922.692 SS Running ResultTask(1, 0)
0714-164922.693 SS Size of task 0 is 1434 bytes
0714-164922.749 SS Got brand-new decompressor
0714-164956.566 SS Finished ResultTask(1, 0)
0714-164956.570 SS Completed ResultTask(1, 0)
0714-164956.570 SS Stage 1 (textFile at <console>:12) finished in 33.875 s
0714-164956.570 SS Job finished: count at <console>:15, took 33.882537662 s
res1: Long = 3000314

scala> s.count()
0714-164956.868 SS Starting job: count at <console>:15
0714-164956.869 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-164956.869 SS Final stage: Stage 2 (textFile at <console>:12)
0714-164956.869 SS Parents of final stage: List()
0714-164956.871 SS Missing parents: List()
0714-164956.872 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-164956.872 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-164956.873 SS Running ResultTask(2, 0)
0714-164956.875 SS Size of task 0 is 1434 bytes
0714-164956.930 SS Got brand-new decompressor
0714-165030.312 SS Finished ResultTask(2, 0)
0714-165030.312 SS Completed ResultTask(2, 0)
0714-165030.313 SS Stage 2 (textFile at <console>:12) finished in 33.437 s
0714-165030.313 SS Job finished: count at <console>:15, took 33.444072324 s
res2: Long = 3000314

scala> s.count()
0714-165030.578 SS Starting job: count at <console>:15
0714-165030.579 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-165030.579 SS Final stage: Stage 3 (textFile at <console>:12)
0714-165030.579 SS Parents of final stage: List()
0714-165030.581 SS Missing parents: List()
0714-165030.581 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-165030.582 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-165030.583 SS Running ResultTask(3, 0)
0714-165030.585 SS Size of task 0 is 1434 bytes
0714-165030.615 SS Got brand-new decompressor
0714-165103.730 SS Finished ResultTask(3, 0)
0714-165103.731 SS Completed ResultTask(3, 0)
0714-165103.732 SS Stage 3 (textFile at <console>:12) finished in 33.146 s
0714-165103.732 SS Job finished: count at <console>:15, took 33.153032036 s
res3: Long = 3000314

scala> s.count()
0714-165103.979 SS Starting job: count at <console>:15
0714-165103.980 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-165103.980 SS Final stage: Stage 4 (textFile at <console>:12)
0714-165103.980 SS Parents of final stage: List()
0714-165103.982 SS Missing parents: List()
0714-165103.983 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-165103.983 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-165103.984 SS Running ResultTask(4, 0)
0714-165103.986 SS Size of task 0 is 1434 bytes
0714-165104.017 SS Got brand-new decompressor
0714-165137.006 SS Finished ResultTask(4, 0)
0714-165137.006 SS Completed ResultTask(4, 0)
0714-165137.007 SS Stage 4 (textFile at <console>:12) finished in 33.019 s
0714-165137.007 SS Job finished: count at <console>:15, took 33.026888253 s
res4: Long = 3000314

scala> restaring tachyon
Killed 0 processes
Killed 0 processes
localhost: Killed 0 processes
Mounting ramfs on Linux...
TACHYON_RAM_FOLDER was not set. Using the default one: /mnt/ramdisk
Formatting RamFS: /mnt/ramdisk
Starting master @ localhost
Starting worker @ tachyon-ec2-0

spark-shell count
20156 tachyon.Master
20169 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-165158.419 SS Slf4jEventHandler started
0714-165159.124 SS Registered BlockManagerMaster Actor
0714-165159.166 SS MemoryStore started with capacity 326.7 MB.
0714-165159.178 SS Created local directory at /tmp/spark-local-20130714165159-92a8
0714-165159.240 SS Bound socket to port 56939 with id = ConnectionManagerId(tachyon-ec2-0,56939)
0714-165159.259 SS Trying to register BlockManager
0714-165159.265 SS Registering block manager tachyon-ec2-0:56939 with 326.7 MB RAM
0714-165159.266 SS Registered BlockManager
0714-165159.316 SS Broadcast server started at http://10.190.33.193:60503
0714-165159.326 SS Registered MapOutputTrackerActor actor
0714-165159.334 SS HTTP File server directory is /tmp/spark-4ebe3ea5-6bd8-40d6-a53c-c7ecc2849726
0714-165159.805 SS IoWorker thread 'spray-io-worker-0' started
0714-165200.998 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:43463
0714-165201.001 SS Started BlockManager web UI at http://tachyon-ec2-0:43463
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("tachyon://localhost:19998/hit_data.tsv.3000000.gz")
0714-165203.767 SS ensureFreeSpace(58447) called with curMem=0, maxMem=342526525
0714-165203.770 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-165204.435 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-165204.439 SS Snappy native library not loaded
0714-165204.486 SS 20217 63 Thread-37 |        Trying to connect master @ localhost/127.0.0.1:19998
0714-165204.550 SS 20217 63 Thread-37 |          User registered at the master localhost/127.0.0.1:19998 got UserId 1
0714-165204.551 SS 20217 63 Thread-37 |        Trying to get local worker host : tachyon-ec2-0
0714-165204.570 SS 20217 63 Thread-37 |        Connecting local worker @ tachyon-ec2-0/10.190.33.193:29998
0714-165206.313 SS Total input paths to process : 1
0714-165208.762 SS Starting job: count at <console>:15
0714-165208.784 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-165208.786 SS Final stage: Stage 0 (textFile at <console>:12)
0714-165208.787 SS Parents of final stage: List()
0714-165208.803 SS Missing parents: List()
0714-165208.809 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-165208.824 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-165208.832 SS Running ResultTask(0, 0)
0714-165208.891 SS Size of task 0 is 1442 bytes
0714-165208.992 SS 20217 66 pool-1-thread-1 |          /mnt/ramdisk/tachyonworker/2 is not on local disk.
0714-165209.001 SS 20217 66 pool-1-thread-1 |          Try to find and read from remote workers.
0714-165209.122 SS 20217 66 pool-1-thread-1 |          fileLocations: [NetAddress(mHost:localhost, mPort:-1)]
0714-165209.341 SS Opening 's3n://2012-05-19-sample/hit_data.tsv.3000000.gz' for reading
0714-165209.477 SS 20217 66 pool-1-thread-1 |          Folder /mnt/ramdisk/tachyonworker/users/1 was created!
0714-165209.480 SS 20217 66 pool-1-thread-1 |        File /mnt/ramdisk/tachyonworker/users/1/2 was created!
0714-165228.409 SS Got brand-new decompressor
0714-165307.625 SS Finished ResultTask(0, 0)
0714-165307.629 SS Completed ResultTask(0, 0)
0714-165307.632 SS Stage 0 (textFile at <console>:12) finished in 58.800 s
0714-165307.634 SS Job finished: count at <console>:15, took 58.866807064 s
res0: Long = 3000314

scala> s.count()
0714-165307.963 SS Starting job: count at <console>:15
0714-165307.964 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-165307.964 SS Final stage: Stage 1 (textFile at <console>:12)
0714-165307.964 SS Parents of final stage: List()
0714-165307.966 SS Missing parents: List()
0714-165307.967 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-165307.967 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-165307.968 SS Running ResultTask(1, 0)
0714-165307.969 SS Size of task 0 is 1445 bytes
0714-165308.004 SS Got brand-new decompressor
0714-165346.735 SS Finished ResultTask(1, 0)
0714-165346.736 SS Completed ResultTask(1, 0)
0714-165346.740 SS Stage 1 (textFile at <console>:12) finished in 38.768 s
0714-165346.740 SS Job finished: count at <console>:15, took 38.776225286 s
res1: Long = 3000314

scala> s.count()
0714-165347.071 SS Starting job: count at <console>:15
0714-165347.072 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-165347.072 SS Final stage: Stage 2 (textFile at <console>:12)
0714-165347.072 SS Parents of final stage: List()
0714-165347.074 SS Missing parents: List()
0714-165347.075 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-165347.075 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-165347.076 SS Running ResultTask(2, 0)
0714-165347.077 SS Size of task 0 is 1445 bytes
0714-165347.115 SS Got brand-new decompressor
0714-165425.018 SS Finished ResultTask(2, 0)
0714-165425.018 SS Completed ResultTask(2, 0)
0714-165425.019 SS Stage 2 (textFile at <console>:12) finished in 37.939 s
0714-165425.019 SS Job finished: count at <console>:15, took 37.946948247 s
res2: Long = 3000314

scala> s.count()
0714-165425.361 SS Starting job: count at <console>:15
0714-165425.362 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-165425.362 SS Final stage: Stage 3 (textFile at <console>:12)
0714-165425.362 SS Parents of final stage: List()
0714-165425.364 SS Missing parents: List()
0714-165425.365 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-165425.365 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-165425.366 SS Running ResultTask(3, 0)
0714-165425.368 SS Size of task 0 is 1445 bytes
0714-165425.399 SS Got brand-new decompressor
0714-165503.659 SS Finished ResultTask(3, 0)
0714-165503.660 SS Completed ResultTask(3, 0)
0714-165503.660 SS Stage 3 (textFile at <console>:12) finished in 38.289 s
0714-165503.660 SS Job finished: count at <console>:15, took 38.298592444 s
res3: Long = 3000314

scala> s.count()
0714-165503.920 SS Starting job: count at <console>:15
0714-165503.920 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-165503.921 SS Final stage: Stage 4 (textFile at <console>:12)
0714-165503.921 SS Parents of final stage: List()
0714-165503.922 SS Missing parents: List()
0714-165503.923 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-165503.924 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-165503.924 SS Running ResultTask(4, 0)
0714-165503.926 SS Size of task 0 is 1445 bytes
0714-165503.973 SS Got brand-new decompressor
0714-165541.976 SS Finished ResultTask(4, 0)
0714-165541.976 SS Completed ResultTask(4, 0)
0714-165541.977 SS Stage 4 (textFile at <console>:12) finished in 38.049 s
0714-165541.977 SS Job finished: count at <console>:15, took 38.056706458 s
res4: Long = 3000314

scala> Killed 1 processes
Killed 1 processes
localhost: Killed 0 processes
Formatting Tachyon @ localhost
0714-165543.587 TU Deleting /mnt/tachyon/tachyon/tachyon_checkpoint.data
0714-165543.592 TU Deleting /mnt/tachyon/tachyon/tachyon_log.data
0714-165544.623 TU Formatting s3n://2012-05-19-sample/tachyon/data
0714-165545.914 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-165546.101 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-165546.114 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-165546.148 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-165546.175 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-165546.186 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-165546.232 TU Formatting s3n://2012-05-19-sample/tachyon/workers
0714-165546.244 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-165546.344 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-165546.359 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200
0714-165546.397 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-165546.440 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-165546.455 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200

spark-shell count

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-165603.010 SS Slf4jEventHandler started
0714-165603.684 SS Registered BlockManagerMaster Actor
0714-165603.748 SS MemoryStore started with capacity 326.7 MB.
0714-165603.767 SS Created local directory at /tmp/spark-local-20130714165603-a905
0714-165603.838 SS Bound socket to port 47600 with id = ConnectionManagerId(tachyon-ec2-0,47600)
0714-165603.858 SS Trying to register BlockManager
0714-165603.865 SS Registering block manager tachyon-ec2-0:47600 with 326.7 MB RAM
0714-165603.866 SS Registered BlockManager
0714-165603.913 SS Broadcast server started at http://10.190.33.193:56113
0714-165603.926 SS Registered MapOutputTrackerActor actor
0714-165603.935 SS HTTP File server directory is /tmp/spark-c7fe18b2-f310-47be-8357-e35fc7aebb0c
0714-165604.352 SS IoWorker thread 'spray-io-worker-0' started
0714-165605.517 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:45997
0714-165605.520 SS Started BlockManager web UI at http://tachyon-ec2-0:45997
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/data/hit_data.tsv.4000000.gz")
0714-165608.118 SS ensureFreeSpace(58423) called with curMem=0, maxMem=342526525
0714-165608.121 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-165608.737 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-165608.745 SS Snappy native library not loaded
0714-165608.772 SS Total input paths to process : 1
0714-165608.792 SS Starting job: count at <console>:15
0714-165608.802 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-165608.808 SS Final stage: Stage 0 (textFile at <console>:12)
0714-165608.808 SS Parents of final stage: List()
0714-165608.815 SS Missing parents: List()
0714-165608.818 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-165608.831 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-165608.846 SS Running ResultTask(0, 0)
0714-165609.034 SS Size of task 0 is 1431 bytes
0714-165609.243 SS Got brand-new decompressor
0714-165655.741 SS Exception in task 0
java.io.IOException: stored gzip size doesn't match decompressed size
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeTrailerState(BuiltInGzipDecompressor.java:389)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:224)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:83)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:77)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:176)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:43)
	at spark.rdd.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:84)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:492)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:490)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.scheduler.ResultTask.run(ResultTask.scala:76)
	at spark.scheduler.local.LocalScheduler.runTask$1(LocalScheduler.scala:74)
	at spark.scheduler.local.LocalScheduler$$anon$1.run(LocalScheduler.scala:50)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
0714-165655.756 SS Failed to run count at <console>:15
spark.SparkException: Job failed: ResultTask(0, 0) failed: ExceptionFailure(java.io.IOException: stored gzip size doesn't match decompressed size)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:629)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:627)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:60)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:627)
	at spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:588)
	at spark.scheduler.DAGScheduler.processEvent(DAGScheduler.scala:294)
	at spark.scheduler.DAGScheduler.spark$scheduler$DAGScheduler$$run(DAGScheduler.scala:358)
	at spark.scheduler.DAGScheduler$$anon$1.run(DAGScheduler.scala:102)

scala> s.count()
0714-165656.347 SS Starting job: count at <console>:15
0714-165656.348 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-165656.348 SS Final stage: Stage 1 (textFile at <console>:12)
0714-165656.348 SS Parents of final stage: List()
0714-165656.350 SS Missing parents: List()
0714-165656.350 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-165656.351 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-165656.351 SS Running ResultTask(1, 0)
0714-165656.353 SS Size of task 0 is 1431 bytes
0714-165656.387 SS Got brand-new decompressor
0714-165741.980 SS Exception in task 0
java.io.IOException: stored gzip size doesn't match decompressed size
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeTrailerState(BuiltInGzipDecompressor.java:389)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:224)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:83)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:77)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:176)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:43)
	at spark.rdd.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:84)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:492)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:490)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.scheduler.ResultTask.run(ResultTask.scala:76)
	at spark.scheduler.local.LocalScheduler.runTask$1(LocalScheduler.scala:74)
	at spark.scheduler.local.LocalScheduler$$anon$1.run(LocalScheduler.scala:50)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
0714-165741.990 SS Failed to run count at <console>:15
spark.SparkException: Job failed: ResultTask(1, 0) failed: ExceptionFailure(java.io.IOException: stored gzip size doesn't match decompressed size)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:629)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:627)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:60)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:627)
	at spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:588)
	at spark.scheduler.DAGScheduler.processEvent(DAGScheduler.scala:294)
	at spark.scheduler.DAGScheduler.spark$scheduler$DAGScheduler$$run(DAGScheduler.scala:358)
	at spark.scheduler.DAGScheduler$$anon$1.run(DAGScheduler.scala:102)

scala> s.count()
0714-165742.656 SS Starting job: count at <console>:15
0714-165742.656 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-165742.656 SS Final stage: Stage 2 (textFile at <console>:12)
0714-165742.656 SS Parents of final stage: List()
0714-165742.658 SS Missing parents: List()
0714-165742.659 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-165742.659 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-165742.660 SS Running ResultTask(2, 0)
0714-165742.662 SS Size of task 0 is 1431 bytes
0714-165742.727 SS Got brand-new decompressor
0714-165827.633 SS Exception in task 0
java.io.IOException: stored gzip size doesn't match decompressed size
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeTrailerState(BuiltInGzipDecompressor.java:389)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:224)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:83)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:77)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:176)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:43)
	at spark.rdd.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:84)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:492)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:490)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.scheduler.ResultTask.run(ResultTask.scala:76)
	at spark.scheduler.local.LocalScheduler.runTask$1(LocalScheduler.scala:74)
	at spark.scheduler.local.LocalScheduler$$anon$1.run(LocalScheduler.scala:50)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
0714-165827.645 SS Failed to run count at <console>:15
spark.SparkException: Job failed: ResultTask(2, 0) failed: ExceptionFailure(java.io.IOException: stored gzip size doesn't match decompressed size)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:629)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:627)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:60)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:627)
	at spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:588)
	at spark.scheduler.DAGScheduler.processEvent(DAGScheduler.scala:294)
	at spark.scheduler.DAGScheduler.spark$scheduler$DAGScheduler$$run(DAGScheduler.scala:358)
	at spark.scheduler.DAGScheduler$$anon$1.run(DAGScheduler.scala:102)

scala> s.count()
0714-165828.309 SS Starting job: count at <console>:15
0714-165828.315 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-165828.315 SS Final stage: Stage 3 (textFile at <console>:12)
0714-165828.315 SS Parents of final stage: List()
0714-165828.317 SS Missing parents: List()
0714-165828.318 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-165828.319 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-165828.319 SS Running ResultTask(3, 0)
0714-165828.321 SS Size of task 0 is 1431 bytes
0714-165828.409 SS Got brand-new decompressor
0714-165913.187 SS Exception in task 0
java.io.IOException: stored gzip size doesn't match decompressed size
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeTrailerState(BuiltInGzipDecompressor.java:389)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:224)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:83)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:77)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:176)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:43)
	at spark.rdd.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:84)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:492)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:490)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.scheduler.ResultTask.run(ResultTask.scala:76)
	at spark.scheduler.local.LocalScheduler.runTask$1(LocalScheduler.scala:74)
	at spark.scheduler.local.LocalScheduler$$anon$1.run(LocalScheduler.scala:50)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
0714-165913.193 SS Failed to run count at <console>:15
spark.SparkException: Job failed: ResultTask(3, 0) failed: ExceptionFailure(java.io.IOException: stored gzip size doesn't match decompressed size)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:629)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:627)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:60)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:627)
	at spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:588)
	at spark.scheduler.DAGScheduler.processEvent(DAGScheduler.scala:294)
	at spark.scheduler.DAGScheduler.spark$scheduler$DAGScheduler$$run(DAGScheduler.scala:358)
	at spark.scheduler.DAGScheduler$$anon$1.run(DAGScheduler.scala:102)

scala> s.count()
0714-165913.760 SS Starting job: count at <console>:15
0714-165913.761 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-165913.761 SS Final stage: Stage 4 (textFile at <console>:12)
0714-165913.761 SS Parents of final stage: List()
0714-165913.763 SS Missing parents: List()
0714-165913.764 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-165913.764 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-165913.765 SS Running ResultTask(4, 0)
0714-165913.766 SS Size of task 0 is 1431 bytes
0714-165913.796 SS Got brand-new decompressor
0714-165958.160 SS Exception in task 0
java.io.IOException: stored gzip size doesn't match decompressed size
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeTrailerState(BuiltInGzipDecompressor.java:389)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:224)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:83)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:77)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:176)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:43)
	at spark.rdd.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:84)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:492)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:490)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.scheduler.ResultTask.run(ResultTask.scala:76)
	at spark.scheduler.local.LocalScheduler.runTask$1(LocalScheduler.scala:74)
	at spark.scheduler.local.LocalScheduler$$anon$1.run(LocalScheduler.scala:50)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
0714-165958.167 SS Failed to run count at <console>:15
spark.SparkException: Job failed: ResultTask(4, 0) failed: ExceptionFailure(java.io.IOException: stored gzip size doesn't match decompressed size)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:629)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:627)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:60)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:627)
	at spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:588)
	at spark.scheduler.DAGScheduler.processEvent(DAGScheduler.scala:294)
	at spark.scheduler.DAGScheduler.spark$scheduler$DAGScheduler$$run(DAGScheduler.scala:358)
	at spark.scheduler.DAGScheduler$$anon$1.run(DAGScheduler.scala:102)

scala> restaring tachyon
Killed 0 processes
Killed 0 processes
localhost: Killed 0 processes
Mounting ramfs on Linux...
TACHYON_RAM_FOLDER was not set. Using the default one: /mnt/ramdisk
Formatting RamFS: /mnt/ramdisk
Starting master @ localhost
Starting worker @ tachyon-ec2-0

spark-shell count
21071 tachyon.Master
21084 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-170019.889 SS Slf4jEventHandler started
0714-170020.572 SS Registered BlockManagerMaster Actor
0714-170020.650 SS MemoryStore started with capacity 326.7 MB.
0714-170020.659 SS Created local directory at /tmp/spark-local-20130714170020-b193
0714-170020.725 SS Bound socket to port 49383 with id = ConnectionManagerId(tachyon-ec2-0,49383)
0714-170020.744 SS Trying to register BlockManager
0714-170020.748 SS Registering block manager tachyon-ec2-0:49383 with 326.7 MB RAM
0714-170020.749 SS Registered BlockManager
0714-170020.800 SS Broadcast server started at http://10.190.33.193:49891
0714-170020.814 SS Registered MapOutputTrackerActor actor
0714-170020.819 SS HTTP File server directory is /tmp/spark-28ae58fd-5e84-4ff9-8435-bed8a997bbf3
0714-170021.302 SS IoWorker thread 'spray-io-worker-0' started
0714-170022.450 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:54551
0714-170022.452 SS Started BlockManager web UI at http://tachyon-ec2-0:54551
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("tachyon://localhost:19998/hit_data.tsv.4000000.gz")
0714-170025.044 SS ensureFreeSpace(58447) called with curMem=0, maxMem=342526525
0714-170025.047 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-170025.705 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-170025.706 SS Snappy native library not loaded
0714-170025.757 SS 21132 62 Thread-37 |        Trying to connect master @ localhost/127.0.0.1:19998
0714-170025.816 SS 21132 62 Thread-37 |          User registered at the master localhost/127.0.0.1:19998 got UserId 1
0714-170025.816 SS 21132 62 Thread-37 |        Trying to get local worker host : tachyon-ec2-0
0714-170025.833 SS 21132 62 Thread-37 |        Connecting local worker @ tachyon-ec2-0/10.190.33.193:29998
0714-170027.502 SS Total input paths to process : 1
0714-170029.794 SS Starting job: count at <console>:15
0714-170029.815 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170029.816 SS Final stage: Stage 0 (textFile at <console>:12)
0714-170029.817 SS Parents of final stage: List()
0714-170029.827 SS Missing parents: List()
0714-170029.830 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170029.849 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-170029.856 SS Running ResultTask(0, 0)
0714-170029.915 SS Size of task 0 is 1442 bytes
0714-170030.010 SS 21132 65 pool-1-thread-1 |          /mnt/ramdisk/tachyonworker/2 is not on local disk.
0714-170030.020 SS 21132 65 pool-1-thread-1 |          Try to find and read from remote workers.
0714-170030.142 SS 21132 65 pool-1-thread-1 |          fileLocations: [NetAddress(mHost:localhost, mPort:-1)]
0714-170030.354 SS Opening 's3n://2012-05-19-sample/hit_data.tsv.4000000.gz' for reading
0714-170030.531 SS 21132 65 pool-1-thread-1 |          Folder /mnt/ramdisk/tachyonworker/users/1 was created!
0714-170030.532 SS 21132 65 pool-1-thread-1 |        File /mnt/ramdisk/tachyonworker/users/1/2 was created!
0714-170057.233 SS Got brand-new decompressor
0714-170149.253 SS Exception in task 0
java.io.IOException: stored gzip size doesn't match decompressed size
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeTrailerState(BuiltInGzipDecompressor.java:389)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:224)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:83)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:77)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:176)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:43)
	at spark.rdd.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:84)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:492)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:490)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.scheduler.ResultTask.run(ResultTask.scala:76)
	at spark.scheduler.local.LocalScheduler.runTask$1(LocalScheduler.scala:74)
	at spark.scheduler.local.LocalScheduler$$anon$1.run(LocalScheduler.scala:50)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
0714-170149.286 SS Failed to run count at <console>:15
spark.SparkException: Job failed: ResultTask(0, 0) failed: ExceptionFailure(java.io.IOException: stored gzip size doesn't match decompressed size)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:629)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:627)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:60)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:627)
	at spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:588)
	at spark.scheduler.DAGScheduler.processEvent(DAGScheduler.scala:294)
	at spark.scheduler.DAGScheduler.spark$scheduler$DAGScheduler$$run(DAGScheduler.scala:358)
	at spark.scheduler.DAGScheduler$$anon$1.run(DAGScheduler.scala:102)

scala> s.count()
0714-170150.157 SS Starting job: count at <console>:15
0714-170150.164 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170150.164 SS Final stage: Stage 1 (textFile at <console>:12)
0714-170150.164 SS Parents of final stage: List()
0714-170150.166 SS Missing parents: List()
0714-170150.167 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170150.167 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-170150.168 SS Running ResultTask(1, 0)
0714-170150.170 SS Size of task 0 is 1442 bytes
0714-170150.228 SS Got brand-new decompressor
0714-170241.976 SS Exception in task 0
java.io.IOException: stored gzip size doesn't match decompressed size
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeTrailerState(BuiltInGzipDecompressor.java:389)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:224)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:83)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:77)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:176)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:43)
	at spark.rdd.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:84)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:492)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:490)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.scheduler.ResultTask.run(ResultTask.scala:76)
	at spark.scheduler.local.LocalScheduler.runTask$1(LocalScheduler.scala:74)
	at spark.scheduler.local.LocalScheduler$$anon$1.run(LocalScheduler.scala:50)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
0714-170241.983 SS Failed to run count at <console>:15
spark.SparkException: Job failed: ResultTask(1, 0) failed: ExceptionFailure(java.io.IOException: stored gzip size doesn't match decompressed size)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:629)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:627)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:60)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:627)
	at spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:588)
	at spark.scheduler.DAGScheduler.processEvent(DAGScheduler.scala:294)
	at spark.scheduler.DAGScheduler.spark$scheduler$DAGScheduler$$run(DAGScheduler.scala:358)
	at spark.scheduler.DAGScheduler$$anon$1.run(DAGScheduler.scala:102)

scala> s.count()
0714-170242.635 SS Starting job: count at <console>:15
0714-170242.635 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170242.635 SS Final stage: Stage 2 (textFile at <console>:12)
0714-170242.635 SS Parents of final stage: List()
0714-170242.638 SS Missing parents: List()
0714-170242.638 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170242.639 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-170242.639 SS Running ResultTask(2, 0)
0714-170242.641 SS Size of task 0 is 1442 bytes
0714-170242.679 SS Got brand-new decompressor
0714-170333.666 SS Exception in task 0
java.io.IOException: stored gzip size doesn't match decompressed size
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeTrailerState(BuiltInGzipDecompressor.java:389)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:224)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:83)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:77)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:176)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:43)
	at spark.rdd.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:84)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:492)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:490)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.scheduler.ResultTask.run(ResultTask.scala:76)
	at spark.scheduler.local.LocalScheduler.runTask$1(LocalScheduler.scala:74)
	at spark.scheduler.local.LocalScheduler$$anon$1.run(LocalScheduler.scala:50)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
0714-170333.673 SS Failed to run count at <console>:15
spark.SparkException: Job failed: ResultTask(2, 0) failed: ExceptionFailure(java.io.IOException: stored gzip size doesn't match decompressed size)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:629)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:627)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:60)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:627)
	at spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:588)
	at spark.scheduler.DAGScheduler.processEvent(DAGScheduler.scala:294)
	at spark.scheduler.DAGScheduler.spark$scheduler$DAGScheduler$$run(DAGScheduler.scala:358)
	at spark.scheduler.DAGScheduler$$anon$1.run(DAGScheduler.scala:102)

scala> s.count()
0714-170334.312 SS Starting job: count at <console>:15
0714-170334.313 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170334.313 SS Final stage: Stage 3 (textFile at <console>:12)
0714-170334.313 SS Parents of final stage: List()
0714-170334.315 SS Missing parents: List()
0714-170334.315 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170334.316 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-170334.316 SS Running ResultTask(3, 0)
0714-170334.318 SS Size of task 0 is 1442 bytes
0714-170334.404 SS Got brand-new decompressor
0714-170425.079 SS Exception in task 0
java.io.IOException: stored gzip size doesn't match decompressed size
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeTrailerState(BuiltInGzipDecompressor.java:389)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:224)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:83)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:77)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:176)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:43)
	at spark.rdd.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:84)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:492)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:490)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.scheduler.ResultTask.run(ResultTask.scala:76)
	at spark.scheduler.local.LocalScheduler.runTask$1(LocalScheduler.scala:74)
	at spark.scheduler.local.LocalScheduler$$anon$1.run(LocalScheduler.scala:50)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
0714-170425.085 SS Failed to run count at <console>:15
spark.SparkException: Job failed: ResultTask(3, 0) failed: ExceptionFailure(java.io.IOException: stored gzip size doesn't match decompressed size)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:629)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:627)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:60)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:627)
	at spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:588)
	at spark.scheduler.DAGScheduler.processEvent(DAGScheduler.scala:294)
	at spark.scheduler.DAGScheduler.spark$scheduler$DAGScheduler$$run(DAGScheduler.scala:358)
	at spark.scheduler.DAGScheduler$$anon$1.run(DAGScheduler.scala:102)

scala> s.count()
0714-170425.782 SS Starting job: count at <console>:15
0714-170425.783 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170425.783 SS Final stage: Stage 4 (textFile at <console>:12)
0714-170425.783 SS Parents of final stage: List()
0714-170425.785 SS Missing parents: List()
0714-170425.786 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170425.786 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-170425.787 SS Running ResultTask(4, 0)
0714-170425.789 SS Size of task 0 is 1442 bytes
0714-170425.849 SS Got brand-new decompressor
0714-170516.252 SS Exception in task 0
java.io.IOException: stored gzip size doesn't match decompressed size
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeTrailerState(BuiltInGzipDecompressor.java:389)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:224)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:83)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:77)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:176)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:43)
	at spark.rdd.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:84)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:492)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:490)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.scheduler.ResultTask.run(ResultTask.scala:76)
	at spark.scheduler.local.LocalScheduler.runTask$1(LocalScheduler.scala:74)
	at spark.scheduler.local.LocalScheduler$$anon$1.run(LocalScheduler.scala:50)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
0714-170516.258 SS Failed to run count at <console>:15
spark.SparkException: Job failed: ResultTask(4, 0) failed: ExceptionFailure(java.io.IOException: stored gzip size doesn't match decompressed size)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:629)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:627)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:60)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:627)
	at spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:588)
	at spark.scheduler.DAGScheduler.processEvent(DAGScheduler.scala:294)
	at spark.scheduler.DAGScheduler.spark$scheduler$DAGScheduler$$run(DAGScheduler.scala:358)
	at spark.scheduler.DAGScheduler$$anon$1.run(DAGScheduler.scala:102)

scala> Killed 1 processes
Killed 1 processes
localhost: Killed 0 processes
Formatting Tachyon @ localhost
0714-170519.291 TU Deleting /mnt/tachyon/tachyon/tachyon_checkpoint.data
0714-170519.297 TU Deleting /mnt/tachyon/tachyon/tachyon_log.data
0714-170520.469 TU Formatting s3n://2012-05-19-sample/tachyon/data
0714-170521.786 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-170522.164 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-170522.187 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-170522.264 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-170522.478 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-170522.500 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-170522.754 TU Formatting s3n://2012-05-19-sample/tachyon/workers
0714-170522.779 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-170522.911 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-170522.933 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200
0714-170522.977 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-170523.019 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-170523.041 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200

run #: 1

spark-shell count

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-170540.702 SS Slf4jEventHandler started
0714-170541.384 SS Registered BlockManagerMaster Actor
0714-170541.457 SS MemoryStore started with capacity 326.7 MB.
0714-170541.471 SS Created local directory at /tmp/spark-local-20130714170541-aee9
0714-170541.523 SS Bound socket to port 52821 with id = ConnectionManagerId(tachyon-ec2-0,52821)
0714-170541.550 SS Trying to register BlockManager
0714-170541.554 SS Registering block manager tachyon-ec2-0:52821 with 326.7 MB RAM
0714-170541.555 SS Registered BlockManager
0714-170541.604 SS Broadcast server started at http://10.190.33.193:50094
0714-170541.614 SS Registered MapOutputTrackerActor actor
0714-170541.623 SS HTTP File server directory is /tmp/spark-5713838e-13e5-4a86-ba7a-33ddd62060a7
0714-170542.040 SS IoWorker thread 'spray-io-worker-0' started
0714-170543.256 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:46625
0714-170543.258 SS Started BlockManager web UI at http://tachyon-ec2-0:46625
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/data/hit_data.tsv.100.gz")
0714-170545.821 SS ensureFreeSpace(58415) called with curMem=0, maxMem=342526525
0714-170545.824 SS Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-170546.458 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-170546.463 SS Snappy native library not loaded
0714-170546.486 SS Total input paths to process : 1
0714-170546.512 SS Starting job: count at <console>:15
0714-170546.519 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170546.524 SS Final stage: Stage 0 (textFile at <console>:12)
0714-170546.524 SS Parents of final stage: List()
0714-170546.532 SS Missing parents: List()
0714-170546.535 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170546.549 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-170546.565 SS Running ResultTask(0, 0)
0714-170546.790 SS Size of task 0 is 1427 bytes
0714-170546.965 SS Got brand-new decompressor
0714-170547.016 SS Finished ResultTask(0, 0)
0714-170547.018 SS Completed ResultTask(0, 0)
0714-170547.021 SS Stage 0 (textFile at <console>:12) finished in 0.456 s
0714-170547.022 SS Job finished: count at <console>:15, took 0.510035364 s
res0: Long = 100

scala> s.count()
0714-170547.444 SS Starting job: count at <console>:15
0714-170547.445 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170547.445 SS Final stage: Stage 1 (textFile at <console>:12)
0714-170547.445 SS Parents of final stage: List()
0714-170547.447 SS Missing parents: List()
0714-170547.447 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170547.448 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-170547.448 SS Running ResultTask(1, 0)
0714-170547.450 SS Size of task 0 is 1430 bytes
0714-170547.528 SS Got brand-new decompressor
0714-170547.541 SS Finished ResultTask(1, 0)
0714-170547.541 SS Completed ResultTask(1, 0)
0714-170547.542 SS Stage 1 (textFile at <console>:12) finished in 0.090 s
0714-170547.542 SS Job finished: count at <console>:15, took 0.097342007 s
res1: Long = 100

scala> s.count()
0714-170547.877 SS Starting job: count at <console>:15
0714-170547.877 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170547.877 SS Final stage: Stage 2 (textFile at <console>:12)
0714-170547.877 SS Parents of final stage: List()
0714-170547.879 SS Missing parents: List()
0714-170547.880 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170547.881 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-170547.881 SS Running ResultTask(2, 0)
0714-170547.883 SS Size of task 0 is 1430 bytes
0714-170547.960 SS Got brand-new decompressor
0714-170547.963 SS Finished ResultTask(2, 0)
0714-170547.965 SS Completed ResultTask(2, 0)
0714-170547.965 SS Stage 2 (textFile at <console>:12) finished in 0.082 s
0714-170547.966 SS Job finished: count at <console>:15, took 0.088503601 s
res2: Long = 100

scala> s.count()
0714-170548.647 SS Starting job: count at <console>:15
0714-170548.650 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170548.650 SS Final stage: Stage 3 (textFile at <console>:12)
0714-170548.650 SS Parents of final stage: List()
0714-170548.652 SS Missing parents: List()
0714-170548.653 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170548.654 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-170548.654 SS Running ResultTask(3, 0)
0714-170548.656 SS Size of task 0 is 1430 bytes
0714-170548.689 SS Got brand-new decompressor
0714-170548.691 SS Finished ResultTask(3, 0)
0714-170548.692 SS Completed ResultTask(3, 0)
0714-170548.692 SS Stage 3 (textFile at <console>:12) finished in 0.036 s
0714-170548.692 SS Job finished: count at <console>:15, took 0.042430547 s
res3: Long = 100

scala> s.count()
0714-170548.998 SS Starting job: count at <console>:15
0714-170548.998 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170548.998 SS Final stage: Stage 4 (textFile at <console>:12)
0714-170548.999 SS Parents of final stage: List()
0714-170549.000 SS Missing parents: List()
0714-170549.001 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170549.002 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-170549.003 SS Running ResultTask(4, 0)
0714-170549.005 SS Size of task 0 is 1430 bytes
0714-170549.063 SS Got brand-new decompressor
0714-170549.066 SS Finished ResultTask(4, 0)
0714-170549.066 SS Completed ResultTask(4, 0)
0714-170549.066 SS Stage 4 (textFile at <console>:12) finished in 0.059 s
0714-170549.067 SS Job finished: count at <console>:15, took 0.068463923 s
res4: Long = 100

scala> restaring tachyon
Killed 0 processes
Killed 0 processes
localhost: Killed 0 processes
Mounting ramfs on Linux...
TACHYON_RAM_FOLDER was not set. Using the default one: /mnt/ramdisk
Formatting RamFS: /mnt/ramdisk
Starting master @ localhost
Starting worker @ tachyon-ec2-0

spark-shell count
21961 tachyon.Master
21974 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-170610.690 SS Slf4jEventHandler started
0714-170611.392 SS Registered BlockManagerMaster Actor
0714-170611.437 SS MemoryStore started with capacity 326.7 MB.
0714-170611.446 SS Created local directory at /tmp/spark-local-20130714170611-177d
0714-170611.511 SS Bound socket to port 38739 with id = ConnectionManagerId(tachyon-ec2-0,38739)
0714-170611.532 SS Trying to register BlockManager
0714-170611.537 SS Registering block manager tachyon-ec2-0:38739 with 326.7 MB RAM
0714-170611.538 SS Registered BlockManager
0714-170611.588 SS Broadcast server started at http://10.190.33.193:38466
0714-170611.602 SS Registered MapOutputTrackerActor actor
0714-170611.607 SS HTTP File server directory is /tmp/spark-638b6352-9903-4507-a3c6-a69c7464a4c1
0714-170612.088 SS IoWorker thread 'spray-io-worker-0' started
0714-170613.288 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:57054
0714-170613.290 SS Started BlockManager web UI at http://tachyon-ec2-0:57054
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("tachyon://localhost:19998/hit_data.tsv.100.gz")
0714-170615.919 SS ensureFreeSpace(58439) called with curMem=0, maxMem=342526525
0714-170615.922 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-170616.549 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-170616.551 SS Snappy native library not loaded
0714-170616.593 SS 22022 62 Thread-37 |        Trying to connect master @ localhost/127.0.0.1:19998
0714-170616.656 SS 22022 62 Thread-37 |          User registered at the master localhost/127.0.0.1:19998 got UserId 1
0714-170616.656 SS 22022 62 Thread-37 |        Trying to get local worker host : tachyon-ec2-0
0714-170616.672 SS 22022 62 Thread-37 |        Connecting local worker @ tachyon-ec2-0/10.190.33.193:29998
0714-170618.355 SS Total input paths to process : 1
0714-170620.668 SS Starting job: count at <console>:15
0714-170620.677 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170620.679 SS Final stage: Stage 0 (textFile at <console>:12)
0714-170620.680 SS Parents of final stage: List()
0714-170620.691 SS Missing parents: List()
0714-170620.694 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170620.704 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-170620.711 SS Running ResultTask(0, 0)
0714-170620.773 SS Size of task 0 is 1438 bytes
0714-170620.873 SS 22022 65 pool-1-thread-1 |          /mnt/ramdisk/tachyonworker/2 is not on local disk.
0714-170620.895 SS 22022 65 pool-1-thread-1 |          Try to find and read from remote workers.
0714-170621.076 SS 22022 65 pool-1-thread-1 |          fileLocations: [NetAddress(mHost:localhost, mPort:-1)]
0714-170621.249 SS Opening 's3n://2012-05-19-sample/hit_data.tsv.100.gz' for reading
0714-170621.321 SS 22022 65 pool-1-thread-1 |          Folder /mnt/ramdisk/tachyonworker/users/1 was created!
0714-170621.322 SS 22022 65 pool-1-thread-1 |        File /mnt/ramdisk/tachyonworker/users/1/2 was created!
0714-170621.404 SS Got brand-new decompressor
0714-170621.509 SS Finished ResultTask(0, 0)
0714-170621.526 SS Completed ResultTask(0, 0)
0714-170621.529 SS Stage 0 (textFile at <console>:12) finished in 0.817 s
0714-170621.531 SS Job finished: count at <console>:15, took 0.862562064 s
res0: Long = 100

scala> s.count()
0714-170621.952 SS Starting job: count at <console>:15
0714-170621.954 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170621.954 SS Final stage: Stage 1 (textFile at <console>:12)
0714-170621.954 SS Parents of final stage: List()
0714-170621.956 SS Missing parents: List()
0714-170621.956 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170621.957 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-170621.957 SS Running ResultTask(1, 0)
0714-170621.959 SS Size of task 0 is 1441 bytes
0714-170622.028 SS Got brand-new decompressor
0714-170622.039 SS Finished ResultTask(1, 0)
0714-170622.043 SS Completed ResultTask(1, 0)
0714-170622.044 SS Stage 1 (textFile at <console>:12) finished in 0.085 s
0714-170622.044 SS Job finished: count at <console>:15, took 0.090622007 s
res1: Long = 100

scala> s.count()
0714-170622.364 SS Starting job: count at <console>:15
0714-170622.365 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170622.365 SS Final stage: Stage 2 (textFile at <console>:12)
0714-170622.365 SS Parents of final stage: List()
0714-170622.367 SS Missing parents: List()
0714-170622.368 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170622.368 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-170622.369 SS Running ResultTask(2, 0)
0714-170622.370 SS Size of task 0 is 1441 bytes
0714-170622.407 SS Got brand-new decompressor
0714-170622.412 SS Finished ResultTask(2, 0)
0714-170622.413 SS Completed ResultTask(2, 0)
0714-170622.413 SS Stage 2 (textFile at <console>:12) finished in 0.042 s
0714-170622.413 SS Job finished: count at <console>:15, took 0.048640775 s
res2: Long = 100

scala> s.count()
0714-170622.914 SS Starting job: count at <console>:15
0714-170622.915 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170622.915 SS Final stage: Stage 3 (textFile at <console>:12)
0714-170622.915 SS Parents of final stage: List()
0714-170622.917 SS Missing parents: List()
0714-170622.917 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170622.918 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-170622.918 SS Running ResultTask(3, 0)
0714-170622.920 SS Size of task 0 is 1441 bytes
0714-170622.951 SS Got brand-new decompressor
0714-170622.956 SS Finished ResultTask(3, 0)
0714-170622.957 SS Completed ResultTask(3, 0)
0714-170622.957 SS Stage 3 (textFile at <console>:12) finished in 0.035 s
0714-170622.957 SS Job finished: count at <console>:15, took 0.042795036 s
res3: Long = 100

scala> s.count()
0714-170623.288 SS Starting job: count at <console>:15
0714-170623.288 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170623.288 SS Final stage: Stage 4 (textFile at <console>:12)
0714-170623.289 SS Parents of final stage: List()
0714-170623.290 SS Missing parents: List()
0714-170623.291 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170623.292 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-170623.292 SS Running ResultTask(4, 0)
0714-170623.294 SS Size of task 0 is 1441 bytes
0714-170623.355 SS Got brand-new decompressor
0714-170623.361 SS Finished ResultTask(4, 0)
0714-170623.361 SS Completed ResultTask(4, 0)
0714-170623.362 SS Stage 4 (textFile at <console>:12) finished in 0.066 s
0714-170623.362 SS Job finished: count at <console>:15, took 0.073645569 s
res4: Long = 100

scala> Killed 1 processes
Killed 1 processes
localhost: Killed 0 processes
Formatting Tachyon @ localhost
0714-170624.919 TU Deleting /mnt/tachyon/tachyon/tachyon_checkpoint.data
0714-170624.921 TU Deleting /mnt/tachyon/tachyon/tachyon_log.data
0714-170625.907 TU Formatting s3n://2012-05-19-sample/tachyon/data
0714-170627.234 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-170627.419 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-170627.446 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-170627.508 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-170627.559 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-170627.580 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-170627.860 TU Formatting s3n://2012-05-19-sample/tachyon/workers
0714-170627.970 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-170628.349 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-170628.366 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200
0714-170628.411 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-170628.465 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-170628.492 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200

spark-shell count

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-170645.673 SS Slf4jEventHandler started
0714-170646.348 SS Registered BlockManagerMaster Actor
0714-170646.425 SS MemoryStore started with capacity 326.7 MB.
0714-170646.444 SS Created local directory at /tmp/spark-local-20130714170646-075f
0714-170646.501 SS Bound socket to port 36893 with id = ConnectionManagerId(tachyon-ec2-0,36893)
0714-170646.526 SS Trying to register BlockManager
0714-170646.530 SS Registering block manager tachyon-ec2-0:36893 with 326.7 MB RAM
0714-170646.531 SS Registered BlockManager
0714-170646.584 SS Broadcast server started at http://10.190.33.193:48953
0714-170646.594 SS Registered MapOutputTrackerActor actor
0714-170646.602 SS HTTP File server directory is /tmp/spark-174fa7b3-1a34-4f82-8a84-ef44d385f755
0714-170647.031 SS IoWorker thread 'spray-io-worker-0' started
0714-170648.223 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:51721
0714-170648.226 SS Started BlockManager web UI at http://tachyon-ec2-0:51721
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/data/hit_data.tsv.1000.gz")
0714-170650.791 SS ensureFreeSpace(58415) called with curMem=0, maxMem=342526525
0714-170650.794 SS Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-170651.441 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-170651.447 SS Snappy native library not loaded
0714-170651.472 SS Total input paths to process : 1
0714-170651.491 SS Starting job: count at <console>:15
0714-170651.504 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170651.505 SS Final stage: Stage 0 (textFile at <console>:12)
0714-170651.505 SS Parents of final stage: List()
0714-170651.514 SS Missing parents: List()
0714-170651.517 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170651.529 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-170651.545 SS Running ResultTask(0, 0)
0714-170651.752 SS Size of task 0 is 1428 bytes
0714-170651.950 SS Got brand-new decompressor
0714-170652.049 SS Finished ResultTask(0, 0)
0714-170652.052 SS Completed ResultTask(0, 0)
0714-170652.054 SS Stage 0 (textFile at <console>:12) finished in 0.510 s
0714-170652.056 SS Job finished: count at <console>:15, took 0.564672003 s
res0: Long = 1000

scala> s.count()
0714-170652.432 SS Starting job: count at <console>:15
0714-170652.432 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170652.432 SS Final stage: Stage 1 (textFile at <console>:12)
0714-170652.433 SS Parents of final stage: List()
0714-170652.434 SS Missing parents: List()
0714-170652.435 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170652.436 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-170652.436 SS Running ResultTask(1, 0)
0714-170652.438 SS Size of task 0 is 1431 bytes
0714-170652.531 SS Got brand-new decompressor
0714-170652.551 SS Finished ResultTask(1, 0)
0714-170652.552 SS Completed ResultTask(1, 0)
0714-170652.552 SS Stage 1 (textFile at <console>:12) finished in 0.113 s
0714-170652.552 SS Job finished: count at <console>:15, took 0.120267503 s
res1: Long = 1000

scala> s.count()
0714-170652.856 SS Starting job: count at <console>:15
0714-170652.857 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170652.857 SS Final stage: Stage 2 (textFile at <console>:12)
0714-170652.857 SS Parents of final stage: List()
0714-170652.859 SS Missing parents: List()
0714-170652.859 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170652.860 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-170652.860 SS Running ResultTask(2, 0)
0714-170652.862 SS Size of task 0 is 1431 bytes
0714-170652.940 SS Got brand-new decompressor
0714-170652.993 SS Finished ResultTask(2, 0)
0714-170652.996 SS Completed ResultTask(2, 0)
0714-170652.996 SS Stage 2 (textFile at <console>:12) finished in 0.133 s
0714-170652.997 SS Job finished: count at <console>:15, took 0.140322592 s
res2: Long = 1000

scala> s.count()
0714-170653.675 SS Starting job: count at <console>:15
0714-170653.676 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170653.676 SS Final stage: Stage 3 (textFile at <console>:12)
0714-170653.676 SS Parents of final stage: List()
0714-170653.679 SS Missing parents: List()
0714-170653.679 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170653.680 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-170653.680 SS Running ResultTask(3, 0)
0714-170653.682 SS Size of task 0 is 1431 bytes
0714-170653.716 SS Got brand-new decompressor
0714-170653.730 SS Finished ResultTask(3, 0)
0714-170653.731 SS Completed ResultTask(3, 0)
0714-170653.731 SS Stage 3 (textFile at <console>:12) finished in 0.049 s
0714-170653.731 SS Job finished: count at <console>:15, took 0.055388588 s
res3: Long = 1000

scala> s.count()
0714-170654.011 SS Starting job: count at <console>:15
0714-170654.012 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170654.012 SS Final stage: Stage 4 (textFile at <console>:12)
0714-170654.012 SS Parents of final stage: List()
0714-170654.015 SS Missing parents: List()
0714-170654.016 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170654.017 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-170654.017 SS Running ResultTask(4, 0)
0714-170654.020 SS Size of task 0 is 1431 bytes
0714-170654.062 SS Got brand-new decompressor
0714-170654.079 SS Finished ResultTask(4, 0)
0714-170654.080 SS Completed ResultTask(4, 0)
0714-170654.080 SS Stage 4 (textFile at <console>:12) finished in 0.058 s
0714-170654.080 SS Job finished: count at <console>:15, took 0.068530201 s
res4: Long = 1000

scala> restaring tachyon
Killed 0 processes
Killed 0 processes
localhost: Killed 0 processes
Mounting ramfs on Linux...
TACHYON_RAM_FOLDER was not set. Using the default one: /mnt/ramdisk
Formatting RamFS: /mnt/ramdisk
Starting master @ localhost
Starting worker @ tachyon-ec2-0

spark-shell count
22610 tachyon.Master
22623 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-170715.382 SS Slf4jEventHandler started
0714-170716.076 SS Registered BlockManagerMaster Actor
0714-170716.126 SS MemoryStore started with capacity 326.7 MB.
0714-170716.134 SS Created local directory at /tmp/spark-local-20130714170716-3a76
0714-170716.200 SS Bound socket to port 34841 with id = ConnectionManagerId(tachyon-ec2-0,34841)
0714-170716.220 SS Trying to register BlockManager
0714-170716.225 SS Registering block manager tachyon-ec2-0:34841 with 326.7 MB RAM
0714-170716.226 SS Registered BlockManager
0714-170716.276 SS Broadcast server started at http://10.190.33.193:32797
0714-170716.285 SS Registered MapOutputTrackerActor actor
0714-170716.294 SS HTTP File server directory is /tmp/spark-9946ca89-9520-46b6-95d2-d47a6a13e9ec
0714-170716.759 SS IoWorker thread 'spray-io-worker-0' started
0714-170717.954 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:58590
0714-170717.957 SS Started BlockManager web UI at http://tachyon-ec2-0:58590
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("tachyon://localhost:19998/hit_data.tsv.1000.gz")
0714-170720.515 SS ensureFreeSpace(58439) called with curMem=0, maxMem=342526525
0714-170720.518 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-170721.190 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-170721.190 SS Snappy native library not loaded
0714-170721.230 SS 22671 62 Thread-37 |        Trying to connect master @ localhost/127.0.0.1:19998
0714-170721.292 SS 22671 62 Thread-37 |          User registered at the master localhost/127.0.0.1:19998 got UserId 1
0714-170721.292 SS 22671 62 Thread-37 |        Trying to get local worker host : tachyon-ec2-0
0714-170721.309 SS 22671 62 Thread-37 |        Connecting local worker @ tachyon-ec2-0/10.190.33.193:29998
0714-170722.965 SS Total input paths to process : 1
0714-170725.262 SS Starting job: count at <console>:15
0714-170725.276 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170725.277 SS Final stage: Stage 0 (textFile at <console>:12)
0714-170725.278 SS Parents of final stage: List()
0714-170725.291 SS Missing parents: List()
0714-170725.294 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170725.308 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-170725.313 SS Running ResultTask(0, 0)
0714-170725.372 SS Size of task 0 is 1439 bytes
0714-170725.472 SS 22671 65 pool-1-thread-1 |          /mnt/ramdisk/tachyonworker/2 is not on local disk.
0714-170725.482 SS 22671 65 pool-1-thread-1 |          Try to find and read from remote workers.
0714-170725.601 SS 22671 65 pool-1-thread-1 |          fileLocations: [NetAddress(mHost:localhost, mPort:-1)]
0714-170725.803 SS Opening 's3n://2012-05-19-sample/hit_data.tsv.1000.gz' for reading
0714-170725.884 SS 22671 65 pool-1-thread-1 |          Folder /mnt/ramdisk/tachyonworker/users/1 was created!
0714-170725.885 SS 22671 65 pool-1-thread-1 |        File /mnt/ramdisk/tachyonworker/users/1/2 was created!
0714-170726.052 SS Got brand-new decompressor
0714-170726.144 SS Finished ResultTask(0, 0)
0714-170726.149 SS Completed ResultTask(0, 0)
0714-170726.152 SS Stage 0 (textFile at <console>:12) finished in 0.839 s
0714-170726.153 SS Job finished: count at <console>:15, took 0.890023674 s
res0: Long = 1000

scala> s.count()
0714-170726.584 SS Starting job: count at <console>:15
0714-170726.585 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170726.585 SS Final stage: Stage 1 (textFile at <console>:12)
0714-170726.585 SS Parents of final stage: List()
0714-170726.587 SS Missing parents: List()
0714-170726.588 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170726.588 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-170726.589 SS Running ResultTask(1, 0)
0714-170726.591 SS Size of task 0 is 1442 bytes
0714-170726.661 SS Got brand-new decompressor
0714-170726.686 SS Finished ResultTask(1, 0)
0714-170726.687 SS Completed ResultTask(1, 0)
0714-170726.687 SS Stage 1 (textFile at <console>:12) finished in 0.096 s
0714-170726.687 SS Job finished: count at <console>:15, took 0.102330332 s
res1: Long = 1000

scala> s.count()
0714-170727.020 SS Starting job: count at <console>:15
0714-170727.020 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170727.020 SS Final stage: Stage 2 (textFile at <console>:12)
0714-170727.020 SS Parents of final stage: List()
0714-170727.023 SS Missing parents: List()
0714-170727.023 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170727.024 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-170727.024 SS Running ResultTask(2, 0)
0714-170727.026 SS Size of task 0 is 1442 bytes
0714-170727.062 SS Got brand-new decompressor
0714-170727.084 SS Finished ResultTask(2, 0)
0714-170727.084 SS Completed ResultTask(2, 0)
0714-170727.085 SS Stage 2 (textFile at <console>:12) finished in 0.057 s
0714-170727.085 SS Job finished: count at <console>:15, took 0.064638258 s
res2: Long = 1000

scala> s.count()
0714-170727.588 SS Starting job: count at <console>:15
0714-170727.589 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170727.589 SS Final stage: Stage 3 (textFile at <console>:12)
0714-170727.589 SS Parents of final stage: List()
0714-170727.591 SS Missing parents: List()
0714-170727.591 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170727.592 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-170727.592 SS Running ResultTask(3, 0)
0714-170727.594 SS Size of task 0 is 1442 bytes
0714-170727.625 SS Got brand-new decompressor
0714-170727.676 SS Finished ResultTask(3, 0)
0714-170727.677 SS Completed ResultTask(3, 0)
0714-170727.677 SS Stage 3 (textFile at <console>:12) finished in 0.082 s
0714-170727.677 SS Job finished: count at <console>:15, took 0.089038112 s
res3: Long = 1000

scala> s.count()
0714-170728.033 SS Starting job: count at <console>:15
0714-170728.034 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170728.034 SS Final stage: Stage 4 (textFile at <console>:12)
0714-170728.034 SS Parents of final stage: List()
0714-170728.040 SS Missing parents: List()
0714-170728.041 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170728.041 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-170728.042 SS Running ResultTask(4, 0)
0714-170728.044 SS Size of task 0 is 1442 bytes
0714-170728.087 SS Got brand-new decompressor
0714-170728.107 SS Finished ResultTask(4, 0)
0714-170728.108 SS Completed ResultTask(4, 0)
0714-170728.108 SS Stage 4 (textFile at <console>:12) finished in 0.057 s
0714-170728.108 SS Job finished: count at <console>:15, took 0.074391331 s
res4: Long = 1000

scala> Killed 1 processes
Killed 1 processes
localhost: Killed 0 processes
Formatting Tachyon @ localhost
0714-170729.631 TU Deleting /mnt/tachyon/tachyon/tachyon_checkpoint.data
0714-170729.637 TU Deleting /mnt/tachyon/tachyon/tachyon_log.data
0714-170730.665 TU Formatting s3n://2012-05-19-sample/tachyon/data
0714-170731.966 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-170732.121 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-170732.138 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-170732.173 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-170732.203 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-170732.220 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-170732.276 TU Formatting s3n://2012-05-19-sample/tachyon/workers
0714-170732.292 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-170732.413 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-170732.427 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200
0714-170732.471 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-170732.515 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-170732.532 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200

spark-shell count

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-170749.991 SS Slf4jEventHandler started
0714-170750.656 SS Registered BlockManagerMaster Actor
0714-170750.749 SS MemoryStore started with capacity 326.7 MB.
0714-170750.757 SS Created local directory at /tmp/spark-local-20130714170750-3edc
0714-170750.812 SS Bound socket to port 45237 with id = ConnectionManagerId(tachyon-ec2-0,45237)
0714-170750.832 SS Trying to register BlockManager
0714-170750.838 SS Registering block manager tachyon-ec2-0:45237 with 326.7 MB RAM
0714-170750.839 SS Registered BlockManager
0714-170750.888 SS Broadcast server started at http://10.190.33.193:35830
0714-170750.898 SS Registered MapOutputTrackerActor actor
0714-170750.906 SS HTTP File server directory is /tmp/spark-61419349-5b90-4bbc-9586-7e133e17d786
0714-170751.360 SS IoWorker thread 'spray-io-worker-0' started
0714-170752.554 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:59292
0714-170752.556 SS Started BlockManager web UI at http://tachyon-ec2-0:59292
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/data/hit_data.tsv.10000.gz")
0714-170755.107 SS ensureFreeSpace(58415) called with curMem=0, maxMem=342526525
0714-170755.110 SS Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-170755.734 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-170755.734 SS Snappy native library not loaded
0714-170755.760 SS Total input paths to process : 1
0714-170755.782 SS Starting job: count at <console>:15
0714-170755.792 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170755.793 SS Final stage: Stage 0 (textFile at <console>:12)
0714-170755.796 SS Parents of final stage: List()
0714-170755.803 SS Missing parents: List()
0714-170755.806 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170755.821 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-170755.835 SS Running ResultTask(0, 0)
0714-170756.022 SS Size of task 0 is 1429 bytes
0714-170756.237 SS Got brand-new decompressor
0714-170756.601 SS Finished ResultTask(0, 0)
0714-170756.612 SS Completed ResultTask(0, 0)
0714-170756.614 SS Stage 0 (textFile at <console>:12) finished in 0.779 s
0714-170756.616 SS Job finished: count at <console>:15, took 0.833837387 s
res0: Long = 10000

scala> s.count()
0714-170757.060 SS Starting job: count at <console>:15
0714-170757.063 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170757.063 SS Final stage: Stage 1 (textFile at <console>:12)
0714-170757.063 SS Parents of final stage: List()
0714-170757.068 SS Missing parents: List()
0714-170757.069 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170757.069 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-170757.070 SS Running ResultTask(1, 0)
0714-170757.072 SS Size of task 0 is 1432 bytes
0714-170757.150 SS Got brand-new decompressor
0714-170757.323 SS Finished ResultTask(1, 0)
0714-170757.324 SS Completed ResultTask(1, 0)
0714-170757.324 SS Stage 1 (textFile at <console>:12) finished in 0.252 s
0714-170757.324 SS Job finished: count at <console>:15, took 0.261005817 s
res1: Long = 10000

scala> s.count()
0714-170757.655 SS Starting job: count at <console>:15
0714-170757.656 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170757.656 SS Final stage: Stage 2 (textFile at <console>:12)
0714-170757.656 SS Parents of final stage: List()
0714-170757.658 SS Missing parents: List()
0714-170757.658 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170757.659 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-170757.659 SS Running ResultTask(2, 0)
0714-170757.661 SS Size of task 0 is 1432 bytes
0714-170757.740 SS Got brand-new decompressor
0714-170757.988 SS Finished ResultTask(2, 0)
0714-170757.989 SS Completed ResultTask(2, 0)
0714-170757.989 SS Stage 2 (textFile at <console>:12) finished in 0.326 s
0714-170757.989 SS Job finished: count at <console>:15, took 0.333941843 s
res2: Long = 10000

scala> s.count()
0714-170758.542 SS Starting job: count at <console>:15
0714-170758.542 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170758.543 SS Final stage: Stage 3 (textFile at <console>:12)
0714-170758.543 SS Parents of final stage: List()
0714-170758.545 SS Missing parents: List()
0714-170758.545 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170758.546 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-170758.546 SS Running ResultTask(3, 0)
0714-170758.548 SS Size of task 0 is 1432 bytes
0714-170758.581 SS Got brand-new decompressor
0714-170758.692 SS Finished ResultTask(3, 0)
0714-170758.692 SS Completed ResultTask(3, 0)
0714-170758.693 SS Stage 3 (textFile at <console>:12) finished in 0.141 s
0714-170758.693 SS Job finished: count at <console>:15, took 0.150676407 s
res3: Long = 10000

scala> s.count()
0714-170758.990 SS Starting job: count at <console>:15
0714-170758.991 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170758.991 SS Final stage: Stage 4 (textFile at <console>:12)
0714-170758.991 SS Parents of final stage: List()
0714-170758.993 SS Missing parents: List()
0714-170758.993 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170758.994 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-170758.994 SS Running ResultTask(4, 0)
0714-170758.996 SS Size of task 0 is 1432 bytes
0714-170759.042 SS Got brand-new decompressor
0714-170759.171 SS Finished ResultTask(4, 0)
0714-170759.172 SS Completed ResultTask(4, 0)
0714-170759.172 SS Stage 4 (textFile at <console>:12) finished in 0.175 s
0714-170759.172 SS Job finished: count at <console>:15, took 0.181967289 s
res4: Long = 10000

scala> restaring tachyon
Killed 0 processes
Killed 0 processes
localhost: Killed 0 processes
Mounting ramfs on Linux...
TACHYON_RAM_FOLDER was not set. Using the default one: /mnt/ramdisk
Formatting RamFS: /mnt/ramdisk
Starting master @ localhost
Starting worker @ tachyon-ec2-0

spark-shell count
23258 tachyon.Master
23271 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-170820.731 SS Slf4jEventHandler started
0714-170821.436 SS Registered BlockManagerMaster Actor
0714-170821.483 SS MemoryStore started with capacity 326.7 MB.
0714-170821.491 SS Created local directory at /tmp/spark-local-20130714170821-5a9e
0714-170821.551 SS Bound socket to port 43666 with id = ConnectionManagerId(tachyon-ec2-0,43666)
0714-170821.578 SS Trying to register BlockManager
0714-170821.582 SS Registering block manager tachyon-ec2-0:43666 with 326.7 MB RAM
0714-170821.583 SS Registered BlockManager
0714-170821.632 SS Broadcast server started at http://10.190.33.193:36862
0714-170821.646 SS Registered MapOutputTrackerActor actor
0714-170821.651 SS HTTP File server directory is /tmp/spark-61ea32b8-ec52-4002-89ef-4d9c4132109b
0714-170822.113 SS IoWorker thread 'spray-io-worker-0' started
0714-170823.301 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:33604
0714-170823.304 SS Started BlockManager web UI at http://tachyon-ec2-0:33604
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("tachyon://localhost:19998/hit_data.tsv.10000.gz")
0714-170825.873 SS ensureFreeSpace(58439) called with curMem=0, maxMem=342526525
0714-170825.876 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-170826.539 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-170826.539 SS Snappy native library not loaded
0714-170826.579 SS 23319 61 Thread-37 |        Trying to connect master @ localhost/127.0.0.1:19998
0714-170826.644 SS 23319 61 Thread-37 |          User registered at the master localhost/127.0.0.1:19998 got UserId 1
0714-170826.644 SS 23319 61 Thread-37 |        Trying to get local worker host : tachyon-ec2-0
0714-170826.661 SS 23319 61 Thread-37 |        Connecting local worker @ tachyon-ec2-0/10.190.33.193:29998
0714-170828.341 SS Total input paths to process : 1
0714-170830.670 SS Starting job: count at <console>:15
0714-170830.682 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170830.688 SS Final stage: Stage 0 (textFile at <console>:12)
0714-170830.688 SS Parents of final stage: List()
0714-170830.699 SS Missing parents: List()
0714-170830.702 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170830.717 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-170830.726 SS Running ResultTask(0, 0)
0714-170830.787 SS Size of task 0 is 1440 bytes
0714-170830.888 SS 23319 64 pool-1-thread-1 |          /mnt/ramdisk/tachyonworker/2 is not on local disk.
0714-170830.898 SS 23319 64 pool-1-thread-1 |          Try to find and read from remote workers.
0714-170831.022 SS 23319 64 pool-1-thread-1 |          fileLocations: [NetAddress(mHost:localhost, mPort:-1)]
0714-170831.221 SS Opening 's3n://2012-05-19-sample/hit_data.tsv.10000.gz' for reading
0714-170831.453 SS 23319 64 pool-1-thread-1 |          Folder /mnt/ramdisk/tachyonworker/users/1 was created!
0714-170831.454 SS 23319 64 pool-1-thread-1 |        File /mnt/ramdisk/tachyonworker/users/1/2 was created!
0714-170831.785 SS Got brand-new decompressor
0714-170832.123 SS Finished ResultTask(0, 0)
0714-170832.128 SS Completed ResultTask(0, 0)
0714-170832.130 SS Stage 0 (textFile at <console>:12) finished in 1.405 s
0714-170832.136 SS Job finished: count at <console>:15, took 1.460710074 s
res0: Long = 10000

scala> s.count()
0714-170832.597 SS Starting job: count at <console>:15
0714-170832.599 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170832.599 SS Final stage: Stage 1 (textFile at <console>:12)
0714-170832.599 SS Parents of final stage: List()
0714-170832.601 SS Missing parents: List()
0714-170832.601 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170832.602 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-170832.602 SS Running ResultTask(1, 0)
0714-170832.604 SS Size of task 0 is 1443 bytes
0714-170832.675 SS Got brand-new decompressor
0714-170832.907 SS Finished ResultTask(1, 0)
0714-170832.908 SS Completed ResultTask(1, 0)
0714-170832.908 SS Stage 1 (textFile at <console>:12) finished in 0.303 s
0714-170832.909 SS Job finished: count at <console>:15, took 0.310142787 s
res1: Long = 10000

scala> s.count()
0714-170833.202 SS Starting job: count at <console>:15
0714-170833.203 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170833.203 SS Final stage: Stage 2 (textFile at <console>:12)
0714-170833.203 SS Parents of final stage: List()
0714-170833.205 SS Missing parents: List()
0714-170833.206 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170833.207 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-170833.207 SS Running ResultTask(2, 0)
0714-170833.209 SS Size of task 0 is 1443 bytes
0714-170833.246 SS Got brand-new decompressor
0714-170833.412 SS Finished ResultTask(2, 0)
0714-170833.412 SS Completed ResultTask(2, 0)
0714-170833.413 SS Stage 2 (textFile at <console>:12) finished in 0.201 s
0714-170833.413 SS Job finished: count at <console>:15, took 0.210130745 s
res2: Long = 10000

scala> s.count()
0714-170833.880 SS Starting job: count at <console>:15
0714-170833.880 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170833.880 SS Final stage: Stage 3 (textFile at <console>:12)
0714-170833.880 SS Parents of final stage: List()
0714-170833.882 SS Missing parents: List()
0714-170833.883 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170833.883 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-170833.884 SS Running ResultTask(3, 0)
0714-170833.886 SS Size of task 0 is 1443 bytes
0714-170833.933 SS Got brand-new decompressor
0714-170834.085 SS Finished ResultTask(3, 0)
0714-170834.087 SS Completed ResultTask(3, 0)
0714-170834.088 SS Stage 3 (textFile at <console>:12) finished in 0.201 s
0714-170834.088 SS Job finished: count at <console>:15, took 0.207827839 s
res3: Long = 10000

scala> s.count()
0714-170834.395 SS Starting job: count at <console>:15
0714-170834.395 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170834.395 SS Final stage: Stage 4 (textFile at <console>:12)
0714-170834.396 SS Parents of final stage: List()
0714-170834.397 SS Missing parents: List()
0714-170834.398 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170834.398 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-170834.399 SS Running ResultTask(4, 0)
0714-170834.401 SS Size of task 0 is 1443 bytes
0714-170834.448 SS Got brand-new decompressor
0714-170834.622 SS Finished ResultTask(4, 0)
0714-170834.623 SS Completed ResultTask(4, 0)
0714-170834.623 SS Stage 4 (textFile at <console>:12) finished in 0.222 s
0714-170834.624 SS Job finished: count at <console>:15, took 0.228483949 s
res4: Long = 10000

scala> Killed 1 processes
Killed 1 processes
localhost: Killed 0 processes
Formatting Tachyon @ localhost
0714-170836.163 TU Deleting /mnt/tachyon/tachyon/tachyon_checkpoint.data
0714-170836.165 TU Deleting /mnt/tachyon/tachyon/tachyon_log.data
0714-170837.174 TU Formatting s3n://2012-05-19-sample/tachyon/data
0714-170838.465 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-170838.604 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-170838.618 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-170838.650 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-170838.679 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-170838.692 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-170838.753 TU Formatting s3n://2012-05-19-sample/tachyon/workers
0714-170838.766 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-170838.872 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-170838.886 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200
0714-170838.925 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-170838.963 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-170838.979 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200

spark-shell count

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-170857.068 SS Slf4jEventHandler started
0714-170857.760 SS Registered BlockManagerMaster Actor
0714-170857.808 SS MemoryStore started with capacity 326.7 MB.
0714-170857.818 SS Created local directory at /tmp/spark-local-20130714170857-5856
0714-170857.881 SS Bound socket to port 34012 with id = ConnectionManagerId(tachyon-ec2-0,34012)
0714-170857.902 SS Trying to register BlockManager
0714-170857.910 SS Registering block manager tachyon-ec2-0:34012 with 326.7 MB RAM
0714-170857.911 SS Registered BlockManager
0714-170857.956 SS Broadcast server started at http://10.190.33.193:33451
0714-170857.970 SS Registered MapOutputTrackerActor actor
0714-170857.979 SS HTTP File server directory is /tmp/spark-616bd9b9-d399-4563-9e67-a2bbb2a86dec
0714-170858.418 SS IoWorker thread 'spray-io-worker-0' started
0714-170859.589 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:47359
0714-170859.592 SS Started BlockManager web UI at http://tachyon-ec2-0:47359
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/data/hit_data.tsv.100000.gz")
0714-170902.033 SS ensureFreeSpace(58423) called with curMem=0, maxMem=342526525
0714-170902.036 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-170902.656 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-170902.657 SS Snappy native library not loaded
0714-170902.707 SS Total input paths to process : 1
0714-170902.730 SS Starting job: count at <console>:15
0714-170902.741 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170902.744 SS Final stage: Stage 0 (textFile at <console>:12)
0714-170902.744 SS Parents of final stage: List()
0714-170902.754 SS Missing parents: List()
0714-170902.757 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170902.770 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-170902.787 SS Running ResultTask(0, 0)
0714-170902.983 SS Size of task 0 is 1430 bytes
0714-170903.153 SS Got brand-new decompressor
0714-170904.668 SS Finished ResultTask(0, 0)
0714-170904.671 SS Completed ResultTask(0, 0)
0714-170904.673 SS Stage 0 (textFile at <console>:12) finished in 1.886 s
0714-170904.674 SS Job finished: count at <console>:15, took 1.942998858 s
res0: Long = 100002

scala> s.count()
0714-170905.090 SS Starting job: count at <console>:15
0714-170905.091 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170905.091 SS Final stage: Stage 1 (textFile at <console>:12)
0714-170905.091 SS Parents of final stage: List()
0714-170905.096 SS Missing parents: List()
0714-170905.097 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170905.097 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-170905.098 SS Running ResultTask(1, 0)
0714-170905.100 SS Size of task 0 is 1433 bytes
0714-170905.189 SS Got brand-new decompressor
0714-170906.397 SS Finished ResultTask(1, 0)
0714-170906.398 SS Completed ResultTask(1, 0)
0714-170906.398 SS Stage 1 (textFile at <console>:12) finished in 1.298 s
0714-170906.398 SS Job finished: count at <console>:15, took 1.307529748 s
res1: Long = 100002

scala> s.count()
0714-170906.785 SS Starting job: count at <console>:15
0714-170906.786 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170906.786 SS Final stage: Stage 2 (textFile at <console>:12)
0714-170906.786 SS Parents of final stage: List()
0714-170906.788 SS Missing parents: List()
0714-170906.789 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170906.789 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-170906.790 SS Running ResultTask(2, 0)
0714-170906.792 SS Size of task 0 is 1433 bytes
0714-170906.868 SS Got brand-new decompressor
0714-170908.351 SS Finished ResultTask(2, 0)
0714-170908.352 SS Completed ResultTask(2, 0)
0714-170908.352 SS Stage 2 (textFile at <console>:12) finished in 1.560 s
0714-170908.353 SS Job finished: count at <console>:15, took 1.566789864 s
res2: Long = 100002

scala> s.count()
0714-170908.819 SS Starting job: count at <console>:15
0714-170908.819 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170908.819 SS Final stage: Stage 3 (textFile at <console>:12)
0714-170908.820 SS Parents of final stage: List()
0714-170908.821 SS Missing parents: List()
0714-170908.822 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170908.822 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-170908.823 SS Running ResultTask(3, 0)
0714-170908.825 SS Size of task 0 is 1433 bytes
0714-170908.856 SS Got brand-new decompressor
0714-170910.017 SS Finished ResultTask(3, 0)
0714-170910.018 SS Completed ResultTask(3, 0)
0714-170910.018 SS Stage 3 (textFile at <console>:12) finished in 1.191 s
0714-170910.019 SS Job finished: count at <console>:15, took 1.199395361 s
res3: Long = 100002

scala> s.count()
0714-170910.289 SS Starting job: count at <console>:15
0714-170910.289 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170910.290 SS Final stage: Stage 4 (textFile at <console>:12)
0714-170910.290 SS Parents of final stage: List()
0714-170910.302 SS Missing parents: List()
0714-170910.302 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170910.303 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-170910.304 SS Running ResultTask(4, 0)
0714-170910.306 SS Size of task 0 is 1433 bytes
0714-170910.364 SS Got brand-new decompressor
0714-170911.612 SS Finished ResultTask(4, 0)
0714-170911.613 SS Completed ResultTask(4, 0)
0714-170911.613 SS Stage 4 (textFile at <console>:12) finished in 1.306 s
0714-170911.614 SS Job finished: count at <console>:15, took 1.324449242 s
res4: Long = 100002

scala> restaring tachyon
Killed 0 processes
Killed 0 processes
localhost: Killed 0 processes
Mounting ramfs on Linux...
TACHYON_RAM_FOLDER was not set. Using the default one: /mnt/ramdisk
Formatting RamFS: /mnt/ramdisk
Starting master @ localhost
Starting worker @ tachyon-ec2-0

spark-shell count
23911 tachyon.Master
23924 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-170932.949 SS Slf4jEventHandler started
0714-170933.620 SS Registered BlockManagerMaster Actor
0714-170933.692 SS MemoryStore started with capacity 326.7 MB.
0714-170933.697 SS Created local directory at /tmp/spark-local-20130714170933-cee0
0714-170933.750 SS Bound socket to port 56733 with id = ConnectionManagerId(tachyon-ec2-0,56733)
0714-170933.776 SS Trying to register BlockManager
0714-170933.779 SS Registering block manager tachyon-ec2-0:56733 with 326.7 MB RAM
0714-170933.780 SS Registered BlockManager
0714-170933.828 SS Broadcast server started at http://10.190.33.193:50441
0714-170933.838 SS Registered MapOutputTrackerActor actor
0714-170933.846 SS HTTP File server directory is /tmp/spark-309f3889-fe42-42ac-89d1-e47eb95a5ef6
0714-170934.323 SS IoWorker thread 'spray-io-worker-0' started
0714-170935.498 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:46351
0714-170935.500 SS Started BlockManager web UI at http://tachyon-ec2-0:46351
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("tachyon://localhost:19998/hit_data.tsv.100000.gz")
0714-170938.122 SS ensureFreeSpace(58439) called with curMem=0, maxMem=342526525
0714-170938.125 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-170938.802 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-170938.802 SS Snappy native library not loaded
0714-170938.843 SS 23972 61 Thread-37 |        Trying to connect master @ localhost/127.0.0.1:19998
0714-170938.904 SS 23972 61 Thread-37 |          User registered at the master localhost/127.0.0.1:19998 got UserId 1
0714-170938.905 SS 23972 61 Thread-37 |        Trying to get local worker host : tachyon-ec2-0
0714-170938.922 SS 23972 61 Thread-37 |        Connecting local worker @ tachyon-ec2-0/10.190.33.193:29998
0714-170940.609 SS Total input paths to process : 1
0714-170942.913 SS Starting job: count at <console>:15
0714-170942.926 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170942.936 SS Final stage: Stage 0 (textFile at <console>:12)
0714-170942.937 SS Parents of final stage: List()
0714-170942.955 SS Missing parents: List()
0714-170942.958 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170942.971 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-170942.984 SS Running ResultTask(0, 0)
0714-170943.043 SS Size of task 0 is 1441 bytes
0714-170943.179 SS 23972 64 pool-1-thread-1 |          /mnt/ramdisk/tachyonworker/2 is not on local disk.
0714-170943.188 SS 23972 64 pool-1-thread-1 |          Try to find and read from remote workers.
0714-170943.309 SS 23972 64 pool-1-thread-1 |          fileLocations: [NetAddress(mHost:localhost, mPort:-1)]
0714-170943.485 SS Opening 's3n://2012-05-19-sample/hit_data.tsv.100000.gz' for reading
0714-170943.566 SS 23972 64 pool-1-thread-1 |          Folder /mnt/ramdisk/tachyonworker/users/1 was created!
0714-170943.569 SS 23972 64 pool-1-thread-1 |        File /mnt/ramdisk/tachyonworker/users/1/2 was created!
0714-170944.804 SS Got brand-new decompressor
0714-170946.493 SS Finished ResultTask(0, 0)
0714-170946.498 SS Completed ResultTask(0, 0)
0714-170946.500 SS Stage 0 (textFile at <console>:12) finished in 3.517 s
0714-170946.502 SS Job finished: count at <console>:15, took 3.582836348 s
res0: Long = 100002

scala> s.count()
0714-170946.892 SS Starting job: count at <console>:15
0714-170946.893 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170946.893 SS Final stage: Stage 1 (textFile at <console>:12)
0714-170946.893 SS Parents of final stage: List()
0714-170946.895 SS Missing parents: List()
0714-170946.895 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170946.896 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-170946.896 SS Running ResultTask(1, 0)
0714-170946.898 SS Size of task 0 is 1444 bytes
0714-170946.971 SS Got brand-new decompressor
0714-170948.363 SS Finished ResultTask(1, 0)
0714-170948.364 SS Completed ResultTask(1, 0)
0714-170948.364 SS Stage 1 (textFile at <console>:12) finished in 1.465 s
0714-170948.364 SS Job finished: count at <console>:15, took 1.471594803 s
res1: Long = 100002

scala> s.count()
0714-170948.657 SS Starting job: count at <console>:15
0714-170948.658 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170948.658 SS Final stage: Stage 2 (textFile at <console>:12)
0714-170948.658 SS Parents of final stage: List()
0714-170948.661 SS Missing parents: List()
0714-170948.661 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170948.662 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-170948.662 SS Running ResultTask(2, 0)
0714-170948.664 SS Size of task 0 is 1444 bytes
0714-170948.700 SS Got brand-new decompressor
0714-170950.234 SS Finished ResultTask(2, 0)
0714-170950.235 SS Completed ResultTask(2, 0)
0714-170950.235 SS Stage 2 (textFile at <console>:12) finished in 1.570 s
0714-170950.236 SS Job finished: count at <console>:15, took 1.577712453 s
res2: Long = 100002

scala> s.count()
0714-170950.704 SS Starting job: count at <console>:15
0714-170950.704 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170950.704 SS Final stage: Stage 3 (textFile at <console>:12)
0714-170950.705 SS Parents of final stage: List()
0714-170950.706 SS Missing parents: List()
0714-170950.707 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170950.707 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-170950.708 SS Running ResultTask(3, 0)
0714-170950.710 SS Size of task 0 is 1444 bytes
0714-170950.740 SS Got brand-new decompressor
0714-170952.084 SS Finished ResultTask(3, 0)
0714-170952.085 SS Completed ResultTask(3, 0)
0714-170952.085 SS Stage 3 (textFile at <console>:12) finished in 1.374 s
0714-170952.085 SS Job finished: count at <console>:15, took 1.381143356 s
res3: Long = 100002

scala> s.count()
0714-170952.411 SS Starting job: count at <console>:15
0714-170952.416 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-170952.416 SS Final stage: Stage 4 (textFile at <console>:12)
0714-170952.416 SS Parents of final stage: List()
0714-170952.418 SS Missing parents: List()
0714-170952.418 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-170952.419 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-170952.419 SS Running ResultTask(4, 0)
0714-170952.421 SS Size of task 0 is 1444 bytes
0714-170952.476 SS Got brand-new decompressor
0714-170953.930 SS Finished ResultTask(4, 0)
0714-170953.931 SS Completed ResultTask(4, 0)
0714-170953.931 SS Stage 4 (textFile at <console>:12) finished in 1.504 s
0714-170953.931 SS Job finished: count at <console>:15, took 1.515801576 s
res4: Long = 100002

scala> Killed 1 processes
Killed 1 processes
localhost: Killed 0 processes
Formatting Tachyon @ localhost
0714-170955.451 TU Deleting /mnt/tachyon/tachyon/tachyon_checkpoint.data
0714-170955.454 TU Deleting /mnt/tachyon/tachyon/tachyon_log.data
0714-170956.475 TU Formatting s3n://2012-05-19-sample/tachyon/data
0714-170957.771 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-170957.914 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-170957.926 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-170957.959 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-170957.986 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-170957.997 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-170958.043 TU Formatting s3n://2012-05-19-sample/tachyon/workers
0714-170958.057 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-170958.155 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-170958.169 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200
0714-170958.205 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-170958.240 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-170958.258 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200

spark-shell count

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-171014.228 SS Slf4jEventHandler started
0714-171014.892 SS Registered BlockManagerMaster Actor
0714-171014.963 SS MemoryStore started with capacity 326.7 MB.
0714-171014.971 SS Created local directory at /tmp/spark-local-20130714171014-9ea6
0714-171015.028 SS Bound socket to port 43876 with id = ConnectionManagerId(tachyon-ec2-0,43876)
0714-171015.048 SS Trying to register BlockManager
0714-171015.053 SS Registering block manager tachyon-ec2-0:43876 with 326.7 MB RAM
0714-171015.054 SS Registered BlockManager
0714-171015.104 SS Broadcast server started at http://10.190.33.193:52079
0714-171015.127 SS Registered MapOutputTrackerActor actor
0714-171015.141 SS HTTP File server directory is /tmp/spark-d8ef3abe-419e-4b00-ac5c-d7475c22f201
0714-171015.546 SS IoWorker thread 'spray-io-worker-0' started
0714-171016.750 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:41668
0714-171016.752 SS Started BlockManager web UI at http://tachyon-ec2-0:41668
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/data/hit_data.tsv.1000000.gz")
0714-171019.345 SS ensureFreeSpace(58423) called with curMem=0, maxMem=342526525
0714-171019.347 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-171019.960 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-171019.961 SS Snappy native library not loaded
0714-171019.989 SS Total input paths to process : 1
0714-171020.007 SS Starting job: count at <console>:15
0714-171020.018 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171020.024 SS Final stage: Stage 0 (textFile at <console>:12)
0714-171020.024 SS Parents of final stage: List()
0714-171020.031 SS Missing parents: List()
0714-171020.034 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171020.049 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-171020.078 SS Running ResultTask(0, 0)
0714-171020.293 SS Size of task 0 is 1431 bytes
0714-171020.452 SS Got brand-new decompressor
0714-171032.306 SS Finished ResultTask(0, 0)
0714-171032.308 SS Completed ResultTask(0, 0)
0714-171032.311 SS Stage 0 (textFile at <console>:12) finished in 12.233 s
0714-171032.312 SS Job finished: count at <console>:15, took 12.301496949 s
res0: Long = 1000135

scala> s.count()
0714-171032.704 SS Starting job: count at <console>:15
0714-171032.707 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171032.708 SS Final stage: Stage 1 (textFile at <console>:12)
0714-171032.708 SS Parents of final stage: List()
0714-171032.712 SS Missing parents: List()
0714-171032.713 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171032.713 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-171032.714 SS Running ResultTask(1, 0)
0714-171032.716 SS Size of task 0 is 1434 bytes
0714-171032.808 SS Got brand-new decompressor
0714-171044.084 SS Finished ResultTask(1, 0)
0714-171044.088 SS Completed ResultTask(1, 0)
0714-171044.088 SS Stage 1 (textFile at <console>:12) finished in 11.369 s
0714-171044.088 SS Job finished: count at <console>:15, took 11.380978717 s
res1: Long = 1000135

scala> s.count()
0714-171044.376 SS Starting job: count at <console>:15
0714-171044.377 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171044.377 SS Final stage: Stage 2 (textFile at <console>:12)
0714-171044.377 SS Parents of final stage: List()
0714-171044.379 SS Missing parents: List()
0714-171044.379 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171044.380 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-171044.380 SS Running ResultTask(2, 0)
0714-171044.382 SS Size of task 0 is 1434 bytes
0714-171044.443 SS Got brand-new decompressor
0714-171055.901 SS Finished ResultTask(2, 0)
0714-171055.902 SS Completed ResultTask(2, 0)
0714-171055.902 SS Stage 2 (textFile at <console>:12) finished in 11.519 s
0714-171055.902 SS Job finished: count at <console>:15, took 11.525426093 s
res2: Long = 1000135

scala> s.count()
0714-171056.163 SS Starting job: count at <console>:15
0714-171056.164 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171056.164 SS Final stage: Stage 3 (textFile at <console>:12)
0714-171056.164 SS Parents of final stage: List()
0714-171056.166 SS Missing parents: List()
0714-171056.166 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171056.167 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-171056.167 SS Running ResultTask(3, 0)
0714-171056.169 SS Size of task 0 is 1434 bytes
0714-171056.196 SS Got brand-new decompressor
0714-171107.546 SS Finished ResultTask(3, 0)
0714-171107.546 SS Completed ResultTask(3, 0)
0714-171107.547 SS Stage 3 (textFile at <console>:12) finished in 11.376 s
0714-171107.547 SS Job finished: count at <console>:15, took 11.383341463 s
res3: Long = 1000135

scala> s.count()
0714-171107.784 SS Starting job: count at <console>:15
0714-171107.785 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171107.785 SS Final stage: Stage 4 (textFile at <console>:12)
0714-171107.785 SS Parents of final stage: List()
0714-171107.787 SS Missing parents: List()
0714-171107.787 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171107.788 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-171107.788 SS Running ResultTask(4, 0)
0714-171107.791 SS Size of task 0 is 1434 bytes
0714-171107.829 SS Got brand-new decompressor
0714-171119.054 SS Finished ResultTask(4, 0)
0714-171119.054 SS Completed ResultTask(4, 0)
0714-171119.055 SS Stage 4 (textFile at <console>:12) finished in 11.263 s
0714-171119.055 SS Job finished: count at <console>:15, took 11.270119906 s
res4: Long = 1000135

scala> restaring tachyon
Killed 0 processes
Killed 0 processes
localhost: Killed 0 processes
Mounting ramfs on Linux...
TACHYON_RAM_FOLDER was not set. Using the default one: /mnt/ramdisk
Formatting RamFS: /mnt/ramdisk
Starting master @ localhost
Starting worker @ tachyon-ec2-0

spark-shell count
24588 tachyon.Master
24601 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-171140.070 SS Slf4jEventHandler started
0714-171140.778 SS Registered BlockManagerMaster Actor
0714-171140.822 SS MemoryStore started with capacity 326.7 MB.
0714-171140.835 SS Created local directory at /tmp/spark-local-20130714171140-a91b
0714-171140.895 SS Bound socket to port 34220 with id = ConnectionManagerId(tachyon-ec2-0,34220)
0714-171140.921 SS Trying to register BlockManager
0714-171140.932 SS Registering block manager tachyon-ec2-0:34220 with 326.7 MB RAM
0714-171140.936 SS Registered BlockManager
0714-171140.989 SS Broadcast server started at http://10.190.33.193:42931
0714-171141.002 SS Registered MapOutputTrackerActor actor
0714-171141.011 SS HTTP File server directory is /tmp/spark-eb2399fe-b957-4854-8ff2-00b60e1999d5
0714-171141.471 SS IoWorker thread 'spray-io-worker-0' started
0714-171142.654 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:46459
0714-171142.656 SS Started BlockManager web UI at http://tachyon-ec2-0:46459
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("tachyon://localhost:19998/hit_data.tsv.1000000.gz")
0714-171145.100 SS ensureFreeSpace(58447) called with curMem=0, maxMem=342526525
0714-171145.103 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-171145.687 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-171145.688 SS Snappy native library not loaded
0714-171145.728 SS 24649 62 Thread-37 |        Trying to connect master @ localhost/127.0.0.1:19998
0714-171145.792 SS 24649 62 Thread-37 |          User registered at the master localhost/127.0.0.1:19998 got UserId 1
0714-171145.792 SS 24649 62 Thread-37 |        Trying to get local worker host : tachyon-ec2-0
0714-171145.821 SS 24649 62 Thread-37 |        Connecting local worker @ tachyon-ec2-0/10.190.33.193:29998
0714-171147.474 SS Total input paths to process : 1
0714-171149.760 SS Starting job: count at <console>:15
0714-171149.772 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171149.773 SS Final stage: Stage 0 (textFile at <console>:12)
0714-171149.773 SS Parents of final stage: List()
0714-171149.787 SS Missing parents: List()
0714-171149.793 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171149.829 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-171149.841 SS Running ResultTask(0, 0)
0714-171149.913 SS Size of task 0 is 1442 bytes
0714-171150.014 SS 24649 65 pool-1-thread-1 |          /mnt/ramdisk/tachyonworker/2 is not on local disk.
0714-171150.024 SS 24649 65 pool-1-thread-1 |          Try to find and read from remote workers.
0714-171150.144 SS 24649 65 pool-1-thread-1 |          fileLocations: [NetAddress(mHost:localhost, mPort:-1)]
0714-171150.302 SS Opening 's3n://2012-05-19-sample/hit_data.tsv.1000000.gz' for reading
0714-171150.450 SS 24649 65 pool-1-thread-1 |          Folder /mnt/ramdisk/tachyonworker/users/1 was created!
0714-171150.451 SS 24649 65 pool-1-thread-1 |        File /mnt/ramdisk/tachyonworker/users/1/2 was created!
0714-171157.183 SS Got brand-new decompressor
0714-171211.305 SS Finished ResultTask(0, 0)
0714-171211.308 SS Completed ResultTask(0, 0)
0714-171211.310 SS Stage 0 (textFile at <console>:12) finished in 21.470 s
0714-171211.312 SS Job finished: count at <console>:15, took 21.551988952 s
res0: Long = 1000135

scala> s.count()
0714-171211.712 SS Starting job: count at <console>:15
0714-171211.713 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171211.713 SS Final stage: Stage 1 (textFile at <console>:12)
0714-171211.713 SS Parents of final stage: List()
0714-171211.715 SS Missing parents: List()
0714-171211.716 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171211.716 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-171211.717 SS Running ResultTask(1, 0)
0714-171211.718 SS Size of task 0 is 1445 bytes
0714-171211.765 SS Got brand-new decompressor
0714-171224.967 SS Finished ResultTask(1, 0)
0714-171224.968 SS Completed ResultTask(1, 0)
0714-171224.968 SS Stage 1 (textFile at <console>:12) finished in 13.248 s
0714-171224.968 SS Job finished: count at <console>:15, took 13.255422861 s
res1: Long = 1000135

scala> s.count()
0714-171225.226 SS Starting job: count at <console>:15
0714-171225.227 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171225.228 SS Final stage: Stage 2 (textFile at <console>:12)
0714-171225.228 SS Parents of final stage: List()
0714-171225.229 SS Missing parents: List()
0714-171225.230 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171225.231 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-171225.231 SS Running ResultTask(2, 0)
0714-171225.233 SS Size of task 0 is 1445 bytes
0714-171225.273 SS Got brand-new decompressor
0714-171237.769 SS Finished ResultTask(2, 0)
0714-171237.770 SS Completed ResultTask(2, 0)
0714-171237.770 SS Stage 2 (textFile at <console>:12) finished in 12.535 s
0714-171237.770 SS Job finished: count at <console>:15, took 12.543041673 s
res2: Long = 1000135

scala> s.count()
0714-171238.081 SS Starting job: count at <console>:15
0714-171238.081 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171238.082 SS Final stage: Stage 3 (textFile at <console>:12)
0714-171238.082 SS Parents of final stage: List()
0714-171238.083 SS Missing parents: List()
0714-171238.084 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171238.085 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-171238.085 SS Running ResultTask(3, 0)
0714-171238.087 SS Size of task 0 is 1445 bytes
0714-171238.149 SS Got brand-new decompressor
0714-171250.707 SS Finished ResultTask(3, 0)
0714-171250.708 SS Completed ResultTask(3, 0)
0714-171250.708 SS Stage 3 (textFile at <console>:12) finished in 12.621 s
0714-171250.708 SS Job finished: count at <console>:15, took 12.627049592 s
res3: Long = 1000135

scala> s.count()
0714-171250.954 SS Starting job: count at <console>:15
0714-171250.955 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171250.955 SS Final stage: Stage 4 (textFile at <console>:12)
0714-171250.955 SS Parents of final stage: List()
0714-171250.957 SS Missing parents: List()
0714-171250.957 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171250.958 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-171250.958 SS Running ResultTask(4, 0)
0714-171250.960 SS Size of task 0 is 1445 bytes
0714-171250.996 SS Got brand-new decompressor
0714-171303.667 SS Finished ResultTask(4, 0)
0714-171303.668 SS Completed ResultTask(4, 0)
0714-171303.668 SS Stage 4 (textFile at <console>:12) finished in 12.705 s
0714-171303.668 SS Job finished: count at <console>:15, took 12.713511448 s
res4: Long = 1000135

scala> Killed 1 processes
Killed 1 processes
localhost: Killed 0 processes
Formatting Tachyon @ localhost
0714-171305.587 TU Deleting /mnt/tachyon/tachyon/tachyon_checkpoint.data
0714-171305.590 TU Deleting /mnt/tachyon/tachyon/tachyon_log.data
0714-171306.600 TU Formatting s3n://2012-05-19-sample/tachyon/data
0714-171307.879 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-171308.032 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-171308.047 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-171308.080 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-171308.110 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-171308.122 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-171308.169 TU Formatting s3n://2012-05-19-sample/tachyon/workers
0714-171308.188 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-171308.292 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-171308.306 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200
0714-171308.342 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-171308.382 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-171308.502 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200

spark-shell count

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-171323.938 SS Slf4jEventHandler started
0714-171324.608 SS Registered BlockManagerMaster Actor
0714-171324.697 SS MemoryStore started with capacity 326.7 MB.
0714-171324.707 SS Created local directory at /tmp/spark-local-20130714171324-d089
0714-171324.762 SS Bound socket to port 54982 with id = ConnectionManagerId(tachyon-ec2-0,54982)
0714-171324.786 SS Trying to register BlockManager
0714-171324.790 SS Registering block manager tachyon-ec2-0:54982 with 326.7 MB RAM
0714-171324.791 SS Registered BlockManager
0714-171324.840 SS Broadcast server started at http://10.190.33.193:37511
0714-171324.850 SS Registered MapOutputTrackerActor actor
0714-171324.859 SS HTTP File server directory is /tmp/spark-0daf15d3-d693-44d1-960c-9b1ba79fa527
0714-171325.295 SS IoWorker thread 'spray-io-worker-0' started
0714-171326.482 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:49513
0714-171326.484 SS Started BlockManager web UI at http://tachyon-ec2-0:49513
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/data/hit_data.tsv.2000000.gz")
0714-171328.876 SS ensureFreeSpace(58423) called with curMem=0, maxMem=342526525
0714-171328.879 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-171329.501 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-171329.502 SS Snappy native library not loaded
0714-171329.515 SS Total input paths to process : 1
0714-171329.526 SS Starting job: count at <console>:15
0714-171329.533 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171329.534 SS Final stage: Stage 0 (textFile at <console>:12)
0714-171329.535 SS Parents of final stage: List()
0714-171329.540 SS Missing parents: List()
0714-171329.542 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171329.548 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-171329.559 SS Running ResultTask(0, 0)
0714-171329.707 SS Size of task 0 is 1431 bytes
0714-171329.874 SS Got brand-new decompressor
0714-171352.943 SS Finished ResultTask(0, 0)
0714-171352.946 SS Completed ResultTask(0, 0)
0714-171352.948 SS Stage 0 (textFile at <console>:12) finished in 23.388 s
0714-171352.950 SS Job finished: count at <console>:15, took 23.423265799 s
res0: Long = 2000298

scala> s.count()
0714-171353.505 SS Starting job: count at <console>:15
0714-171353.506 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171353.506 SS Final stage: Stage 1 (textFile at <console>:12)
0714-171353.507 SS Parents of final stage: List()
0714-171353.509 SS Missing parents: List()
0714-171353.509 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171353.510 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-171353.510 SS Running ResultTask(1, 0)
0714-171353.512 SS Size of task 0 is 1434 bytes
0714-171353.580 SS Got brand-new decompressor
0714-171416.294 SS Finished ResultTask(1, 0)
0714-171416.295 SS Completed ResultTask(1, 0)
0714-171416.296 SS Stage 1 (textFile at <console>:12) finished in 22.782 s
0714-171416.296 SS Job finished: count at <console>:15, took 22.789536202 s
res1: Long = 2000298

scala> s.count()
0714-171416.564 SS Starting job: count at <console>:15
0714-171416.564 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171416.564 SS Final stage: Stage 2 (textFile at <console>:12)
0714-171416.564 SS Parents of final stage: List()
0714-171416.566 SS Missing parents: List()
0714-171416.567 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171416.568 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-171416.568 SS Running ResultTask(2, 0)
0714-171416.570 SS Size of task 0 is 1434 bytes
0714-171416.626 SS Got brand-new decompressor
0714-171439.766 SS Finished ResultTask(2, 0)
0714-171439.767 SS Completed ResultTask(2, 0)
0714-171439.768 SS Stage 2 (textFile at <console>:12) finished in 23.196 s
0714-171439.768 SS Job finished: count at <console>:15, took 23.203579346 s
res2: Long = 2000298

scala> s.count()
0714-171440.063 SS Starting job: count at <console>:15
0714-171440.064 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171440.064 SS Final stage: Stage 3 (textFile at <console>:12)
0714-171440.064 SS Parents of final stage: List()
0714-171440.066 SS Missing parents: List()
0714-171440.067 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171440.067 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-171440.068 SS Running ResultTask(3, 0)
0714-171440.070 SS Size of task 0 is 1434 bytes
0714-171440.101 SS Got brand-new decompressor
0714-171502.572 SS Finished ResultTask(3, 0)
0714-171502.573 SS Completed ResultTask(3, 0)
0714-171502.573 SS Stage 3 (textFile at <console>:12) finished in 22.502 s
0714-171502.574 SS Job finished: count at <console>:15, took 22.509463796 s
res3: Long = 2000298

scala> s.count()
0714-171502.815 SS Starting job: count at <console>:15
0714-171502.816 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171502.816 SS Final stage: Stage 4 (textFile at <console>:12)
0714-171502.816 SS Parents of final stage: List()
0714-171502.818 SS Missing parents: List()
0714-171502.819 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171502.819 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-171502.820 SS Running ResultTask(4, 0)
0714-171502.822 SS Size of task 0 is 1434 bytes
0714-171502.852 SS Got brand-new decompressor
0714-171525.111 SS Finished ResultTask(4, 0)
0714-171525.112 SS Completed ResultTask(4, 0)
0714-171525.112 SS Stage 4 (textFile at <console>:12) finished in 22.289 s
0714-171525.112 SS Job finished: count at <console>:15, took 22.296551864 s
res4: Long = 2000298

scala> restaring tachyon
Killed 0 processes
Killed 0 processes
localhost: Killed 0 processes
Mounting ramfs on Linux...
TACHYON_RAM_FOLDER was not set. Using the default one: /mnt/ramdisk
Formatting RamFS: /mnt/ramdisk
Starting master @ localhost
Starting worker @ tachyon-ec2-0

spark-shell count
25422 tachyon.Master
25435 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-171546.471 SS Slf4jEventHandler started
0714-171547.160 SS Registered BlockManagerMaster Actor
0714-171547.202 SS MemoryStore started with capacity 326.7 MB.
0714-171547.215 SS Created local directory at /tmp/spark-local-20130714171547-1019
0714-171547.277 SS Bound socket to port 53151 with id = ConnectionManagerId(tachyon-ec2-0,53151)
0714-171547.298 SS Trying to register BlockManager
0714-171547.305 SS Registering block manager tachyon-ec2-0:53151 with 326.7 MB RAM
0714-171547.306 SS Registered BlockManager
0714-171547.381 SS Broadcast server started at http://10.190.33.193:54266
0714-171547.395 SS Registered MapOutputTrackerActor actor
0714-171547.402 SS HTTP File server directory is /tmp/spark-df174b79-9346-456e-9fe4-c9c9f9c06c7f
0714-171547.834 SS IoWorker thread 'spray-io-worker-0' started
0714-171549.015 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:47499
0714-171549.021 SS Started BlockManager web UI at http://tachyon-ec2-0:47499
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("tachyon://localhost:19998/hit_data.tsv.2000000.gz")
0714-171551.674 SS ensureFreeSpace(58447) called with curMem=0, maxMem=342526525
0714-171551.677 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-171552.296 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-171552.297 SS Snappy native library not loaded
0714-171552.338 SS 25483 62 Thread-37 |        Trying to connect master @ localhost/127.0.0.1:19998
0714-171552.416 SS 25483 62 Thread-37 |          User registered at the master localhost/127.0.0.1:19998 got UserId 1
0714-171552.416 SS 25483 62 Thread-37 |        Trying to get local worker host : tachyon-ec2-0
0714-171552.443 SS 25483 62 Thread-37 |        Connecting local worker @ tachyon-ec2-0/10.190.33.193:29998
0714-171554.128 SS Total input paths to process : 1
0714-171556.394 SS Starting job: count at <console>:15
0714-171556.429 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171556.436 SS Final stage: Stage 0 (textFile at <console>:12)
0714-171556.437 SS Parents of final stage: List()
0714-171556.465 SS Missing parents: List()
0714-171556.471 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171556.489 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-171556.498 SS Running ResultTask(0, 0)
0714-171556.557 SS Size of task 0 is 1442 bytes
0714-171556.645 SS 25483 65 pool-1-thread-1 |          /mnt/ramdisk/tachyonworker/2 is not on local disk.
0714-171556.662 SS 25483 65 pool-1-thread-1 |          Try to find and read from remote workers.
0714-171556.782 SS 25483 65 pool-1-thread-1 |          fileLocations: [NetAddress(mHost:localhost, mPort:-1)]
0714-171556.918 SS Opening 's3n://2012-05-19-sample/hit_data.tsv.2000000.gz' for reading
0714-171557.057 SS 25483 65 pool-1-thread-1 |          Folder /mnt/ramdisk/tachyonworker/users/1 was created!
0714-171557.060 SS 25483 65 pool-1-thread-1 |        File /mnt/ramdisk/tachyonworker/users/1/2 was created!
0714-171613.989 SS Got brand-new decompressor
0714-171640.773 SS Finished ResultTask(0, 0)
0714-171640.775 SS Completed ResultTask(0, 0)
0714-171640.778 SS Stage 0 (textFile at <console>:12) finished in 44.280 s
0714-171640.779 SS Job finished: count at <console>:15, took 44.36795163 s
res0: Long = 2000298

scala> s.count()
0714-171641.130 SS Starting job: count at <console>:15
0714-171641.134 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171641.134 SS Final stage: Stage 1 (textFile at <console>:12)
0714-171641.134 SS Parents of final stage: List()
0714-171641.136 SS Missing parents: List()
0714-171641.136 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171641.137 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-171641.138 SS Running ResultTask(1, 0)
0714-171641.140 SS Size of task 0 is 1445 bytes
0714-171641.193 SS Got brand-new decompressor
0714-171707.191 SS Finished ResultTask(1, 0)
0714-171707.192 SS Completed ResultTask(1, 0)
0714-171707.192 SS Stage 1 (textFile at <console>:12) finished in 26.050 s
0714-171707.192 SS Job finished: count at <console>:15, took 26.058748141 s
res1: Long = 2000298

scala> s.count()
0714-171707.446 SS Starting job: count at <console>:15
0714-171707.447 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171707.447 SS Final stage: Stage 2 (textFile at <console>:12)
0714-171707.447 SS Parents of final stage: List()
0714-171707.449 SS Missing parents: List()
0714-171707.449 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171707.450 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-171707.450 SS Running ResultTask(2, 0)
0714-171707.452 SS Size of task 0 is 1445 bytes
0714-171707.520 SS Got brand-new decompressor
0714-171732.758 SS Finished ResultTask(2, 0)
0714-171732.759 SS Completed ResultTask(2, 0)
0714-171732.759 SS Stage 2 (textFile at <console>:12) finished in 25.304 s
0714-171732.760 SS Job finished: count at <console>:15, took 25.312913664 s
res2: Long = 2000298

scala> s.count()
0714-171733.092 SS Starting job: count at <console>:15
0714-171733.092 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171733.092 SS Final stage: Stage 3 (textFile at <console>:12)
0714-171733.093 SS Parents of final stage: List()
0714-171733.094 SS Missing parents: List()
0714-171733.095 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171733.095 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-171733.096 SS Running ResultTask(3, 0)
0714-171733.098 SS Size of task 0 is 1445 bytes
0714-171733.128 SS Got brand-new decompressor
0714-171758.478 SS Finished ResultTask(3, 0)
0714-171758.479 SS Completed ResultTask(3, 0)
0714-171758.480 SS Stage 3 (textFile at <console>:12) finished in 25.380 s
0714-171758.480 SS Job finished: count at <console>:15, took 25.387517044 s
res3: Long = 2000298

scala> s.count()
0714-171758.731 SS Starting job: count at <console>:15
0714-171758.732 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171758.732 SS Final stage: Stage 4 (textFile at <console>:12)
0714-171758.732 SS Parents of final stage: List()
0714-171758.734 SS Missing parents: List()
0714-171758.735 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171758.735 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-171758.736 SS Running ResultTask(4, 0)
0714-171758.738 SS Size of task 0 is 1445 bytes
0714-171758.770 SS Got brand-new decompressor
0714-171824.200 SS Finished ResultTask(4, 0)
0714-171824.201 SS Completed ResultTask(4, 0)
0714-171824.201 SS Stage 4 (textFile at <console>:12) finished in 25.462 s
0714-171824.202 SS Job finished: count at <console>:15, took 25.469988047 s
res4: Long = 2000298

scala> Killed 1 processes
Killed 1 processes
localhost: Killed 0 processes
Formatting Tachyon @ localhost
0714-171825.787 TU Deleting /mnt/tachyon/tachyon/tachyon_checkpoint.data
0714-171825.789 TU Deleting /mnt/tachyon/tachyon/tachyon_log.data
0714-171826.804 TU Formatting s3n://2012-05-19-sample/tachyon/data
0714-171828.092 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-171828.298 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-171828.317 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-171828.368 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-171828.399 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-171828.422 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-171828.476 TU Formatting s3n://2012-05-19-sample/tachyon/workers
0714-171828.495 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-171828.610 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-171828.633 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200
0714-171828.688 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-171828.727 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-171828.753 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200

spark-shell count

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-171846.184 SS Slf4jEventHandler started
0714-171846.852 SS Registered BlockManagerMaster Actor
0714-171846.918 SS MemoryStore started with capacity 326.7 MB.
0714-171846.931 SS Created local directory at /tmp/spark-local-20130714171846-9046
0714-171846.989 SS Bound socket to port 38346 with id = ConnectionManagerId(tachyon-ec2-0,38346)
0714-171847.012 SS Trying to register BlockManager
0714-171847.015 SS Registering block manager tachyon-ec2-0:38346 with 326.7 MB RAM
0714-171847.016 SS Registered BlockManager
0714-171847.061 SS Broadcast server started at http://10.190.33.193:50335
0714-171847.074 SS Registered MapOutputTrackerActor actor
0714-171847.083 SS HTTP File server directory is /tmp/spark-dc7414bb-e503-4e41-abc7-fd54e8c71cf5
0714-171847.540 SS IoWorker thread 'spray-io-worker-0' started
0714-171848.719 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:39838
0714-171848.721 SS Started BlockManager web UI at http://tachyon-ec2-0:39838
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/data/hit_data.tsv.3000000.gz")
0714-171851.264 SS ensureFreeSpace(58423) called with curMem=0, maxMem=342526525
0714-171851.267 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-171851.865 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-171851.866 SS Snappy native library not loaded
0714-171851.890 SS Total input paths to process : 1
0714-171851.913 SS Starting job: count at <console>:15
0714-171851.924 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171851.925 SS Final stage: Stage 0 (textFile at <console>:12)
0714-171851.925 SS Parents of final stage: List()
0714-171851.934 SS Missing parents: List()
0714-171851.940 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171851.951 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-171851.966 SS Running ResultTask(0, 0)
0714-171852.187 SS Size of task 0 is 1431 bytes
0714-171852.358 SS Got brand-new decompressor
0714-171926.721 SS Finished ResultTask(0, 0)
0714-171926.724 SS Completed ResultTask(0, 0)
0714-171926.726 SS Stage 0 (textFile at <console>:12) finished in 34.760 s
0714-171926.728 SS Job finished: count at <console>:15, took 34.814947402 s
res0: Long = 3000314

scala> s.count()
0714-171927.009 SS Starting job: count at <console>:15
0714-171927.011 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-171927.011 SS Final stage: Stage 1 (textFile at <console>:12)
0714-171927.012 SS Parents of final stage: List()
0714-171927.013 SS Missing parents: List()
0714-171927.014 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-171927.014 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-171927.015 SS Running ResultTask(1, 0)
0714-171927.017 SS Size of task 0 is 1434 bytes
0714-171927.073 SS Got brand-new decompressor
0714-172001.402 SS Finished ResultTask(1, 0)
0714-172001.403 SS Completed ResultTask(1, 0)
0714-172001.404 SS Stage 1 (textFile at <console>:12) finished in 34.384 s
0714-172001.404 SS Job finished: count at <console>:15, took 34.392718184 s
res1: Long = 3000314

scala> s.count()
0714-172001.690 SS Starting job: count at <console>:15
0714-172001.691 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-172001.691 SS Final stage: Stage 2 (textFile at <console>:12)
0714-172001.691 SS Parents of final stage: List()
0714-172001.693 SS Missing parents: List()
0714-172001.694 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-172001.694 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-172001.695 SS Running ResultTask(2, 0)
0714-172001.697 SS Size of task 0 is 1434 bytes
0714-172001.758 SS Got brand-new decompressor
0714-172035.527 SS Finished ResultTask(2, 0)
0714-172035.528 SS Completed ResultTask(2, 0)
0714-172035.528 SS Stage 2 (textFile at <console>:12) finished in 33.829 s
0714-172035.529 SS Job finished: count at <console>:15, took 33.837816713 s
res2: Long = 3000314

scala> s.count()
0714-172035.802 SS Starting job: count at <console>:15
0714-172035.802 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-172035.802 SS Final stage: Stage 3 (textFile at <console>:12)
0714-172035.802 SS Parents of final stage: List()
0714-172035.808 SS Missing parents: List()
0714-172035.808 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-172035.809 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-172035.809 SS Running ResultTask(3, 0)
0714-172035.811 SS Size of task 0 is 1434 bytes
0714-172035.859 SS Got brand-new decompressor
0714-172109.290 SS Finished ResultTask(3, 0)
0714-172109.296 SS Completed ResultTask(3, 0)
0714-172109.296 SS Stage 3 (textFile at <console>:12) finished in 33.484 s
0714-172109.296 SS Job finished: count at <console>:15, took 33.494017305 s
res3: Long = 3000314

scala> s.count()
0714-172109.568 SS Starting job: count at <console>:15
0714-172109.569 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-172109.569 SS Final stage: Stage 4 (textFile at <console>:12)
0714-172109.569 SS Parents of final stage: List()
0714-172109.571 SS Missing parents: List()
0714-172109.571 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-172109.572 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-172109.572 SS Running ResultTask(4, 0)
0714-172109.574 SS Size of task 0 is 1434 bytes
0714-172109.606 SS Got brand-new decompressor
0714-172143.138 SS Finished ResultTask(4, 0)
0714-172143.139 SS Completed ResultTask(4, 0)
0714-172143.139 SS Stage 4 (textFile at <console>:12) finished in 33.564 s
0714-172143.140 SS Job finished: count at <console>:15, took 33.571131263 s
res4: Long = 3000314

scala> restaring tachyon
Killed 0 processes
Killed 0 processes
localhost: Killed 0 processes
Mounting ramfs on Linux...
TACHYON_RAM_FOLDER was not set. Using the default one: /mnt/ramdisk
Formatting RamFS: /mnt/ramdisk
Starting master @ localhost
Starting worker @ tachyon-ec2-0

spark-shell count
26311 tachyon.Master
26325 tachyon.Worker

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-172204.560 SS Slf4jEventHandler started
0714-172205.248 SS Registered BlockManagerMaster Actor
0714-172205.302 SS MemoryStore started with capacity 326.7 MB.
0714-172205.311 SS Created local directory at /tmp/spark-local-20130714172205-ef4c
0714-172205.374 SS Bound socket to port 57880 with id = ConnectionManagerId(tachyon-ec2-0,57880)
0714-172205.396 SS Trying to register BlockManager
0714-172205.399 SS Registering block manager tachyon-ec2-0:57880 with 326.7 MB RAM
0714-172205.400 SS Registered BlockManager
0714-172205.449 SS Broadcast server started at http://10.190.33.193:33551
0714-172205.460 SS Registered MapOutputTrackerActor actor
0714-172205.466 SS HTTP File server directory is /tmp/spark-2a1f7fbe-de6d-4588-bf66-16903cbec89f
0714-172205.925 SS IoWorker thread 'spray-io-worker-0' started
0714-172207.126 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:35176
0714-172207.128 SS Started BlockManager web UI at http://tachyon-ec2-0:35176
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("tachyon://localhost:19998/hit_data.tsv.3000000.gz")
0714-172209.773 SS ensureFreeSpace(58447) called with curMem=0, maxMem=342526525
0714-172209.782 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-172210.395 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-172210.399 SS Snappy native library not loaded
0714-172210.439 SS 26372 62 Thread-37 |        Trying to connect master @ localhost/127.0.0.1:19998
0714-172210.504 SS 26372 62 Thread-37 |          User registered at the master localhost/127.0.0.1:19998 got UserId 1
0714-172210.504 SS 26372 62 Thread-37 |        Trying to get local worker host : tachyon-ec2-0
0714-172210.517 SS 26372 62 Thread-37 |        Connecting local worker @ tachyon-ec2-0/10.190.33.193:29998
0714-172212.168 SS Total input paths to process : 1
0714-172214.465 SS Starting job: count at <console>:15
0714-172214.480 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-172214.481 SS Final stage: Stage 0 (textFile at <console>:12)
0714-172214.482 SS Parents of final stage: List()
0714-172214.490 SS Missing parents: List()
0714-172214.492 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-172214.501 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-172214.506 SS Running ResultTask(0, 0)
0714-172214.565 SS Size of task 0 is 1442 bytes
0714-172214.665 SS 26372 65 pool-1-thread-1 |          /mnt/ramdisk/tachyonworker/2 is not on local disk.
0714-172214.675 SS 26372 65 pool-1-thread-1 |          Try to find and read from remote workers.
0714-172214.794 SS 26372 65 pool-1-thread-1 |          fileLocations: [NetAddress(mHost:localhost, mPort:-1)]
0714-172214.995 SS Opening 's3n://2012-05-19-sample/hit_data.tsv.3000000.gz' for reading
0714-172215.121 SS 26372 65 pool-1-thread-1 |          Folder /mnt/ramdisk/tachyonworker/users/1 was created!
0714-172215.126 SS 26372 65 pool-1-thread-1 |        File /mnt/ramdisk/tachyonworker/users/1/2 was created!
0714-172233.720 SS Got brand-new decompressor
0714-172312.897 SS Finished ResultTask(0, 0)
0714-172312.903 SS Completed ResultTask(0, 0)
0714-172312.905 SS Stage 0 (textFile at <console>:12) finished in 58.400 s
0714-172312.907 SS Job finished: count at <console>:15, took 58.439730307 s
res0: Long = 3000314

scala> s.count()
0714-172313.175 SS Starting job: count at <console>:15
0714-172313.175 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-172313.176 SS Final stage: Stage 1 (textFile at <console>:12)
0714-172313.176 SS Parents of final stage: List()
0714-172313.178 SS Missing parents: List()
0714-172313.178 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-172313.179 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-172313.179 SS Running ResultTask(1, 0)
0714-172313.181 SS Size of task 0 is 1445 bytes
0714-172313.218 SS Got brand-new decompressor
0714-172351.884 SS Finished ResultTask(1, 0)
0714-172351.884 SS Completed ResultTask(1, 0)
0714-172351.885 SS Stage 1 (textFile at <console>:12) finished in 38.702 s
0714-172351.885 SS Job finished: count at <console>:15, took 38.709739433 s
res1: Long = 3000314

scala> s.count()
0714-172352.215 SS Starting job: count at <console>:15
0714-172352.215 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-172352.215 SS Final stage: Stage 2 (textFile at <console>:12)
0714-172352.216 SS Parents of final stage: List()
0714-172352.217 SS Missing parents: List()
0714-172352.218 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-172352.219 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-172352.219 SS Running ResultTask(2, 0)
0714-172352.221 SS Size of task 0 is 1445 bytes
0714-172352.259 SS Got brand-new decompressor
0714-172430.295 SS Finished ResultTask(2, 0)
0714-172430.296 SS Completed ResultTask(2, 0)
0714-172430.296 SS Stage 2 (textFile at <console>:12) finished in 38.073 s
0714-172430.296 SS Job finished: count at <console>:15, took 38.081196599 s
res2: Long = 3000314

scala> s.count()
0714-172430.576 SS Starting job: count at <console>:15
0714-172430.577 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-172430.577 SS Final stage: Stage 3 (textFile at <console>:12)
0714-172430.577 SS Parents of final stage: List()
0714-172430.579 SS Missing parents: List()
0714-172430.580 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-172430.580 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-172430.581 SS Running ResultTask(3, 0)
0714-172430.582 SS Size of task 0 is 1445 bytes
0714-172430.613 SS Got brand-new decompressor
0714-172508.775 SS Finished ResultTask(3, 0)
0714-172508.775 SS Completed ResultTask(3, 0)
0714-172508.776 SS Stage 3 (textFile at <console>:12) finished in 38.192 s
0714-172508.776 SS Job finished: count at <console>:15, took 38.199014813 s
res3: Long = 3000314

scala> s.count()
0714-172509.063 SS Starting job: count at <console>:15
0714-172509.068 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-172509.068 SS Final stage: Stage 4 (textFile at <console>:12)
0714-172509.068 SS Parents of final stage: List()
0714-172509.072 SS Missing parents: List()
0714-172509.073 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-172509.073 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-172509.074 SS Running ResultTask(4, 0)
0714-172509.076 SS Size of task 0 is 1445 bytes
0714-172509.143 SS Got brand-new decompressor
0714-172546.872 SS Finished ResultTask(4, 0)
0714-172546.873 SS Completed ResultTask(4, 0)
0714-172546.873 SS Stage 4 (textFile at <console>:12) finished in 37.794 s
0714-172546.873 SS Job finished: count at <console>:15, took 37.805864673 s
res4: Long = 3000314

scala> Killed 1 processes
Killed 1 processes
localhost: Killed 0 processes
Formatting Tachyon @ localhost
0714-172548.531 TU Deleting /mnt/tachyon/tachyon/tachyon_checkpoint.data
0714-172548.538 TU Deleting /mnt/tachyon/tachyon/tachyon_log.data
0714-172549.567 TU Formatting s3n://2012-05-19-sample/tachyon/data
0714-172550.873 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-172551.070 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-172551.093 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-172551.216 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-172551.290 TU Response '/tachyon%2Fdata' - Unexpected response code 404, expected 200
0714-172551.312 TU Response '/tachyon%2Fdata_%24folder%24' - Unexpected response code 404, expected 200
0714-172551.373 TU Formatting s3n://2012-05-19-sample/tachyon/workers
0714-172551.402 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-172551.558 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-172551.572 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200
0714-172551.618 TU Response '/tachyon' - Unexpected response code 404, expected 200
0714-172551.658 TU Response '/tachyon%2Fworkers' - Unexpected response code 404, expected 200
0714-172551.681 TU Response '/tachyon%2Fworkers_%24folder%24' - Unexpected response code 404, expected 200

spark-shell count

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.2.1-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark-0.7.0/lib_managed/jars/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.7.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_21)
Initializing interpreter...
Creating SparkContext...
0714-172609.060 SS Slf4jEventHandler started
0714-172609.728 SS Registered BlockManagerMaster Actor
0714-172609.796 SS MemoryStore started with capacity 326.7 MB.
0714-172609.805 SS Created local directory at /tmp/spark-local-20130714172609-63be
0714-172609.862 SS Bound socket to port 46828 with id = ConnectionManagerId(tachyon-ec2-0,46828)
0714-172609.905 SS Trying to register BlockManager
0714-172609.913 SS Registering block manager tachyon-ec2-0:46828 with 326.7 MB RAM
0714-172609.914 SS Registered BlockManager
0714-172609.960 SS Broadcast server started at http://10.190.33.193:49400
0714-172609.974 SS Registered MapOutputTrackerActor actor
0714-172609.979 SS HTTP File server directory is /tmp/spark-80ebff23-1e54-4333-b033-b79f81579e30
0714-172610.377 SS IoWorker thread 'spray-io-worker-0' started
0714-172611.604 SS akka://spark/user/BlockManagerHTTPServer started on /0.0.0.0:49216
0714-172611.606 SS Started BlockManager web UI at http://tachyon-ec2-0:49216
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/data/hit_data.tsv.4000000.gz")
0714-172614.119 SS ensureFreeSpace(58423) called with curMem=0, maxMem=342526525
0714-172614.122 SS Block broadcast_0 stored as values to memory (estimated size 57.1 KB, free 326.6 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
0714-172614.749 SS Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
0714-172614.752 SS Snappy native library not loaded
0714-172614.776 SS Total input paths to process : 1
0714-172614.798 SS Starting job: count at <console>:15
0714-172614.820 SS Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-172614.824 SS Final stage: Stage 0 (textFile at <console>:12)
0714-172614.825 SS Parents of final stage: List()
0714-172614.847 SS Missing parents: List()
0714-172614.850 SS Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-172614.867 SS Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
0714-172614.880 SS Running ResultTask(0, 0)
0714-172615.074 SS Size of task 0 is 1431 bytes
0714-172615.241 SS Got brand-new decompressor
0714-172700.966 SS Exception in task 0
java.io.IOException: stored gzip size doesn't match decompressed size
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeTrailerState(BuiltInGzipDecompressor.java:389)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:224)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:83)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:77)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:176)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:43)
	at spark.rdd.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:84)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:492)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:490)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.scheduler.ResultTask.run(ResultTask.scala:76)
	at spark.scheduler.local.LocalScheduler.runTask$1(LocalScheduler.scala:74)
	at spark.scheduler.local.LocalScheduler$$anon$1.run(LocalScheduler.scala:50)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
0714-172700.993 SS Failed to run count at <console>:15
spark.SparkException: Job failed: ResultTask(0, 0) failed: ExceptionFailure(java.io.IOException: stored gzip size doesn't match decompressed size)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:629)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:627)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:60)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:627)
	at spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:588)
	at spark.scheduler.DAGScheduler.processEvent(DAGScheduler.scala:294)
	at spark.scheduler.DAGScheduler.spark$scheduler$DAGScheduler$$run(DAGScheduler.scala:358)
	at spark.scheduler.DAGScheduler$$anon$1.run(DAGScheduler.scala:102)

scala> s.count()
0714-172701.684 SS Starting job: count at <console>:15
0714-172701.688 SS Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-172701.688 SS Final stage: Stage 1 (textFile at <console>:12)
0714-172701.688 SS Parents of final stage: List()
0714-172701.690 SS Missing parents: List()
0714-172701.691 SS Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-172701.691 SS Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
0714-172701.692 SS Running ResultTask(1, 0)
0714-172701.694 SS Size of task 0 is 1431 bytes
0714-172701.783 SS Got brand-new decompressor
0714-172747.922 SS Exception in task 0
java.io.IOException: stored gzip size doesn't match decompressed size
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeTrailerState(BuiltInGzipDecompressor.java:389)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:224)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:83)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:77)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:176)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:43)
	at spark.rdd.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:84)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:492)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:490)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.scheduler.ResultTask.run(ResultTask.scala:76)
	at spark.scheduler.local.LocalScheduler.runTask$1(LocalScheduler.scala:74)
	at spark.scheduler.local.LocalScheduler$$anon$1.run(LocalScheduler.scala:50)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
0714-172747.923 SS Failed to run count at <console>:15
spark.SparkException: Job failed: ResultTask(1, 0) failed: ExceptionFailure(java.io.IOException: stored gzip size doesn't match decompressed size)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:629)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:627)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:60)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:627)
	at spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:588)
	at spark.scheduler.DAGScheduler.processEvent(DAGScheduler.scala:294)
	at spark.scheduler.DAGScheduler.spark$scheduler$DAGScheduler$$run(DAGScheduler.scala:358)
	at spark.scheduler.DAGScheduler$$anon$1.run(DAGScheduler.scala:102)

scala> s.count()
0714-172748.519 SS Starting job: count at <console>:15
0714-172748.519 SS Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-172748.520 SS Final stage: Stage 2 (textFile at <console>:12)
0714-172748.520 SS Parents of final stage: List()
0714-172748.521 SS Missing parents: List()
0714-172748.521 SS Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-172748.522 SS Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
0714-172748.522 SS Running ResultTask(2, 0)
0714-172748.524 SS Size of task 0 is 1431 bytes
0714-172748.583 SS Got brand-new decompressor
0714-172834.213 SS Exception in task 0
java.io.IOException: stored gzip size doesn't match decompressed size
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeTrailerState(BuiltInGzipDecompressor.java:389)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:224)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:83)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:77)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:176)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:43)
	at spark.rdd.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:84)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:492)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:490)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.scheduler.ResultTask.run(ResultTask.scala:76)
	at spark.scheduler.local.LocalScheduler.runTask$1(LocalScheduler.scala:74)
	at spark.scheduler.local.LocalScheduler$$anon$1.run(LocalScheduler.scala:50)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
0714-172834.220 SS Failed to run count at <console>:15
spark.SparkException: Job failed: ResultTask(2, 0) failed: ExceptionFailure(java.io.IOException: stored gzip size doesn't match decompressed size)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:629)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:627)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:60)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:627)
	at spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:588)
	at spark.scheduler.DAGScheduler.processEvent(DAGScheduler.scala:294)
	at spark.scheduler.DAGScheduler.spark$scheduler$DAGScheduler$$run(DAGScheduler.scala:358)
	at spark.scheduler.DAGScheduler$$anon$1.run(DAGScheduler.scala:102)

scala> s.count()
0714-172834.887 SS Starting job: count at <console>:15
0714-172834.888 SS Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-172834.888 SS Final stage: Stage 3 (textFile at <console>:12)
0714-172834.888 SS Parents of final stage: List()
0714-172834.889 SS Missing parents: List()
0714-172834.890 SS Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-172834.890 SS Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
0714-172834.890 SS Running ResultTask(3, 0)
0714-172834.892 SS Size of task 0 is 1431 bytes
0714-172834.983 SS Got brand-new decompressor
0714-172920.034 SS Exception in task 0
java.io.IOException: stored gzip size doesn't match decompressed size
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeTrailerState(BuiltInGzipDecompressor.java:389)
	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:224)
	at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:83)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:77)
	at java.io.InputStream.read(InputStream.java:101)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:176)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:43)
	at spark.rdd.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:84)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:400)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:492)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:490)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:610)
	at spark.scheduler.ResultTask.run(ResultTask.scala:76)
	at spark.scheduler.local.LocalScheduler.runTask$1(LocalScheduler.scala:74)
	at spark.scheduler.local.LocalScheduler$$anon$1.run(LocalScheduler.scala:50)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
0714-172920.035 SS Failed to run count at <console>:15
spark.SparkException: Job failed: ResultTask(3, 0) failed: ExceptionFailure(java.io.IOException: stored gzip size doesn't match decompressed size)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:629)
	at spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:627)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:60)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:627)
	at spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:588)
	at spark.scheduler.DAGScheduler.processEvent(DAGScheduler.scala:294)
	at spark.scheduler.DAGScheduler.spark$scheduler$DAGScheduler$$run(DAGScheduler.scala:358)
	at spark.scheduler.DAGScheduler$$anon$1.run(DAGScheduler.scala:102)

scala> s.count()
0714-172920.607 SS Starting job: count at <console>:15
0714-172920.607 SS Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
0714-172920.607 SS Final stage: Stage 4 (textFile at <console>:12)
0714-172920.607 SS Parents of final stage: List()
0714-172920.608 SS Missing parents: List()
0714-172920.609 SS Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
0714-172920.609 SS Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
0714-172920.609 SS Running ResultTask(4, 0)
0714-172920.611 SS Size of task 0 is 1431 bytes
0714-172920.641 SS Got brand-new decompressor
restaring tachyon
