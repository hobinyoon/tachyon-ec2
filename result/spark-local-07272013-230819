run1 #: 0

spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1 as mode POSIX_FADV_DONTNEED
offset: 0
length: 525
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:08:21 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:08:21 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:49036
Creating SparkContext...
13/07/27 23:08:30 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:08:30 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:08:30 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:08:30 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727230830-444e
13/07/27 23:08:30 INFO network.ConnectionManager: Bound socket to port 38143 with id = ConnectionManagerId(tachyon-ec2-0,38143)
13/07/27 23:08:30 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:08:30 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:38143 with 1295.4 MB RAM
13/07/27 23:08:30 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:08:30 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:08:30 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:47551
13/07/27 23:08:30 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:47551
13/07/27 23:08:30 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:08:30 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-569d6e2c-4ac4-4978-a1ea-956a87f7e171
13/07/27 23:08:30 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:08:30 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:41263
13/07/27 23:08:31 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:08:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:08:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:08:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:08:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:08:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:08:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:08:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:08:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:08:31 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:08:31 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1").cache()
13/07/27 23:08:32 INFO storage.MemoryStore: ensureFreeSpace(58391) called with curMem=0, maxMem=1358297825
13/07/27 23:08:32 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:08:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:08:32 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:08:32 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:08:32 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:08:32 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:08:32 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:08:32 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:08:32 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:08:32 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:08:32 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:08:32 INFO local.LocalTaskSetManager: Size of task 0 is 1486 bytes
13/07/27 23:08:32 INFO local.LocalScheduler: Running 0
13/07/27 23:08:33 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:08:33 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:08:33 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58391, maxMem=1358297825
13/07/27 23:08:33 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/27 23:08:33 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:38143 (size: 1192.0 B, free: 1295.4 MB)
13/07/27 23:08:33 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:08:33 INFO local.LocalScheduler: Finished 0
13/07/27 23:08:33 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:08:33 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:08:33 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.313 s
13/07/27 23:08:33 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.357849291 s
res0: Long = 1

scala> 13/07/27 23:08:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:08:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:08:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:08:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:08:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:08:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:08:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:08:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100 as mode POSIX_FADV_DONTNEED
offset: 0
length: 55735
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:08:35 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:08:35 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:49973
Creating SparkContext...
13/07/27 23:08:44 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:08:45 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:08:45 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:08:45 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727230845-12df
13/07/27 23:08:45 INFO network.ConnectionManager: Bound socket to port 49747 with id = ConnectionManagerId(tachyon-ec2-0,49747)
13/07/27 23:08:45 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:08:45 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:49747 with 1295.4 MB RAM
13/07/27 23:08:45 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:08:45 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:08:45 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:36420
13/07/27 23:08:45 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:36420
13/07/27 23:08:45 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:08:45 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-e7d0df57-3b47-4aa5-9df0-5e2eced7a1a0
13/07/27 23:08:45 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:08:45 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:48933
13/07/27 23:08:45 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:08:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:08:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:08:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:08:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:08:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:08:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:08:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:08:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:08:45 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:08:45 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100").cache()
13/07/27 23:08:46 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:08:46 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:08:47 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:08:47 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:08:47 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:08:47 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:08:47 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:08:47 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:08:47 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:08:47 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:08:47 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:08:47 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:08:47 INFO local.LocalTaskSetManager: Size of task 0 is 1488 bytes
13/07/27 23:08:47 INFO local.LocalScheduler: Running 0
13/07/27 23:08:47 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:08:47 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:08:47 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58399, maxMem=1358297825
13/07/27 23:08:47 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/27 23:08:47 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:49747 (size: 113.4 KB, free: 1295.3 MB)
13/07/27 23:08:47 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:08:47 INFO local.LocalScheduler: Finished 0
13/07/27 23:08:47 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:08:47 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:08:47 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.220 s
13/07/27 23:08:47 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.264133637 s
res0: Long = 100

scala> 13/07/27 23:08:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:08:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:08:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:08:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:08:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:08:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:08:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:08:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 776400
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:08:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:08:50 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:45083
Creating SparkContext...
13/07/27 23:08:59 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:08:59 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:08:59 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:08:59 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727230859-77e7
13/07/27 23:08:59 INFO network.ConnectionManager: Bound socket to port 60583 with id = ConnectionManagerId(tachyon-ec2-0,60583)
13/07/27 23:08:59 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:08:59 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:60583 with 1295.4 MB RAM
13/07/27 23:08:59 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:08:59 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:08:59 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55413
13/07/27 23:08:59 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:55413
13/07/27 23:08:59 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:08:59 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-6fd8ca80-c3ef-41b3-b8cf-032a9610fff0
13/07/27 23:08:59 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:08:59 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:51683
13/07/27 23:08:59 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:08:59 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:08:59 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:08:59 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:08:59 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:08:59 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:08:59 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:08:59 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:08:59 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:08:59 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:08:59 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1000").cache()
13/07/27 23:09:01 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:09:01 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:09:01 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:09:01 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:09:01 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:09:01 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:09:01 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:09:01 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:09:01 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:09:01 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:09:01 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:09:01 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:09:01 INFO local.LocalTaskSetManager: Size of task 0 is 1489 bytes
13/07/27 23:09:01 INFO local.LocalScheduler: Running 0
13/07/27 23:09:01 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:09:01 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:09:01 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58399, maxMem=1358297825
13/07/27 23:09:01 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/27 23:09:01 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:60583 (size: 1580.2 KB, free: 1293.8 MB)
13/07/27 23:09:01 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:09:01 INFO local.LocalScheduler: Finished 0
13/07/27 23:09:01 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:09:01 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:09:01 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.240 s
13/07/27 23:09:01 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.283941757 s
res0: Long = 1000

scala> 13/07/27 23:09:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:09:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:09:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:09:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:09:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:09:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:09:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:09:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.10000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 12330369
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:09:04 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:09:04 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37776
Creating SparkContext...
13/07/27 23:09:13 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:09:13 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:09:13 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:09:13 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727230913-c145
13/07/27 23:09:13 INFO network.ConnectionManager: Bound socket to port 54093 with id = ConnectionManagerId(tachyon-ec2-0,54093)
13/07/27 23:09:13 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:09:13 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:54093 with 1295.4 MB RAM
13/07/27 23:09:13 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:09:13 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:09:13 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50099
13/07/27 23:09:13 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:50099
13/07/27 23:09:13 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:09:13 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-d1091375-df23-436b-b165-a43c56bd15eb
13/07/27 23:09:13 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:09:13 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:51584
13/07/27 23:09:13 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:09:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:09:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:09:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:09:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:09:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:09:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:09:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:09:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:09:13 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:09:13 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.10000").cache()
13/07/27 23:09:15 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:09:15 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:09:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:09:15 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:09:15 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:09:15 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:09:15 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:09:15 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:09:15 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:09:15 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:09:15 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:09:15 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:09:15 INFO local.LocalTaskSetManager: Size of task 0 is 1490 bytes
13/07/27 23:09:15 INFO local.LocalScheduler: Running 0
13/07/27 23:09:15 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:09:15 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:09:15 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58399, maxMem=1358297825
13/07/27 23:09:15 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/27 23:09:15 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:54093 (size: 25.0 MB, free: 1270.4 MB)
13/07/27 23:09:15 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:09:15 INFO local.LocalScheduler: Finished 0
13/07/27 23:09:15 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:09:16 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:09:16 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.431 s
13/07/27 23:09:16 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.478567481 s
res0: Long = 10000

scala> 13/07/27 23:09:16 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:09:16 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:09:16 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:09:16 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:09:16 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:09:16 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:09:16 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:09:16 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 125141299
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:09:18 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:09:18 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:33180
Creating SparkContext...
13/07/27 23:09:27 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:09:27 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:09:28 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:09:28 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727230928-c986
13/07/27 23:09:28 INFO network.ConnectionManager: Bound socket to port 56403 with id = ConnectionManagerId(tachyon-ec2-0,56403)
13/07/27 23:09:28 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:09:28 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:56403 with 1295.4 MB RAM
13/07/27 23:09:28 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:09:28 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:09:28 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55013
13/07/27 23:09:28 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:55013
13/07/27 23:09:28 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:09:28 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-238af3b7-09bf-4d19-976c-1de7f1a3f4f3
13/07/27 23:09:28 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:09:28 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:52617
13/07/27 23:09:28 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:09:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:09:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:09:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:09:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:09:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:09:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:09:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:09:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:09:28 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:09:28 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100000").cache()
13/07/27 23:09:29 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:09:29 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:09:29 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:09:29 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:09:29 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:09:29 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:09:29 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:09:29 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:09:29 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:09:29 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:09:29 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:09:29 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:09:30 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:09:30 INFO local.LocalScheduler: Running 0
13/07/27 23:09:30 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:09:30 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:09:30 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:09:30 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:09:30 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:56403 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:09:30 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:09:30 INFO local.LocalScheduler: Finished 0
13/07/27 23:09:30 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:09:30 INFO local.LocalScheduler: Running 1
13/07/27 23:09:30 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:09:30 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:09:30 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:09:30 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:09:30 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:09:30 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:56403 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:09:30 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:09:30 INFO local.LocalScheduler: Finished 1
13/07/27 23:09:30 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:09:30 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:09:30 INFO local.LocalScheduler: Running 2
13/07/27 23:09:30 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:09:30 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:09:31 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:09:31 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:09:31 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:56403 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:09:31 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:09:31 INFO local.LocalScheduler: Finished 2
13/07/27 23:09:31 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:09:31 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:09:31 INFO local.LocalScheduler: Running 3
13/07/27 23:09:31 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:09:31 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:09:31 INFO storage.MemoryStore: ensureFreeSpace(52232232) called with curMem=211087067, maxMem=1358297825
13/07/27 23:09:31 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 49.8 MB, free 1044.3 MB)
13/07/27 23:09:31 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:56403 (size: 49.8 MB, free: 1044.3 MB)
13/07/27 23:09:31 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:09:31 INFO local.LocalScheduler: Finished 3
13/07/27 23:09:31 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:09:31 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:09:31 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.527 s
13/07/27 23:09:31 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.573822892 s
res0: Long = 100002

scala> 13/07/27 23:09:31 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:09:31 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:09:31 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:09:31 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:09:31 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:09:31 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:09:31 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:09:31 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.500000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 618418417
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:09:34 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:09:34 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38528
Creating SparkContext...
13/07/27 23:09:43 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:09:43 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:09:43 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:09:43 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727230943-7b29
13/07/27 23:09:43 INFO network.ConnectionManager: Bound socket to port 36666 with id = ConnectionManagerId(tachyon-ec2-0,36666)
13/07/27 23:09:43 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:09:43 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:36666 with 1295.4 MB RAM
13/07/27 23:09:43 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:09:43 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:09:43 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:52362
13/07/27 23:09:43 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:52362
13/07/27 23:09:43 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:09:43 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-2794eb8f-14dd-4484-ba1e-2b29daeff884
13/07/27 23:09:43 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:09:43 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38801
13/07/27 23:09:43 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:09:43 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:09:43 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:09:43 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:09:43 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:09:43 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:09:43 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:09:43 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:09:43 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:09:43 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:09:43 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.500000").cache()
13/07/27 23:09:44 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:09:44 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:09:45 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:09:45 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:09:45 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:09:45 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:09:45 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:09:45 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:09:45 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:09:45 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:09:45 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:09:45 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:09:45 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:09:45 INFO local.LocalScheduler: Running 0
13/07/27 23:09:45 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:09:45 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:09:45 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:09:45 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:09:45 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:36666 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:09:45 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:09:45 INFO local.LocalScheduler: Finished 0
13/07/27 23:09:45 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:09:45 INFO local.LocalScheduler: Running 1
13/07/27 23:09:45 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:09:45 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:09:45 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:09:46 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:09:46 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:09:46 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:36666 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:09:46 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:09:46 INFO local.LocalScheduler: Finished 1
13/07/27 23:09:46 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:09:46 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:09:46 INFO local.LocalScheduler: Running 2
13/07/27 23:09:46 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:09:46 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:09:46 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:09:46 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:09:46 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:36666 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:09:46 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:09:46 INFO local.LocalScheduler: Finished 2
13/07/27 23:09:46 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:09:46 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:09:46 INFO local.LocalScheduler: Running 3
13/07/27 23:09:46 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:09:46 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:09:46 INFO storage.MemoryStore: ensureFreeSpace(73224723) called with curMem=211087067, maxMem=1358297825
13/07/27 23:09:46 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 69.8 MB, free 1024.2 MB)
13/07/27 23:09:46 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:36666 (size: 69.8 MB, free: 1024.3 MB)
13/07/27 23:09:46 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:09:46 INFO local.LocalScheduler: Finished 3
13/07/27 23:09:46 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:09:46 INFO local.LocalTaskSetManager: Size of task 4 is 1491 bytes
13/07/27 23:09:46 INFO local.LocalScheduler: Running 4
13/07/27 23:09:46 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:09:46 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@695
13/07/27 23:09:47 INFO storage.MemoryStore: ensureFreeSpace(72058182) called with curMem=284311790, maxMem=1358297825
13/07/27 23:09:47 INFO storage.MemoryStore: Block rdd_1_4 stored as values to memory (estimated size 68.7 MB, free 955.5 MB)
13/07/27 23:09:47 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_4 in memory on tachyon-ec2-0:36666 (size: 68.7 MB, free: 955.6 MB)
13/07/27 23:09:47 INFO storage.BlockManagerMaster: Updated info of block rdd_1_4
13/07/27 23:09:47 INFO local.LocalScheduler: Finished 4
13/07/27 23:09:47 INFO scheduler.DAGScheduler: Completed ResultTask(0, 4)
13/07/27 23:09:47 INFO local.LocalTaskSetManager: Size of task 5 is 1491 bytes
13/07/27 23:09:47 INFO local.LocalScheduler: Running 5
13/07/27 23:09:47 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:09:47 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@696
13/07/27 23:09:47 INFO storage.MemoryStore: ensureFreeSpace(69756558) called with curMem=356369972, maxMem=1358297825
13/07/27 23:09:47 INFO storage.MemoryStore: Block rdd_1_5 stored as values to memory (estimated size 66.5 MB, free 889.0 MB)
13/07/27 23:09:47 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_5 in memory on tachyon-ec2-0:36666 (size: 66.5 MB, free: 889.0 MB)
13/07/27 23:09:47 INFO storage.BlockManagerMaster: Updated info of block rdd_1_5
13/07/27 23:09:47 INFO local.LocalScheduler: Finished 5
13/07/27 23:09:47 INFO scheduler.DAGScheduler: Completed ResultTask(0, 5)
13/07/27 23:09:47 INFO local.LocalTaskSetManager: Size of task 6 is 1491 bytes
13/07/27 23:09:47 INFO local.LocalScheduler: Running 6
13/07/27 23:09:47 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:09:47 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@697
13/07/27 23:09:47 INFO storage.MemoryStore: ensureFreeSpace(71337286) called with curMem=426126530, maxMem=1358297825
13/07/27 23:09:47 INFO storage.MemoryStore: Block rdd_1_6 stored as values to memory (estimated size 68.0 MB, free 821.0 MB)
13/07/27 23:09:47 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_6 in memory on tachyon-ec2-0:36666 (size: 68.0 MB, free: 821.0 MB)
13/07/27 23:09:47 INFO storage.BlockManagerMaster: Updated info of block rdd_1_6
13/07/27 23:09:47 INFO local.LocalScheduler: Finished 6
13/07/27 23:09:47 INFO scheduler.DAGScheduler: Completed ResultTask(0, 6)
13/07/27 23:09:47 INFO local.LocalTaskSetManager: Size of task 7 is 1491 bytes
13/07/27 23:09:47 INFO local.LocalScheduler: Running 7
13/07/27 23:09:47 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:09:47 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@698
13/07/27 23:09:48 INFO storage.MemoryStore: ensureFreeSpace(71927110) called with curMem=497463816, maxMem=1358297825
13/07/27 23:09:48 INFO storage.MemoryStore: Block rdd_1_7 stored as values to memory (estimated size 68.6 MB, free 752.4 MB)
13/07/27 23:09:48 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_7 in memory on tachyon-ec2-0:36666 (size: 68.6 MB, free: 752.4 MB)
13/07/27 23:09:48 INFO storage.BlockManagerMaster: Updated info of block rdd_1_7
13/07/27 23:09:48 INFO local.LocalScheduler: Finished 7
13/07/27 23:09:48 INFO scheduler.DAGScheduler: Completed ResultTask(0, 7)
13/07/27 23:09:48 INFO local.LocalTaskSetManager: Size of task 8 is 1491 bytes
13/07/27 23:09:48 INFO local.LocalScheduler: Running 8
13/07/27 23:09:48 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:09:48 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@699
13/07/27 23:09:48 INFO storage.MemoryStore: ensureFreeSpace(68354088) called with curMem=569390926, maxMem=1358297825
13/07/27 23:09:48 INFO storage.MemoryStore: Block rdd_1_8 stored as values to memory (estimated size 65.2 MB, free 687.2 MB)
13/07/27 23:09:48 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_8 in memory on tachyon-ec2-0:36666 (size: 65.2 MB, free: 687.2 MB)
13/07/27 23:09:48 INFO storage.BlockManagerMaster: Updated info of block rdd_1_8
13/07/27 23:09:48 INFO local.LocalScheduler: Finished 8
13/07/27 23:09:48 INFO scheduler.DAGScheduler: Completed ResultTask(0, 8)
13/07/27 23:09:48 INFO local.LocalTaskSetManager: Size of task 9 is 1491 bytes
13/07/27 23:09:48 INFO local.LocalScheduler: Running 9
13/07/27 23:09:48 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:09:48 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69a
13/07/27 23:09:48 INFO storage.MemoryStore: ensureFreeSpace(72189254) called with curMem=637745014, maxMem=1358297825
13/07/27 23:09:48 INFO storage.MemoryStore: Block rdd_1_9 stored as values to memory (estimated size 68.8 MB, free 618.3 MB)
13/07/27 23:09:48 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_9 in memory on tachyon-ec2-0:36666 (size: 68.8 MB, free: 618.4 MB)
13/07/27 23:09:48 INFO storage.BlockManagerMaster: Updated info of block rdd_1_9
13/07/27 23:09:48 INFO local.LocalScheduler: Finished 9
13/07/27 23:09:48 INFO scheduler.DAGScheduler: Completed ResultTask(0, 9)
13/07/27 23:09:48 INFO local.LocalTaskSetManager: Size of task 10 is 1491 bytes
13/07/27 23:09:48 INFO local.LocalScheduler: Running 10
13/07/27 23:09:48 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:09:48 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69b
13/07/27 23:09:49 INFO storage.MemoryStore: ensureFreeSpace(69900737) called with curMem=709934268, maxMem=1358297825
13/07/27 23:09:49 INFO storage.MemoryStore: Block rdd_1_10 stored as values to memory (estimated size 66.7 MB, free 551.7 MB)
13/07/27 23:09:49 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_10 in memory on tachyon-ec2-0:36666 (size: 66.7 MB, free: 551.7 MB)
13/07/27 23:09:49 INFO storage.BlockManagerMaster: Updated info of block rdd_1_10
13/07/27 23:09:49 INFO local.LocalScheduler: Finished 10
13/07/27 23:09:49 INFO scheduler.DAGScheduler: Completed ResultTask(0, 10)
13/07/27 23:09:49 INFO local.LocalTaskSetManager: Size of task 11 is 1491 bytes
13/07/27 23:09:49 INFO local.LocalScheduler: Running 11
13/07/27 23:09:49 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:09:49 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69c
13/07/27 23:09:49 INFO storage.MemoryStore: ensureFreeSpace(71945460) called with curMem=779835005, maxMem=1358297825
13/07/27 23:09:49 INFO storage.MemoryStore: Block rdd_1_11 stored as values to memory (estimated size 68.6 MB, free 483.1 MB)
13/07/27 23:09:49 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_11 in memory on tachyon-ec2-0:36666 (size: 68.6 MB, free: 483.1 MB)
13/07/27 23:09:49 INFO storage.BlockManagerMaster: Updated info of block rdd_1_11
13/07/27 23:09:49 INFO local.LocalScheduler: Finished 11
13/07/27 23:09:49 INFO scheduler.DAGScheduler: Completed ResultTask(0, 11)
13/07/27 23:09:49 INFO local.LocalTaskSetManager: Size of task 12 is 1491 bytes
13/07/27 23:09:49 INFO local.LocalScheduler: Running 12
13/07/27 23:09:49 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:09:49 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69d
13/07/27 23:09:49 INFO storage.MemoryStore: ensureFreeSpace(71937596) called with curMem=851780465, maxMem=1358297825
13/07/27 23:09:49 INFO storage.MemoryStore: Block rdd_1_12 stored as values to memory (estimated size 68.6 MB, free 414.4 MB)
13/07/27 23:09:49 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_12 in memory on tachyon-ec2-0:36666 (size: 68.6 MB, free: 414.5 MB)
13/07/27 23:09:49 INFO storage.BlockManagerMaster: Updated info of block rdd_1_12
13/07/27 23:09:49 INFO local.LocalScheduler: Finished 12
13/07/27 23:09:49 INFO scheduler.DAGScheduler: Completed ResultTask(0, 12)
13/07/27 23:09:49 INFO local.LocalTaskSetManager: Size of task 13 is 1491 bytes
13/07/27 23:09:49 INFO local.LocalScheduler: Running 13
13/07/27 23:09:49 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:09:49 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69e
13/07/27 23:09:50 INFO storage.MemoryStore: ensureFreeSpace(72915393) called with curMem=923718061, maxMem=1358297825
13/07/27 23:09:50 INFO storage.MemoryStore: Block rdd_1_13 stored as values to memory (estimated size 69.5 MB, free 344.9 MB)
13/07/27 23:09:50 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_13 in memory on tachyon-ec2-0:36666 (size: 69.5 MB, free: 345.0 MB)
13/07/27 23:09:50 INFO storage.BlockManagerMaster: Updated info of block rdd_1_13
13/07/27 23:09:50 INFO local.LocalScheduler: Finished 13
13/07/27 23:09:50 INFO scheduler.DAGScheduler: Completed ResultTask(0, 13)
13/07/27 23:09:50 INFO local.LocalTaskSetManager: Size of task 14 is 1491 bytes
13/07/27 23:09:50 INFO local.LocalScheduler: Running 14
13/07/27 23:09:50 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:09:50 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69f
13/07/27 23:09:50 INFO storage.MemoryStore: ensureFreeSpace(71974296) called with curMem=996633454, maxMem=1358297825
13/07/27 23:09:50 INFO storage.MemoryStore: Block rdd_1_14 stored as values to memory (estimated size 68.6 MB, free 276.3 MB)
13/07/27 23:09:50 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_14 in memory on tachyon-ec2-0:36666 (size: 68.6 MB, free: 276.3 MB)
13/07/27 23:09:50 INFO storage.BlockManagerMaster: Updated info of block rdd_1_14
13/07/27 23:09:50 INFO local.LocalScheduler: Finished 14
13/07/27 23:09:50 INFO scheduler.DAGScheduler: Completed ResultTask(0, 14)
13/07/27 23:09:50 INFO local.LocalTaskSetManager: Size of task 15 is 1491 bytes
13/07/27 23:09:50 INFO local.LocalScheduler: Running 15
13/07/27 23:09:50 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:09:50 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a0
13/07/27 23:09:51 INFO storage.MemoryStore: ensureFreeSpace(71051549) called with curMem=1068607750, maxMem=1358297825
13/07/27 23:09:51 INFO storage.MemoryStore: Block rdd_1_15 stored as values to memory (estimated size 67.8 MB, free 208.5 MB)
13/07/27 23:09:51 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_15 in memory on tachyon-ec2-0:36666 (size: 67.8 MB, free: 208.6 MB)
13/07/27 23:09:51 INFO storage.BlockManagerMaster: Updated info of block rdd_1_15
13/07/27 23:09:51 INFO local.LocalScheduler: Finished 15
13/07/27 23:09:51 INFO scheduler.DAGScheduler: Completed ResultTask(0, 15)
13/07/27 23:09:51 INFO local.LocalTaskSetManager: Size of task 16 is 1491 bytes
13/07/27 23:09:51 INFO local.LocalScheduler: Running 16
13/07/27 23:09:51 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:09:51 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a1
13/07/27 23:09:51 INFO storage.MemoryStore: ensureFreeSpace(71565352) called with curMem=1139659299, maxMem=1358297825
13/07/27 23:09:51 INFO storage.MemoryStore: Block rdd_1_16 stored as values to memory (estimated size 68.3 MB, free 140.3 MB)
13/07/27 23:09:51 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_16 in memory on tachyon-ec2-0:36666 (size: 68.3 MB, free: 140.3 MB)
13/07/27 23:09:51 INFO storage.BlockManagerMaster: Updated info of block rdd_1_16
13/07/27 23:09:51 INFO local.LocalScheduler: Finished 16
13/07/27 23:09:51 INFO scheduler.DAGScheduler: Completed ResultTask(0, 16)
13/07/27 23:09:51 INFO local.LocalTaskSetManager: Size of task 17 is 1491 bytes
13/07/27 23:09:51 INFO local.LocalScheduler: Running 17
13/07/27 23:09:51 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:09:51 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a2
13/07/27 23:09:52 INFO storage.MemoryStore: ensureFreeSpace(72682085) called with curMem=1211224651, maxMem=1358297825
13/07/27 23:09:52 INFO storage.MemoryStore: Block rdd_1_17 stored as values to memory (estimated size 69.3 MB, free 70.9 MB)
13/07/27 23:09:52 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_17 in memory on tachyon-ec2-0:36666 (size: 69.3 MB, free: 71.0 MB)
13/07/27 23:09:52 INFO storage.BlockManagerMaster: Updated info of block rdd_1_17
13/07/27 23:09:52 INFO local.LocalScheduler: Finished 17
13/07/27 23:09:52 INFO scheduler.DAGScheduler: Completed ResultTask(0, 17)
13/07/27 23:09:52 INFO local.LocalTaskSetManager: Size of task 18 is 1491 bytes
13/07/27 23:09:52 INFO local.LocalScheduler: Running 18
13/07/27 23:09:52 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:09:52 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a3
13/07/27 23:09:52 INFO storage.MemoryStore: ensureFreeSpace(30062713) called with curMem=1283906736, maxMem=1358297825
13/07/27 23:09:52 INFO storage.MemoryStore: Block rdd_1_18 stored as values to memory (estimated size 28.7 MB, free 42.3 MB)
13/07/27 23:09:52 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_18 in memory on tachyon-ec2-0:36666 (size: 28.7 MB, free: 42.3 MB)
13/07/27 23:09:52 INFO storage.BlockManagerMaster: Updated info of block rdd_1_18
13/07/27 23:09:52 INFO local.LocalScheduler: Finished 18
13/07/27 23:09:52 INFO scheduler.DAGScheduler: Completed ResultTask(0, 18)
13/07/27 23:09:52 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:09:52 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 6.747 s
13/07/27 23:09:52 INFO spark.SparkContext: Job finished: count at <console>:15, took 6.796790379 s
res0: Long = 500094

scala> 13/07/27 23:09:52 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:09:52 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:09:52 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:09:52 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:09:52 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:09:52 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:09:52 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:09:52 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 1

spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1 as mode POSIX_FADV_DONTNEED
offset: 0
length: 525
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:09:54 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:09:54 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:45586
Creating SparkContext...
13/07/27 23:10:04 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:10:04 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:10:04 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:10:04 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231004-2de6
13/07/27 23:10:04 INFO network.ConnectionManager: Bound socket to port 48738 with id = ConnectionManagerId(tachyon-ec2-0,48738)
13/07/27 23:10:04 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:10:04 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:48738 with 1295.4 MB RAM
13/07/27 23:10:04 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:10:04 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:10:04 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59856
13/07/27 23:10:04 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:59856
13/07/27 23:10:04 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:10:04 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-b250d414-36ed-4b62-8f6b-6e559b03ff29
13/07/27 23:10:04 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:10:04 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:33940
13/07/27 23:10:04 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:10:04 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:10:04 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:10:04 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:10:04 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:10:04 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:10:04 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:10:04 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:10:04 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:10:04 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:10:04 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1").cache()
13/07/27 23:10:05 INFO storage.MemoryStore: ensureFreeSpace(58391) called with curMem=0, maxMem=1358297825
13/07/27 23:10:05 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:10:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:10:06 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:10:06 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:10:06 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:10:06 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:10:06 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:10:06 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:10:06 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:10:06 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:10:06 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:10:06 INFO local.LocalTaskSetManager: Size of task 0 is 1486 bytes
13/07/27 23:10:06 INFO local.LocalScheduler: Running 0
13/07/27 23:10:06 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:10:06 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:10:06 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58391, maxMem=1358297825
13/07/27 23:10:06 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/27 23:10:06 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:48738 (size: 1192.0 B, free: 1295.4 MB)
13/07/27 23:10:06 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:10:06 INFO local.LocalScheduler: Finished 0
13/07/27 23:10:06 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:10:06 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:10:06 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.219 s
13/07/27 23:10:06 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.263217149 s
res0: Long = 1

scala> 13/07/27 23:10:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:10:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:10:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:10:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:10:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:10:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:10:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:10:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100 as mode POSIX_FADV_DONTNEED
offset: 0
length: 55735
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:10:09 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:10:09 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:51670
Creating SparkContext...
13/07/27 23:10:18 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:10:18 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:10:18 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:10:18 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231018-18e8
13/07/27 23:10:18 INFO network.ConnectionManager: Bound socket to port 39049 with id = ConnectionManagerId(tachyon-ec2-0,39049)
13/07/27 23:10:18 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:10:18 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:39049 with 1295.4 MB RAM
13/07/27 23:10:18 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:10:18 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:10:18 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53136
13/07/27 23:10:18 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:53136
13/07/27 23:10:18 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:10:18 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-648e26c2-fcab-4845-b4b5-70ea3e3527d2
13/07/27 23:10:18 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:10:18 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:56401
13/07/27 23:10:18 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:10:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:10:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:10:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:10:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:10:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:10:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:10:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:10:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:10:18 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:10:18 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100").cache()
13/07/27 23:10:20 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:10:20 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:10:20 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:10:20 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:10:20 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:10:20 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:10:20 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:10:20 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:10:20 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:10:20 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:10:20 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:10:20 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:10:20 INFO local.LocalTaskSetManager: Size of task 0 is 1488 bytes
13/07/27 23:10:20 INFO local.LocalScheduler: Running 0
13/07/27 23:10:20 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:10:20 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:10:20 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58399, maxMem=1358297825
13/07/27 23:10:20 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/27 23:10:20 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:39049 (size: 113.4 KB, free: 1295.3 MB)
13/07/27 23:10:20 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:10:20 INFO local.LocalScheduler: Finished 0
13/07/27 23:10:20 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:10:20 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:10:20 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.220 s
13/07/27 23:10:20 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.264927939 s
res0: Long = 100

scala> 13/07/27 23:10:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:10:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:10:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:10:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:10:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:10:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:10:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:10:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 776400
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:10:23 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:10:23 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:54207
Creating SparkContext...
13/07/27 23:10:32 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:10:32 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:10:32 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:10:32 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231032-8205
13/07/27 23:10:32 INFO network.ConnectionManager: Bound socket to port 45710 with id = ConnectionManagerId(tachyon-ec2-0,45710)
13/07/27 23:10:32 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:10:32 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:45710 with 1295.4 MB RAM
13/07/27 23:10:32 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:10:32 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:10:32 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37807
13/07/27 23:10:32 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:37807
13/07/27 23:10:32 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:10:32 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-a4d9ede3-c111-48fe-8ce7-63d9fa0443fb
13/07/27 23:10:32 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:10:32 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:56528
13/07/27 23:10:33 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:10:33 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:10:33 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:10:33 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:10:33 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:10:33 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:10:33 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:10:33 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:10:33 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:10:33 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:10:33 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1000").cache()
13/07/27 23:10:34 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:10:34 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:10:34 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:10:34 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:10:34 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:10:34 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:10:34 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:10:34 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:10:34 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:10:34 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:10:34 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:10:34 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:10:34 INFO local.LocalTaskSetManager: Size of task 0 is 1489 bytes
13/07/27 23:10:34 INFO local.LocalScheduler: Running 0
13/07/27 23:10:34 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:10:34 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:10:35 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58399, maxMem=1358297825
13/07/27 23:10:35 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/27 23:10:35 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:45710 (size: 1580.2 KB, free: 1293.8 MB)
13/07/27 23:10:35 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:10:35 INFO local.LocalScheduler: Finished 0
13/07/27 23:10:35 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:10:35 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:10:35 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.260 s
13/07/27 23:10:35 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.303897144 s
res0: Long = 1000

scala> 13/07/27 23:10:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:10:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:10:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:10:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:10:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:10:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:10:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:10:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.10000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 12330369
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:10:37 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:10:37 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50972
Creating SparkContext...
13/07/27 23:10:46 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:10:47 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:10:47 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:10:47 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231047-27e8
13/07/27 23:10:47 INFO network.ConnectionManager: Bound socket to port 59635 with id = ConnectionManagerId(tachyon-ec2-0,59635)
13/07/27 23:10:47 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:10:47 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:59635 with 1295.4 MB RAM
13/07/27 23:10:47 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:10:47 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:10:47 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:52905
13/07/27 23:10:47 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:52905
13/07/27 23:10:47 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:10:47 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-578dc884-6e97-4f0c-87c7-4824fa559119
13/07/27 23:10:47 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:10:47 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:45169
13/07/27 23:10:47 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:10:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:10:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:10:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:10:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:10:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:10:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:10:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:10:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:10:47 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:10:47 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.10000").cache()
13/07/27 23:10:48 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:10:48 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:10:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:10:49 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:10:49 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:10:49 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:10:49 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:10:49 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:10:49 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:10:49 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:10:49 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:10:49 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:10:49 INFO local.LocalTaskSetManager: Size of task 0 is 1490 bytes
13/07/27 23:10:49 INFO local.LocalScheduler: Running 0
13/07/27 23:10:49 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:10:49 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:10:49 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58399, maxMem=1358297825
13/07/27 23:10:49 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/27 23:10:49 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:59635 (size: 25.0 MB, free: 1270.4 MB)
13/07/27 23:10:49 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:10:49 INFO local.LocalScheduler: Finished 0
13/07/27 23:10:49 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:10:49 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:10:49 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.426 s
13/07/27 23:10:49 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.470288803 s
res0: Long = 10000

scala> 13/07/27 23:10:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:10:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:10:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:10:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:10:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:10:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:10:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:10:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 125141299
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:10:52 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:10:52 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:47291
Creating SparkContext...
13/07/27 23:11:01 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:11:01 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:11:01 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:11:01 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231101-ee7e
13/07/27 23:11:01 INFO network.ConnectionManager: Bound socket to port 42532 with id = ConnectionManagerId(tachyon-ec2-0,42532)
13/07/27 23:11:01 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:11:01 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:42532 with 1295.4 MB RAM
13/07/27 23:11:01 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:11:01 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:11:01 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59313
13/07/27 23:11:01 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:59313
13/07/27 23:11:01 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:11:01 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-a9b8c7bd-2a22-410c-b789-c529706f5abf
13/07/27 23:11:01 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:11:01 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:52387
13/07/27 23:11:01 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:11:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:11:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:11:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:11:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:11:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:11:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:11:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:11:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:11:01 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:11:01 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100000").cache()
13/07/27 23:11:03 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:11:03 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:11:03 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:11:03 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:11:03 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:11:03 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:11:03 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:11:03 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:11:03 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:11:03 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:11:03 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:11:03 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:11:03 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:11:03 INFO local.LocalScheduler: Running 0
13/07/27 23:11:03 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:11:03 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:11:04 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:11:04 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:11:04 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:42532 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:11:04 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:11:04 INFO local.LocalScheduler: Finished 0
13/07/27 23:11:04 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:11:04 INFO local.LocalScheduler: Running 1
13/07/27 23:11:04 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:11:04 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:11:04 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:11:04 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:11:04 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:11:04 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:42532 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:11:04 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:11:04 INFO local.LocalScheduler: Finished 1
13/07/27 23:11:04 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:11:04 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:11:04 INFO local.LocalScheduler: Running 2
13/07/27 23:11:04 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:11:04 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:11:04 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:11:04 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:11:04 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:42532 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:11:04 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:11:04 INFO local.LocalScheduler: Finished 2
13/07/27 23:11:04 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:11:04 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:11:04 INFO local.LocalScheduler: Running 3
13/07/27 23:11:04 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:11:04 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:11:05 INFO storage.MemoryStore: ensureFreeSpace(52232232) called with curMem=211087067, maxMem=1358297825
13/07/27 23:11:05 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 49.8 MB, free 1044.3 MB)
13/07/27 23:11:05 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:42532 (size: 49.8 MB, free: 1044.3 MB)
13/07/27 23:11:05 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:11:05 INFO local.LocalScheduler: Finished 3
13/07/27 23:11:05 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:11:05 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:11:05 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.521 s
13/07/27 23:11:05 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.567867041 s
res0: Long = 100002

scala> 13/07/27 23:11:05 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:11:05 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:11:05 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:11:05 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:11:05 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:11:05 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:11:05 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:11:05 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.500000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 618418417
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:11:07 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:11:07 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:32968
Creating SparkContext...
13/07/27 23:11:16 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:11:17 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:11:17 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:11:17 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231117-884e
13/07/27 23:11:17 INFO network.ConnectionManager: Bound socket to port 50339 with id = ConnectionManagerId(tachyon-ec2-0,50339)
13/07/27 23:11:17 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:11:17 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:50339 with 1295.4 MB RAM
13/07/27 23:11:17 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:11:17 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:11:17 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59271
13/07/27 23:11:17 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:59271
13/07/27 23:11:17 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:11:17 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-1c2a5474-e96a-4150-98df-092561dc81fa
13/07/27 23:11:17 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:11:17 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:44136
13/07/27 23:11:17 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:11:17 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:11:17 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:11:17 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:11:17 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:11:17 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:11:17 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:11:17 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:11:17 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:11:17 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:11:17 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.500000").cache()
13/07/27 23:11:18 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:11:18 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:11:19 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:11:19 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:11:19 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:11:19 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:11:19 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:11:19 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:11:19 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:11:19 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:11:19 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:11:19 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:11:19 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:11:19 INFO local.LocalScheduler: Running 0
13/07/27 23:11:19 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:11:19 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:11:19 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:11:19 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:11:19 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:50339 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:11:19 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:11:19 INFO local.LocalScheduler: Finished 0
13/07/27 23:11:19 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:11:19 INFO local.LocalScheduler: Running 1
13/07/27 23:11:19 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:11:19 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:11:19 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:11:19 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:11:19 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:11:19 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:50339 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:11:19 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:11:19 INFO local.LocalScheduler: Finished 1
13/07/27 23:11:19 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:11:19 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:11:19 INFO local.LocalScheduler: Running 2
13/07/27 23:11:19 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:11:19 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:11:20 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:11:20 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:11:20 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:50339 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:11:20 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:11:20 INFO local.LocalScheduler: Finished 2
13/07/27 23:11:20 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:11:20 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:11:20 INFO local.LocalScheduler: Running 3
13/07/27 23:11:20 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:11:20 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:11:20 INFO storage.MemoryStore: ensureFreeSpace(73224723) called with curMem=211087067, maxMem=1358297825
13/07/27 23:11:20 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 69.8 MB, free 1024.2 MB)
13/07/27 23:11:20 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:50339 (size: 69.8 MB, free: 1024.3 MB)
13/07/27 23:11:20 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:11:20 INFO local.LocalScheduler: Finished 3
13/07/27 23:11:20 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:11:20 INFO local.LocalTaskSetManager: Size of task 4 is 1491 bytes
13/07/27 23:11:20 INFO local.LocalScheduler: Running 4
13/07/27 23:11:20 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:11:20 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@695
13/07/27 23:11:20 INFO storage.MemoryStore: ensureFreeSpace(72058182) called with curMem=284311790, maxMem=1358297825
13/07/27 23:11:20 INFO storage.MemoryStore: Block rdd_1_4 stored as values to memory (estimated size 68.7 MB, free 955.5 MB)
13/07/27 23:11:20 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_4 in memory on tachyon-ec2-0:50339 (size: 68.7 MB, free: 955.6 MB)
13/07/27 23:11:20 INFO storage.BlockManagerMaster: Updated info of block rdd_1_4
13/07/27 23:11:20 INFO local.LocalScheduler: Finished 4
13/07/27 23:11:20 INFO scheduler.DAGScheduler: Completed ResultTask(0, 4)
13/07/27 23:11:20 INFO local.LocalTaskSetManager: Size of task 5 is 1491 bytes
13/07/27 23:11:20 INFO local.LocalScheduler: Running 5
13/07/27 23:11:20 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:11:20 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@696
13/07/27 23:11:21 INFO storage.MemoryStore: ensureFreeSpace(69756558) called with curMem=356369972, maxMem=1358297825
13/07/27 23:11:21 INFO storage.MemoryStore: Block rdd_1_5 stored as values to memory (estimated size 66.5 MB, free 889.0 MB)
13/07/27 23:11:21 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_5 in memory on tachyon-ec2-0:50339 (size: 66.5 MB, free: 889.0 MB)
13/07/27 23:11:21 INFO storage.BlockManagerMaster: Updated info of block rdd_1_5
13/07/27 23:11:21 INFO local.LocalScheduler: Finished 5
13/07/27 23:11:21 INFO scheduler.DAGScheduler: Completed ResultTask(0, 5)
13/07/27 23:11:21 INFO local.LocalTaskSetManager: Size of task 6 is 1491 bytes
13/07/27 23:11:21 INFO local.LocalScheduler: Running 6
13/07/27 23:11:21 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:11:21 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@697
13/07/27 23:11:21 INFO storage.MemoryStore: ensureFreeSpace(71337286) called with curMem=426126530, maxMem=1358297825
13/07/27 23:11:21 INFO storage.MemoryStore: Block rdd_1_6 stored as values to memory (estimated size 68.0 MB, free 821.0 MB)
13/07/27 23:11:21 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_6 in memory on tachyon-ec2-0:50339 (size: 68.0 MB, free: 821.0 MB)
13/07/27 23:11:21 INFO storage.BlockManagerMaster: Updated info of block rdd_1_6
13/07/27 23:11:21 INFO local.LocalScheduler: Finished 6
13/07/27 23:11:21 INFO scheduler.DAGScheduler: Completed ResultTask(0, 6)
13/07/27 23:11:21 INFO local.LocalTaskSetManager: Size of task 7 is 1491 bytes
13/07/27 23:11:21 INFO local.LocalScheduler: Running 7
13/07/27 23:11:21 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:11:21 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@698
13/07/27 23:11:21 INFO storage.MemoryStore: ensureFreeSpace(71927110) called with curMem=497463816, maxMem=1358297825
13/07/27 23:11:21 INFO storage.MemoryStore: Block rdd_1_7 stored as values to memory (estimated size 68.6 MB, free 752.4 MB)
13/07/27 23:11:21 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_7 in memory on tachyon-ec2-0:50339 (size: 68.6 MB, free: 752.4 MB)
13/07/27 23:11:21 INFO storage.BlockManagerMaster: Updated info of block rdd_1_7
13/07/27 23:11:21 INFO local.LocalScheduler: Finished 7
13/07/27 23:11:21 INFO scheduler.DAGScheduler: Completed ResultTask(0, 7)
13/07/27 23:11:21 INFO local.LocalTaskSetManager: Size of task 8 is 1491 bytes
13/07/27 23:11:21 INFO local.LocalScheduler: Running 8
13/07/27 23:11:21 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:11:21 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@699
13/07/27 23:11:22 INFO storage.MemoryStore: ensureFreeSpace(68354088) called with curMem=569390926, maxMem=1358297825
13/07/27 23:11:22 INFO storage.MemoryStore: Block rdd_1_8 stored as values to memory (estimated size 65.2 MB, free 687.2 MB)
13/07/27 23:11:22 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_8 in memory on tachyon-ec2-0:50339 (size: 65.2 MB, free: 687.2 MB)
13/07/27 23:11:22 INFO storage.BlockManagerMaster: Updated info of block rdd_1_8
13/07/27 23:11:22 INFO local.LocalScheduler: Finished 8
13/07/27 23:11:22 INFO scheduler.DAGScheduler: Completed ResultTask(0, 8)
13/07/27 23:11:22 INFO local.LocalTaskSetManager: Size of task 9 is 1491 bytes
13/07/27 23:11:22 INFO local.LocalScheduler: Running 9
13/07/27 23:11:22 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:11:22 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69a
13/07/27 23:11:22 INFO storage.MemoryStore: ensureFreeSpace(72189254) called with curMem=637745014, maxMem=1358297825
13/07/27 23:11:22 INFO storage.MemoryStore: Block rdd_1_9 stored as values to memory (estimated size 68.8 MB, free 618.3 MB)
13/07/27 23:11:22 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_9 in memory on tachyon-ec2-0:50339 (size: 68.8 MB, free: 618.4 MB)
13/07/27 23:11:22 INFO storage.BlockManagerMaster: Updated info of block rdd_1_9
13/07/27 23:11:22 INFO local.LocalScheduler: Finished 9
13/07/27 23:11:22 INFO scheduler.DAGScheduler: Completed ResultTask(0, 9)
13/07/27 23:11:22 INFO local.LocalTaskSetManager: Size of task 10 is 1491 bytes
13/07/27 23:11:22 INFO local.LocalScheduler: Running 10
13/07/27 23:11:22 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:11:22 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69b
13/07/27 23:11:22 INFO storage.MemoryStore: ensureFreeSpace(69900737) called with curMem=709934268, maxMem=1358297825
13/07/27 23:11:22 INFO storage.MemoryStore: Block rdd_1_10 stored as values to memory (estimated size 66.7 MB, free 551.7 MB)
13/07/27 23:11:22 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_10 in memory on tachyon-ec2-0:50339 (size: 66.7 MB, free: 551.7 MB)
13/07/27 23:11:22 INFO storage.BlockManagerMaster: Updated info of block rdd_1_10
13/07/27 23:11:22 INFO local.LocalScheduler: Finished 10
13/07/27 23:11:22 INFO scheduler.DAGScheduler: Completed ResultTask(0, 10)
13/07/27 23:11:22 INFO local.LocalTaskSetManager: Size of task 11 is 1491 bytes
13/07/27 23:11:22 INFO local.LocalScheduler: Running 11
13/07/27 23:11:22 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:11:22 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69c
13/07/27 23:11:22 INFO storage.MemoryStore: ensureFreeSpace(71945460) called with curMem=779835005, maxMem=1358297825
13/07/27 23:11:22 INFO storage.MemoryStore: Block rdd_1_11 stored as values to memory (estimated size 68.6 MB, free 483.1 MB)
13/07/27 23:11:22 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_11 in memory on tachyon-ec2-0:50339 (size: 68.6 MB, free: 483.1 MB)
13/07/27 23:11:22 INFO storage.BlockManagerMaster: Updated info of block rdd_1_11
13/07/27 23:11:22 INFO local.LocalScheduler: Finished 11
13/07/27 23:11:23 INFO scheduler.DAGScheduler: Completed ResultTask(0, 11)
13/07/27 23:11:23 INFO local.LocalTaskSetManager: Size of task 12 is 1491 bytes
13/07/27 23:11:23 INFO local.LocalScheduler: Running 12
13/07/27 23:11:23 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:11:23 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69d
13/07/27 23:11:23 INFO storage.MemoryStore: ensureFreeSpace(71937596) called with curMem=851780465, maxMem=1358297825
13/07/27 23:11:23 INFO storage.MemoryStore: Block rdd_1_12 stored as values to memory (estimated size 68.6 MB, free 414.4 MB)
13/07/27 23:11:23 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_12 in memory on tachyon-ec2-0:50339 (size: 68.6 MB, free: 414.5 MB)
13/07/27 23:11:23 INFO storage.BlockManagerMaster: Updated info of block rdd_1_12
13/07/27 23:11:23 INFO local.LocalScheduler: Finished 12
13/07/27 23:11:23 INFO scheduler.DAGScheduler: Completed ResultTask(0, 12)
13/07/27 23:11:23 INFO local.LocalTaskSetManager: Size of task 13 is 1491 bytes
13/07/27 23:11:23 INFO local.LocalScheduler: Running 13
13/07/27 23:11:23 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:11:23 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69e
13/07/27 23:11:24 INFO storage.MemoryStore: ensureFreeSpace(72915393) called with curMem=923718061, maxMem=1358297825
13/07/27 23:11:24 INFO storage.MemoryStore: Block rdd_1_13 stored as values to memory (estimated size 69.5 MB, free 344.9 MB)
13/07/27 23:11:24 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_13 in memory on tachyon-ec2-0:50339 (size: 69.5 MB, free: 345.0 MB)
13/07/27 23:11:24 INFO storage.BlockManagerMaster: Updated info of block rdd_1_13
13/07/27 23:11:24 INFO local.LocalScheduler: Finished 13
13/07/27 23:11:24 INFO scheduler.DAGScheduler: Completed ResultTask(0, 13)
13/07/27 23:11:24 INFO local.LocalTaskSetManager: Size of task 14 is 1491 bytes
13/07/27 23:11:24 INFO local.LocalScheduler: Running 14
13/07/27 23:11:24 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:11:24 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69f
13/07/27 23:11:24 INFO storage.MemoryStore: ensureFreeSpace(71974296) called with curMem=996633454, maxMem=1358297825
13/07/27 23:11:24 INFO storage.MemoryStore: Block rdd_1_14 stored as values to memory (estimated size 68.6 MB, free 276.3 MB)
13/07/27 23:11:24 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_14 in memory on tachyon-ec2-0:50339 (size: 68.6 MB, free: 276.3 MB)
13/07/27 23:11:24 INFO storage.BlockManagerMaster: Updated info of block rdd_1_14
13/07/27 23:11:24 INFO local.LocalScheduler: Finished 14
13/07/27 23:11:24 INFO scheduler.DAGScheduler: Completed ResultTask(0, 14)
13/07/27 23:11:24 INFO local.LocalTaskSetManager: Size of task 15 is 1491 bytes
13/07/27 23:11:24 INFO local.LocalScheduler: Running 15
13/07/27 23:11:24 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:11:24 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a0
13/07/27 23:11:24 INFO storage.MemoryStore: ensureFreeSpace(71051549) called with curMem=1068607750, maxMem=1358297825
13/07/27 23:11:24 INFO storage.MemoryStore: Block rdd_1_15 stored as values to memory (estimated size 67.8 MB, free 208.5 MB)
13/07/27 23:11:24 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_15 in memory on tachyon-ec2-0:50339 (size: 67.8 MB, free: 208.6 MB)
13/07/27 23:11:24 INFO storage.BlockManagerMaster: Updated info of block rdd_1_15
13/07/27 23:11:24 INFO local.LocalScheduler: Finished 15
13/07/27 23:11:24 INFO scheduler.DAGScheduler: Completed ResultTask(0, 15)
13/07/27 23:11:24 INFO local.LocalTaskSetManager: Size of task 16 is 1491 bytes
13/07/27 23:11:24 INFO local.LocalScheduler: Running 16
13/07/27 23:11:24 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:11:24 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a1
13/07/27 23:11:24 INFO storage.MemoryStore: ensureFreeSpace(71565352) called with curMem=1139659299, maxMem=1358297825
13/07/27 23:11:24 INFO storage.MemoryStore: Block rdd_1_16 stored as values to memory (estimated size 68.3 MB, free 140.3 MB)
13/07/27 23:11:24 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_16 in memory on tachyon-ec2-0:50339 (size: 68.3 MB, free: 140.3 MB)
13/07/27 23:11:24 INFO storage.BlockManagerMaster: Updated info of block rdd_1_16
13/07/27 23:11:25 INFO local.LocalScheduler: Finished 16
13/07/27 23:11:25 INFO scheduler.DAGScheduler: Completed ResultTask(0, 16)
13/07/27 23:11:25 INFO local.LocalTaskSetManager: Size of task 17 is 1491 bytes
13/07/27 23:11:25 INFO local.LocalScheduler: Running 17
13/07/27 23:11:25 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:11:25 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a2
13/07/27 23:11:25 INFO storage.MemoryStore: ensureFreeSpace(72682085) called with curMem=1211224651, maxMem=1358297825
13/07/27 23:11:25 INFO storage.MemoryStore: Block rdd_1_17 stored as values to memory (estimated size 69.3 MB, free 70.9 MB)
13/07/27 23:11:25 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_17 in memory on tachyon-ec2-0:50339 (size: 69.3 MB, free: 71.0 MB)
13/07/27 23:11:25 INFO storage.BlockManagerMaster: Updated info of block rdd_1_17
13/07/27 23:11:25 INFO local.LocalScheduler: Finished 17
13/07/27 23:11:25 INFO scheduler.DAGScheduler: Completed ResultTask(0, 17)
13/07/27 23:11:25 INFO local.LocalTaskSetManager: Size of task 18 is 1491 bytes
13/07/27 23:11:25 INFO local.LocalScheduler: Running 18
13/07/27 23:11:25 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:11:25 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a3
13/07/27 23:11:25 INFO storage.MemoryStore: ensureFreeSpace(30062713) called with curMem=1283906736, maxMem=1358297825
13/07/27 23:11:25 INFO storage.MemoryStore: Block rdd_1_18 stored as values to memory (estimated size 28.7 MB, free 42.3 MB)
13/07/27 23:11:25 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_18 in memory on tachyon-ec2-0:50339 (size: 28.7 MB, free: 42.3 MB)
13/07/27 23:11:25 INFO storage.BlockManagerMaster: Updated info of block rdd_1_18
13/07/27 23:11:25 INFO local.LocalScheduler: Finished 18
13/07/27 23:11:25 INFO scheduler.DAGScheduler: Completed ResultTask(0, 18)
13/07/27 23:11:25 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:11:25 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 6.734 s
13/07/27 23:11:25 INFO spark.SparkContext: Job finished: count at <console>:15, took 6.785478556 s
res0: Long = 500094

scala> 13/07/27 23:11:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:11:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:11:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:11:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:11:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:11:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:11:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:11:25 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 2

spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1 as mode POSIX_FADV_DONTNEED
offset: 0
length: 525
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:11:28 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:11:28 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53386
Creating SparkContext...
13/07/27 23:11:37 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:11:38 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:11:38 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:11:38 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231138-8d65
13/07/27 23:11:38 INFO network.ConnectionManager: Bound socket to port 40216 with id = ConnectionManagerId(tachyon-ec2-0,40216)
13/07/27 23:11:38 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:11:38 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:40216 with 1295.4 MB RAM
13/07/27 23:11:38 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:11:38 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:11:38 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:51815
13/07/27 23:11:38 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:51815
13/07/27 23:11:38 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:11:38 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-7c4bfb99-a77e-4e94-9ab9-12a941b40db8
13/07/27 23:11:38 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:11:38 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:58898
13/07/27 23:11:38 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:11:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:11:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:11:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:11:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:11:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:11:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:11:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:11:38 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:11:38 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:11:38 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1").cache()
13/07/27 23:11:39 INFO storage.MemoryStore: ensureFreeSpace(58391) called with curMem=0, maxMem=1358297825
13/07/27 23:11:39 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:11:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:11:39 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:11:39 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:11:39 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:11:39 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:11:39 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:11:39 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:11:39 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:11:39 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:11:39 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:11:40 INFO local.LocalTaskSetManager: Size of task 0 is 1486 bytes
13/07/27 23:11:40 INFO local.LocalScheduler: Running 0
13/07/27 23:11:40 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:11:40 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:11:40 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58391, maxMem=1358297825
13/07/27 23:11:40 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/27 23:11:40 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:40216 (size: 1192.0 B, free: 1295.4 MB)
13/07/27 23:11:40 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:11:40 INFO local.LocalScheduler: Finished 0
13/07/27 23:11:40 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:11:40 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:11:40 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.214 s
13/07/27 23:11:40 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.260047174 s
res0: Long = 1

scala> 13/07/27 23:11:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:11:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:11:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:11:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:11:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:11:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:11:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:11:40 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100 as mode POSIX_FADV_DONTNEED
offset: 0
length: 55735
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:11:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:11:42 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:48771
Creating SparkContext...
13/07/27 23:11:51 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:11:52 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:11:52 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:11:52 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231152-0227
13/07/27 23:11:52 INFO network.ConnectionManager: Bound socket to port 50440 with id = ConnectionManagerId(tachyon-ec2-0,50440)
13/07/27 23:11:52 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:11:52 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:50440 with 1295.4 MB RAM
13/07/27 23:11:52 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:11:52 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:11:52 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:45418
13/07/27 23:11:52 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:45418
13/07/27 23:11:52 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:11:52 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-7bb243b0-c8b6-4bd9-ae52-2c325a622ffc
13/07/27 23:11:52 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:11:52 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55166
13/07/27 23:11:52 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:11:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:11:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:11:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:11:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:11:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:11:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:11:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:11:52 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:11:52 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:11:52 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100").cache()
13/07/27 23:11:53 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:11:53 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:11:54 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:11:54 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:11:54 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:11:54 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:11:54 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:11:54 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:11:54 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:11:54 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:11:54 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:11:54 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:11:54 INFO local.LocalTaskSetManager: Size of task 0 is 1488 bytes
13/07/27 23:11:54 INFO local.LocalScheduler: Running 0
13/07/27 23:11:54 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:11:54 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:11:54 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58399, maxMem=1358297825
13/07/27 23:11:54 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/27 23:11:54 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:50440 (size: 113.4 KB, free: 1295.3 MB)
13/07/27 23:11:54 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:11:54 INFO local.LocalScheduler: Finished 0
13/07/27 23:11:54 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:11:54 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:11:54 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.211 s
13/07/27 23:11:54 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.255491085 s
res0: Long = 100

scala> 13/07/27 23:11:54 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:11:54 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:11:54 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:11:54 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:11:54 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:11:54 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:11:54 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:11:54 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 776400
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:11:56 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:11:56 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60337
Creating SparkContext...
13/07/27 23:12:06 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:12:06 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:12:06 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:12:06 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231206-6d49
13/07/27 23:12:06 INFO network.ConnectionManager: Bound socket to port 40010 with id = ConnectionManagerId(tachyon-ec2-0,40010)
13/07/27 23:12:06 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:12:06 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:40010 with 1295.4 MB RAM
13/07/27 23:12:06 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:12:06 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:12:06 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:34466
13/07/27 23:12:06 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:34466
13/07/27 23:12:06 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:12:06 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-08e81c81-4ff6-4bee-959e-67a6e0bfa668
13/07/27 23:12:06 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:12:06 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:57659
13/07/27 23:12:06 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:12:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:12:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:12:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:12:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:12:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:12:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:12:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:12:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:12:06 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:12:06 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1000").cache()
13/07/27 23:12:07 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:12:07 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:12:08 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:12:08 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:12:08 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:12:08 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:12:08 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:12:08 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:12:08 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:12:08 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:12:08 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:12:08 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:12:08 INFO local.LocalTaskSetManager: Size of task 0 is 1489 bytes
13/07/27 23:12:08 INFO local.LocalScheduler: Running 0
13/07/27 23:12:08 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:12:08 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:12:08 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58399, maxMem=1358297825
13/07/27 23:12:08 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/27 23:12:08 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:40010 (size: 1580.2 KB, free: 1293.8 MB)
13/07/27 23:12:08 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:12:08 INFO local.LocalScheduler: Finished 0
13/07/27 23:12:08 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:12:08 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:12:08 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.237 s
13/07/27 23:12:08 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.280947611 s
res0: Long = 1000

scala> 13/07/27 23:12:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:12:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:12:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:12:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:12:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:12:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:12:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:12:08 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.10000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 12330369
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:12:11 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:12:11 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38952
Creating SparkContext...
13/07/27 23:12:20 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:12:20 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:12:20 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:12:20 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231220-45e4
13/07/27 23:12:20 INFO network.ConnectionManager: Bound socket to port 48610 with id = ConnectionManagerId(tachyon-ec2-0,48610)
13/07/27 23:12:20 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:12:20 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:48610 with 1295.4 MB RAM
13/07/27 23:12:20 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:12:20 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:12:20 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:51861
13/07/27 23:12:20 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:51861
13/07/27 23:12:20 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:12:20 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-5f557dad-23b3-4862-9c34-fe1ea171bf06
13/07/27 23:12:20 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:12:20 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:52236
13/07/27 23:12:20 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:12:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:12:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:12:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:12:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:12:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:12:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:12:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:12:20 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:12:20 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:12:20 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.10000").cache()
13/07/27 23:12:22 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:12:22 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:12:22 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:12:22 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:12:22 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:12:22 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:12:22 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:12:22 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:12:22 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:12:22 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:12:22 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:12:22 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:12:22 INFO local.LocalTaskSetManager: Size of task 0 is 1490 bytes
13/07/27 23:12:22 INFO local.LocalScheduler: Running 0
13/07/27 23:12:22 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:12:22 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:12:22 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58399, maxMem=1358297825
13/07/27 23:12:22 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/27 23:12:22 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:48610 (size: 25.0 MB, free: 1270.4 MB)
13/07/27 23:12:22 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:12:22 INFO local.LocalScheduler: Finished 0
13/07/27 23:12:22 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:12:22 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:12:22 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.437 s
13/07/27 23:12:22 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.482631408 s
res0: Long = 10000

scala> 13/07/27 23:12:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:12:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:12:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:12:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:12:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:12:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:12:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:12:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 125141299
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:12:25 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:12:25 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:35794
Creating SparkContext...
13/07/27 23:12:34 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:12:35 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:12:35 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:12:35 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231235-6521
13/07/27 23:12:35 INFO network.ConnectionManager: Bound socket to port 38592 with id = ConnectionManagerId(tachyon-ec2-0,38592)
13/07/27 23:12:35 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:12:35 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:38592 with 1295.4 MB RAM
13/07/27 23:12:35 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:12:35 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:12:35 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:48852
13/07/27 23:12:35 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:48852
13/07/27 23:12:35 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:12:35 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-e14806fe-de67-4ddf-936f-b571e09bf9f5
13/07/27 23:12:35 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:12:35 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:52076
13/07/27 23:12:35 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:12:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:12:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:12:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:12:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:12:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:12:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:12:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:12:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:12:35 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:12:35 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100000").cache()
13/07/27 23:12:36 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:12:36 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:12:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:12:36 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:12:36 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:12:36 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:12:36 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:12:36 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:12:36 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:12:36 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:12:36 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:12:36 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:12:37 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:12:37 INFO local.LocalScheduler: Running 0
13/07/27 23:12:37 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:12:37 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:12:37 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:12:37 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:12:37 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:38592 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:12:37 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:12:37 INFO local.LocalScheduler: Finished 0
13/07/27 23:12:37 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:12:37 INFO local.LocalScheduler: Running 1
13/07/27 23:12:37 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:12:37 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:12:37 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:12:37 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:12:37 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:12:37 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:38592 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:12:37 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:12:37 INFO local.LocalScheduler: Finished 1
13/07/27 23:12:37 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:12:37 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:12:37 INFO local.LocalScheduler: Running 2
13/07/27 23:12:37 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:12:37 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:12:38 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:12:38 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:12:38 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:38592 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:12:38 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:12:38 INFO local.LocalScheduler: Finished 2
13/07/27 23:12:38 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:12:38 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:12:38 INFO local.LocalScheduler: Running 3
13/07/27 23:12:38 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:12:38 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:12:38 INFO storage.MemoryStore: ensureFreeSpace(52232232) called with curMem=211087067, maxMem=1358297825
13/07/27 23:12:38 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 49.8 MB, free 1044.3 MB)
13/07/27 23:12:38 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:38592 (size: 49.8 MB, free: 1044.3 MB)
13/07/27 23:12:38 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:12:38 INFO local.LocalScheduler: Finished 3
13/07/27 23:12:38 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:12:38 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:12:38 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.548 s
13/07/27 23:12:38 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.593814819 s
res0: Long = 100002

scala> 13/07/27 23:12:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:12:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:12:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:12:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:12:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:12:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:12:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:12:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.500000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 618418417
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:12:41 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:12:41 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50165
Creating SparkContext...
13/07/27 23:12:50 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:12:50 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:12:50 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:12:50 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231250-3af5
13/07/27 23:12:50 INFO network.ConnectionManager: Bound socket to port 43216 with id = ConnectionManagerId(tachyon-ec2-0,43216)
13/07/27 23:12:50 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:12:50 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:43216 with 1295.4 MB RAM
13/07/27 23:12:50 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:12:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:12:50 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:44315
13/07/27 23:12:50 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:44315
13/07/27 23:12:50 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:12:50 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-6c93c7f1-41ad-455e-bb06-34e40e36e5fc
13/07/27 23:12:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:12:50 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38133
13/07/27 23:12:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:12:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:12:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:12:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:12:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:12:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:12:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:12:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:12:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:12:50 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:12:50 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.500000").cache()
13/07/27 23:12:52 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:12:52 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:12:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:12:52 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:12:52 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:12:52 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:12:52 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:12:52 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:12:52 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:12:52 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:12:52 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:12:52 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:12:52 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:12:52 INFO local.LocalScheduler: Running 0
13/07/27 23:12:52 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:12:52 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:12:53 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:12:53 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:12:53 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:43216 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:12:53 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:12:53 INFO local.LocalScheduler: Finished 0
13/07/27 23:12:53 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:12:53 INFO local.LocalScheduler: Running 1
13/07/27 23:12:53 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:12:53 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:12:53 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:12:53 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:12:53 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:12:53 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:43216 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:12:53 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:12:53 INFO local.LocalScheduler: Finished 1
13/07/27 23:12:53 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:12:53 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:12:53 INFO local.LocalScheduler: Running 2
13/07/27 23:12:53 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:12:53 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:12:53 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:12:53 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:12:53 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:43216 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:12:53 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:12:53 INFO local.LocalScheduler: Finished 2
13/07/27 23:12:53 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:12:53 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:12:53 INFO local.LocalScheduler: Running 3
13/07/27 23:12:53 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:12:53 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:12:54 INFO storage.MemoryStore: ensureFreeSpace(73224723) called with curMem=211087067, maxMem=1358297825
13/07/27 23:12:54 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 69.8 MB, free 1024.2 MB)
13/07/27 23:12:54 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:43216 (size: 69.8 MB, free: 1024.3 MB)
13/07/27 23:12:54 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:12:54 INFO local.LocalScheduler: Finished 3
13/07/27 23:12:54 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:12:54 INFO local.LocalTaskSetManager: Size of task 4 is 1491 bytes
13/07/27 23:12:54 INFO local.LocalScheduler: Running 4
13/07/27 23:12:54 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:12:54 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@695
13/07/27 23:12:54 INFO storage.MemoryStore: ensureFreeSpace(72058182) called with curMem=284311790, maxMem=1358297825
13/07/27 23:12:54 INFO storage.MemoryStore: Block rdd_1_4 stored as values to memory (estimated size 68.7 MB, free 955.5 MB)
13/07/27 23:12:54 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_4 in memory on tachyon-ec2-0:43216 (size: 68.7 MB, free: 955.6 MB)
13/07/27 23:12:54 INFO storage.BlockManagerMaster: Updated info of block rdd_1_4
13/07/27 23:12:54 INFO local.LocalScheduler: Finished 4
13/07/27 23:12:54 INFO scheduler.DAGScheduler: Completed ResultTask(0, 4)
13/07/27 23:12:54 INFO local.LocalTaskSetManager: Size of task 5 is 1491 bytes
13/07/27 23:12:54 INFO local.LocalScheduler: Running 5
13/07/27 23:12:54 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:12:54 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@696
13/07/27 23:12:54 INFO storage.MemoryStore: ensureFreeSpace(69756558) called with curMem=356369972, maxMem=1358297825
13/07/27 23:12:54 INFO storage.MemoryStore: Block rdd_1_5 stored as values to memory (estimated size 66.5 MB, free 889.0 MB)
13/07/27 23:12:54 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_5 in memory on tachyon-ec2-0:43216 (size: 66.5 MB, free: 889.0 MB)
13/07/27 23:12:54 INFO storage.BlockManagerMaster: Updated info of block rdd_1_5
13/07/27 23:12:54 INFO local.LocalScheduler: Finished 5
13/07/27 23:12:54 INFO scheduler.DAGScheduler: Completed ResultTask(0, 5)
13/07/27 23:12:54 INFO local.LocalTaskSetManager: Size of task 6 is 1491 bytes
13/07/27 23:12:54 INFO local.LocalScheduler: Running 6
13/07/27 23:12:54 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:12:54 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@697
13/07/27 23:12:55 INFO storage.MemoryStore: ensureFreeSpace(71337286) called with curMem=426126530, maxMem=1358297825
13/07/27 23:12:55 INFO storage.MemoryStore: Block rdd_1_6 stored as values to memory (estimated size 68.0 MB, free 821.0 MB)
13/07/27 23:12:55 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_6 in memory on tachyon-ec2-0:43216 (size: 68.0 MB, free: 821.0 MB)
13/07/27 23:12:55 INFO storage.BlockManagerMaster: Updated info of block rdd_1_6
13/07/27 23:12:55 INFO local.LocalScheduler: Finished 6
13/07/27 23:12:55 INFO scheduler.DAGScheduler: Completed ResultTask(0, 6)
13/07/27 23:12:55 INFO local.LocalTaskSetManager: Size of task 7 is 1491 bytes
13/07/27 23:12:55 INFO local.LocalScheduler: Running 7
13/07/27 23:12:55 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:12:55 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@698
13/07/27 23:12:55 INFO storage.MemoryStore: ensureFreeSpace(71927110) called with curMem=497463816, maxMem=1358297825
13/07/27 23:12:55 INFO storage.MemoryStore: Block rdd_1_7 stored as values to memory (estimated size 68.6 MB, free 752.4 MB)
13/07/27 23:12:55 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_7 in memory on tachyon-ec2-0:43216 (size: 68.6 MB, free: 752.4 MB)
13/07/27 23:12:55 INFO storage.BlockManagerMaster: Updated info of block rdd_1_7
13/07/27 23:12:55 INFO local.LocalScheduler: Finished 7
13/07/27 23:12:55 INFO scheduler.DAGScheduler: Completed ResultTask(0, 7)
13/07/27 23:12:55 INFO local.LocalTaskSetManager: Size of task 8 is 1491 bytes
13/07/27 23:12:55 INFO local.LocalScheduler: Running 8
13/07/27 23:12:55 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:12:55 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@699
13/07/27 23:12:55 INFO storage.MemoryStore: ensureFreeSpace(68354088) called with curMem=569390926, maxMem=1358297825
13/07/27 23:12:55 INFO storage.MemoryStore: Block rdd_1_8 stored as values to memory (estimated size 65.2 MB, free 687.2 MB)
13/07/27 23:12:55 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_8 in memory on tachyon-ec2-0:43216 (size: 65.2 MB, free: 687.2 MB)
13/07/27 23:12:55 INFO storage.BlockManagerMaster: Updated info of block rdd_1_8
13/07/27 23:12:55 INFO local.LocalScheduler: Finished 8
13/07/27 23:12:55 INFO scheduler.DAGScheduler: Completed ResultTask(0, 8)
13/07/27 23:12:55 INFO local.LocalTaskSetManager: Size of task 9 is 1491 bytes
13/07/27 23:12:55 INFO local.LocalScheduler: Running 9
13/07/27 23:12:55 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:12:55 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69a
13/07/27 23:12:56 INFO storage.MemoryStore: ensureFreeSpace(72189254) called with curMem=637745014, maxMem=1358297825
13/07/27 23:12:56 INFO storage.MemoryStore: Block rdd_1_9 stored as values to memory (estimated size 68.8 MB, free 618.3 MB)
13/07/27 23:12:56 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_9 in memory on tachyon-ec2-0:43216 (size: 68.8 MB, free: 618.4 MB)
13/07/27 23:12:56 INFO storage.BlockManagerMaster: Updated info of block rdd_1_9
13/07/27 23:12:56 INFO local.LocalScheduler: Finished 9
13/07/27 23:12:56 INFO scheduler.DAGScheduler: Completed ResultTask(0, 9)
13/07/27 23:12:56 INFO local.LocalTaskSetManager: Size of task 10 is 1491 bytes
13/07/27 23:12:56 INFO local.LocalScheduler: Running 10
13/07/27 23:12:56 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:12:56 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69b
13/07/27 23:12:56 INFO storage.MemoryStore: ensureFreeSpace(69900737) called with curMem=709934268, maxMem=1358297825
13/07/27 23:12:56 INFO storage.MemoryStore: Block rdd_1_10 stored as values to memory (estimated size 66.7 MB, free 551.7 MB)
13/07/27 23:12:56 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_10 in memory on tachyon-ec2-0:43216 (size: 66.7 MB, free: 551.7 MB)
13/07/27 23:12:56 INFO storage.BlockManagerMaster: Updated info of block rdd_1_10
13/07/27 23:12:56 INFO local.LocalScheduler: Finished 10
13/07/27 23:12:56 INFO scheduler.DAGScheduler: Completed ResultTask(0, 10)
13/07/27 23:12:56 INFO local.LocalTaskSetManager: Size of task 11 is 1491 bytes
13/07/27 23:12:56 INFO local.LocalScheduler: Running 11
13/07/27 23:12:56 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:12:56 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69c
13/07/27 23:12:56 INFO storage.MemoryStore: ensureFreeSpace(71945460) called with curMem=779835005, maxMem=1358297825
13/07/27 23:12:56 INFO storage.MemoryStore: Block rdd_1_11 stored as values to memory (estimated size 68.6 MB, free 483.1 MB)
13/07/27 23:12:56 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_11 in memory on tachyon-ec2-0:43216 (size: 68.6 MB, free: 483.1 MB)
13/07/27 23:12:56 INFO storage.BlockManagerMaster: Updated info of block rdd_1_11
13/07/27 23:12:56 INFO local.LocalScheduler: Finished 11
13/07/27 23:12:56 INFO scheduler.DAGScheduler: Completed ResultTask(0, 11)
13/07/27 23:12:56 INFO local.LocalTaskSetManager: Size of task 12 is 1491 bytes
13/07/27 23:12:56 INFO local.LocalScheduler: Running 12
13/07/27 23:12:56 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:12:56 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69d
13/07/27 23:12:56 INFO storage.MemoryStore: ensureFreeSpace(71937596) called with curMem=851780465, maxMem=1358297825
13/07/27 23:12:56 INFO storage.MemoryStore: Block rdd_1_12 stored as values to memory (estimated size 68.6 MB, free 414.4 MB)
13/07/27 23:12:56 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_12 in memory on tachyon-ec2-0:43216 (size: 68.6 MB, free: 414.5 MB)
13/07/27 23:12:56 INFO storage.BlockManagerMaster: Updated info of block rdd_1_12
13/07/27 23:12:56 INFO local.LocalScheduler: Finished 12
13/07/27 23:12:56 INFO scheduler.DAGScheduler: Completed ResultTask(0, 12)
13/07/27 23:12:56 INFO local.LocalTaskSetManager: Size of task 13 is 1491 bytes
13/07/27 23:12:56 INFO local.LocalScheduler: Running 13
13/07/27 23:12:56 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:12:56 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69e
13/07/27 23:12:57 INFO storage.MemoryStore: ensureFreeSpace(72915393) called with curMem=923718061, maxMem=1358297825
13/07/27 23:12:57 INFO storage.MemoryStore: Block rdd_1_13 stored as values to memory (estimated size 69.5 MB, free 344.9 MB)
13/07/27 23:12:57 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_13 in memory on tachyon-ec2-0:43216 (size: 69.5 MB, free: 345.0 MB)
13/07/27 23:12:57 INFO storage.BlockManagerMaster: Updated info of block rdd_1_13
13/07/27 23:12:57 INFO local.LocalScheduler: Finished 13
13/07/27 23:12:57 INFO scheduler.DAGScheduler: Completed ResultTask(0, 13)
13/07/27 23:12:57 INFO local.LocalTaskSetManager: Size of task 14 is 1491 bytes
13/07/27 23:12:57 INFO local.LocalScheduler: Running 14
13/07/27 23:12:57 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:12:57 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69f
13/07/27 23:12:58 INFO storage.MemoryStore: ensureFreeSpace(71974296) called with curMem=996633454, maxMem=1358297825
13/07/27 23:12:58 INFO storage.MemoryStore: Block rdd_1_14 stored as values to memory (estimated size 68.6 MB, free 276.3 MB)
13/07/27 23:12:58 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_14 in memory on tachyon-ec2-0:43216 (size: 68.6 MB, free: 276.3 MB)
13/07/27 23:12:58 INFO storage.BlockManagerMaster: Updated info of block rdd_1_14
13/07/27 23:12:58 INFO local.LocalScheduler: Finished 14
13/07/27 23:12:58 INFO scheduler.DAGScheduler: Completed ResultTask(0, 14)
13/07/27 23:12:58 INFO local.LocalTaskSetManager: Size of task 15 is 1491 bytes
13/07/27 23:12:58 INFO local.LocalScheduler: Running 15
13/07/27 23:12:58 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:12:58 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a0
13/07/27 23:12:58 INFO storage.MemoryStore: ensureFreeSpace(71051549) called with curMem=1068607750, maxMem=1358297825
13/07/27 23:12:58 INFO storage.MemoryStore: Block rdd_1_15 stored as values to memory (estimated size 67.8 MB, free 208.5 MB)
13/07/27 23:12:58 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_15 in memory on tachyon-ec2-0:43216 (size: 67.8 MB, free: 208.6 MB)
13/07/27 23:12:58 INFO storage.BlockManagerMaster: Updated info of block rdd_1_15
13/07/27 23:12:58 INFO local.LocalScheduler: Finished 15
13/07/27 23:12:58 INFO scheduler.DAGScheduler: Completed ResultTask(0, 15)
13/07/27 23:12:58 INFO local.LocalTaskSetManager: Size of task 16 is 1491 bytes
13/07/27 23:12:58 INFO local.LocalScheduler: Running 16
13/07/27 23:12:58 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:12:58 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a1
13/07/27 23:12:58 INFO storage.MemoryStore: ensureFreeSpace(71565352) called with curMem=1139659299, maxMem=1358297825
13/07/27 23:12:58 INFO storage.MemoryStore: Block rdd_1_16 stored as values to memory (estimated size 68.3 MB, free 140.3 MB)
13/07/27 23:12:58 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_16 in memory on tachyon-ec2-0:43216 (size: 68.3 MB, free: 140.3 MB)
13/07/27 23:12:58 INFO storage.BlockManagerMaster: Updated info of block rdd_1_16
13/07/27 23:12:58 INFO local.LocalScheduler: Finished 16
13/07/27 23:12:58 INFO scheduler.DAGScheduler: Completed ResultTask(0, 16)
13/07/27 23:12:58 INFO local.LocalTaskSetManager: Size of task 17 is 1491 bytes
13/07/27 23:12:58 INFO local.LocalScheduler: Running 17
13/07/27 23:12:58 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:12:58 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a2
13/07/27 23:12:59 INFO storage.MemoryStore: ensureFreeSpace(72682085) called with curMem=1211224651, maxMem=1358297825
13/07/27 23:12:59 INFO storage.MemoryStore: Block rdd_1_17 stored as values to memory (estimated size 69.3 MB, free 70.9 MB)
13/07/27 23:12:59 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_17 in memory on tachyon-ec2-0:43216 (size: 69.3 MB, free: 71.0 MB)
13/07/27 23:12:59 INFO storage.BlockManagerMaster: Updated info of block rdd_1_17
13/07/27 23:12:59 INFO local.LocalScheduler: Finished 17
13/07/27 23:12:59 INFO scheduler.DAGScheduler: Completed ResultTask(0, 17)
13/07/27 23:12:59 INFO local.LocalTaskSetManager: Size of task 18 is 1491 bytes
13/07/27 23:12:59 INFO local.LocalScheduler: Running 18
13/07/27 23:12:59 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:12:59 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a3
13/07/27 23:12:59 INFO storage.MemoryStore: ensureFreeSpace(30062713) called with curMem=1283906736, maxMem=1358297825
13/07/27 23:12:59 INFO storage.MemoryStore: Block rdd_1_18 stored as values to memory (estimated size 28.7 MB, free 42.3 MB)
13/07/27 23:12:59 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_18 in memory on tachyon-ec2-0:43216 (size: 28.7 MB, free: 42.3 MB)
13/07/27 23:12:59 INFO storage.BlockManagerMaster: Updated info of block rdd_1_18
13/07/27 23:12:59 INFO local.LocalScheduler: Finished 18
13/07/27 23:12:59 INFO scheduler.DAGScheduler: Completed ResultTask(0, 18)
13/07/27 23:12:59 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:12:59 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 6.648 s
13/07/27 23:12:59 INFO spark.SparkContext: Job finished: count at <console>:15, took 6.698875784 s
res0: Long = 500094

scala> 13/07/27 23:12:59 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:12:59 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:12:59 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:12:59 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:12:59 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:12:59 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:12:59 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:12:59 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 3

spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1 as mode POSIX_FADV_DONTNEED
offset: 0
length: 525
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:13:02 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:13:02 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:56827
Creating SparkContext...
13/07/27 23:13:11 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:13:11 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:13:11 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:13:11 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231311-81e3
13/07/27 23:13:11 INFO network.ConnectionManager: Bound socket to port 50198 with id = ConnectionManagerId(tachyon-ec2-0,50198)
13/07/27 23:13:11 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:13:11 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:50198 with 1295.4 MB RAM
13/07/27 23:13:11 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:13:11 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:13:11 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55995
13/07/27 23:13:11 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:55995
13/07/27 23:13:11 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:13:11 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-37085461-925c-4805-85b4-ce78e2264781
13/07/27 23:13:11 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:13:11 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:46117
13/07/27 23:13:11 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:13:11 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:13:11 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:13:11 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:13:11 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:13:11 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:13:11 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:13:11 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:13:11 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:13:11 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:13:11 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1").cache()
13/07/27 23:13:13 INFO storage.MemoryStore: ensureFreeSpace(58391) called with curMem=0, maxMem=1358297825
13/07/27 23:13:13 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:13:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:13:13 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:13:13 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:13:13 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:13:13 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:13:13 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:13:13 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:13:13 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:13:13 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:13:13 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:13:13 INFO local.LocalTaskSetManager: Size of task 0 is 1486 bytes
13/07/27 23:13:13 INFO local.LocalScheduler: Running 0
13/07/27 23:13:13 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:13:13 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:13:13 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58391, maxMem=1358297825
13/07/27 23:13:13 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/27 23:13:13 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:50198 (size: 1192.0 B, free: 1295.4 MB)
13/07/27 23:13:13 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:13:13 INFO local.LocalScheduler: Finished 0
13/07/27 23:13:13 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:13:13 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:13:13 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.205 s
13/07/27 23:13:13 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.249080648 s
res0: Long = 1

scala> 13/07/27 23:13:13 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:13:13 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:13:13 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:13:13 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:13:13 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:13:13 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:13:13 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:13:13 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100 as mode POSIX_FADV_DONTNEED
offset: 0
length: 55735
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:13:16 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:13:16 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37431
Creating SparkContext...
13/07/27 23:13:25 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:13:25 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:13:25 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:13:25 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231325-609c
13/07/27 23:13:25 INFO network.ConnectionManager: Bound socket to port 42438 with id = ConnectionManagerId(tachyon-ec2-0,42438)
13/07/27 23:13:25 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:13:25 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:42438 with 1295.4 MB RAM
13/07/27 23:13:25 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:13:25 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:13:25 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:36882
13/07/27 23:13:25 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:36882
13/07/27 23:13:25 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:13:25 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-871ef6b6-2813-43d6-ac31-17b31de456a3
13/07/27 23:13:25 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:13:25 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:49775
13/07/27 23:13:25 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:13:25 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:13:25 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:13:25 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:13:25 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:13:25 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:13:25 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:13:25 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:13:25 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:13:25 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:13:25 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100").cache()
13/07/27 23:13:27 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:13:27 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:13:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:13:27 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:13:27 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:13:27 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:13:27 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:13:27 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:13:27 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:13:27 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:13:27 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:13:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:13:27 INFO local.LocalTaskSetManager: Size of task 0 is 1488 bytes
13/07/27 23:13:27 INFO local.LocalScheduler: Running 0
13/07/27 23:13:27 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:13:27 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:13:27 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58399, maxMem=1358297825
13/07/27 23:13:27 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/27 23:13:27 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:42438 (size: 113.4 KB, free: 1295.3 MB)
13/07/27 23:13:27 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:13:27 INFO local.LocalScheduler: Finished 0
13/07/27 23:13:27 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:13:27 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:13:27 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.231 s
13/07/27 23:13:27 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.275680666 s
res0: Long = 100

scala> 13/07/27 23:13:27 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:13:27 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:13:27 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:13:27 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:13:27 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:13:27 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:13:27 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:13:27 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 776400
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:13:30 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:13:30 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:47807
Creating SparkContext...
13/07/27 23:13:39 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:13:39 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:13:39 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:13:39 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231339-b417
13/07/27 23:13:39 INFO network.ConnectionManager: Bound socket to port 53572 with id = ConnectionManagerId(tachyon-ec2-0,53572)
13/07/27 23:13:39 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:13:39 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:53572 with 1295.4 MB RAM
13/07/27 23:13:39 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:13:39 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:13:39 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:41186
13/07/27 23:13:39 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:41186
13/07/27 23:13:39 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:13:39 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-11ca311a-6768-4e73-821a-f07a05ece1ce
13/07/27 23:13:39 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:13:39 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:46061
13/07/27 23:13:39 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:13:39 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:13:39 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:13:39 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:13:39 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:13:39 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:13:39 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:13:39 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:13:39 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:13:39 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:13:39 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1000").cache()
13/07/27 23:13:41 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:13:41 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:13:41 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:13:41 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:13:41 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:13:41 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:13:41 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:13:41 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:13:41 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:13:41 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:13:41 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:13:41 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:13:41 INFO local.LocalTaskSetManager: Size of task 0 is 1489 bytes
13/07/27 23:13:41 INFO local.LocalScheduler: Running 0
13/07/27 23:13:41 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:13:41 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:13:41 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58399, maxMem=1358297825
13/07/27 23:13:41 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/27 23:13:41 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:53572 (size: 1580.2 KB, free: 1293.8 MB)
13/07/27 23:13:41 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:13:41 INFO local.LocalScheduler: Finished 0
13/07/27 23:13:41 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:13:41 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:13:41 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.242 s
13/07/27 23:13:41 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.286214994 s
res0: Long = 1000

scala> 13/07/27 23:13:42 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:13:42 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:13:42 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:13:42 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:13:42 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:13:42 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:13:42 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:13:42 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.10000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 12330369
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:13:44 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:13:44 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:43191
Creating SparkContext...
13/07/27 23:13:53 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:13:53 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:13:53 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:13:53 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231353-fee7
13/07/27 23:13:54 INFO network.ConnectionManager: Bound socket to port 46325 with id = ConnectionManagerId(tachyon-ec2-0,46325)
13/07/27 23:13:54 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:13:54 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:46325 with 1295.4 MB RAM
13/07/27 23:13:54 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:13:54 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:13:54 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53307
13/07/27 23:13:54 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:53307
13/07/27 23:13:54 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:13:54 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-fb39893e-1bf8-4a0a-8000-bcc09ee8087b
13/07/27 23:13:54 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:13:54 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55466
13/07/27 23:13:54 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:13:54 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:13:54 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:13:54 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:13:54 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:13:54 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:13:54 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:13:54 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:13:54 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:13:54 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:13:54 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.10000").cache()
13/07/27 23:13:55 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:13:55 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:13:55 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:13:55 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:13:55 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:13:55 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:13:55 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:13:55 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:13:55 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:13:55 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:13:55 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:13:55 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:13:55 INFO local.LocalTaskSetManager: Size of task 0 is 1490 bytes
13/07/27 23:13:55 INFO local.LocalScheduler: Running 0
13/07/27 23:13:56 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:13:56 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:13:56 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58399, maxMem=1358297825
13/07/27 23:13:56 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/27 23:13:56 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:46325 (size: 25.0 MB, free: 1270.4 MB)
13/07/27 23:13:56 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:13:56 INFO local.LocalScheduler: Finished 0
13/07/27 23:13:56 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:13:56 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:13:56 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.407 s
13/07/27 23:13:56 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.452058355 s
res0: Long = 10000

scala> 13/07/27 23:13:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:13:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:13:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:13:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:13:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:13:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:13:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:13:56 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 125141299
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:13:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:13:58 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:57349
Creating SparkContext...
13/07/27 23:14:08 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:14:08 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:14:08 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:14:08 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231408-214a
13/07/27 23:14:08 INFO network.ConnectionManager: Bound socket to port 54679 with id = ConnectionManagerId(tachyon-ec2-0,54679)
13/07/27 23:14:08 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:14:08 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:54679 with 1295.4 MB RAM
13/07/27 23:14:08 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:14:08 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:14:08 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:58404
13/07/27 23:14:08 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:58404
13/07/27 23:14:08 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:14:08 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-67cc34d2-35ac-4f06-baf9-45f4af84fe97
13/07/27 23:14:08 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:14:08 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:58510
13/07/27 23:14:08 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:14:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:14:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:14:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:14:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:14:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:14:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:14:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:14:08 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:14:08 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:14:08 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100000").cache()
13/07/27 23:14:09 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:14:09 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:14:10 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:14:10 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:14:10 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:14:10 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:14:10 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:14:10 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:14:10 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:14:10 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:14:10 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:14:10 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:14:10 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:14:10 INFO local.LocalScheduler: Running 0
13/07/27 23:14:10 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:14:10 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:14:10 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:14:10 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:14:10 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:54679 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:14:10 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:14:10 INFO local.LocalScheduler: Finished 0
13/07/27 23:14:10 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:14:10 INFO local.LocalScheduler: Running 1
13/07/27 23:14:10 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:14:10 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:14:10 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:14:11 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:14:11 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:14:11 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:54679 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:14:11 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:14:11 INFO local.LocalScheduler: Finished 1
13/07/27 23:14:11 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:14:11 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:14:11 INFO local.LocalScheduler: Running 2
13/07/27 23:14:11 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:14:11 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:14:11 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:14:11 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:14:11 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:54679 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:14:11 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:14:12 INFO local.LocalScheduler: Finished 2
13/07/27 23:14:12 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:14:12 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:14:12 INFO local.LocalScheduler: Running 3
13/07/27 23:14:12 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:14:12 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:14:12 INFO storage.MemoryStore: ensureFreeSpace(52232232) called with curMem=211087067, maxMem=1358297825
13/07/27 23:14:12 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 49.8 MB, free 1044.3 MB)
13/07/27 23:14:12 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:54679 (size: 49.8 MB, free: 1044.3 MB)
13/07/27 23:14:12 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:14:12 INFO local.LocalScheduler: Finished 3
13/07/27 23:14:12 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:14:12 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:14:12 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.990 s
13/07/27 23:14:12 INFO spark.SparkContext: Job finished: count at <console>:15, took 2.035499693 s
res0: Long = 100002

scala> 13/07/27 23:14:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:14:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:14:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:14:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:14:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:14:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:14:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:14:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.500000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 618418417
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:14:14 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:14:15 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:34318
Creating SparkContext...
13/07/27 23:14:24 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:14:24 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:14:24 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:14:24 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231424-6155
13/07/27 23:14:24 INFO network.ConnectionManager: Bound socket to port 58429 with id = ConnectionManagerId(tachyon-ec2-0,58429)
13/07/27 23:14:24 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:14:24 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:58429 with 1295.4 MB RAM
13/07/27 23:14:24 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:14:24 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:14:24 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:58696
13/07/27 23:14:24 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:58696
13/07/27 23:14:24 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:14:24 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-7b03fa22-380d-499b-a42b-705f258ad301
13/07/27 23:14:24 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:14:24 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50897
13/07/27 23:14:24 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:14:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:14:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:14:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:14:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:14:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:14:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:14:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:14:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:14:24 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:14:24 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.500000").cache()
13/07/27 23:14:25 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:14:25 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:14:26 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:14:26 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:14:26 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:14:26 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:14:26 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:14:26 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:14:26 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:14:26 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:14:26 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:14:26 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:14:26 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:14:26 INFO local.LocalScheduler: Running 0
13/07/27 23:14:26 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:14:26 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:14:26 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:14:26 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:14:26 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:58429 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:14:26 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:14:26 INFO local.LocalScheduler: Finished 0
13/07/27 23:14:26 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:14:26 INFO local.LocalScheduler: Running 1
13/07/27 23:14:26 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:14:26 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:14:26 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:14:27 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:14:27 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:14:27 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:58429 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:14:27 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:14:27 INFO local.LocalScheduler: Finished 1
13/07/27 23:14:27 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:14:27 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:14:27 INFO local.LocalScheduler: Running 2
13/07/27 23:14:27 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:14:27 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:14:27 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:14:27 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:14:27 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:58429 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:14:27 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:14:27 INFO local.LocalScheduler: Finished 2
13/07/27 23:14:27 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:14:27 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:14:27 INFO local.LocalScheduler: Running 3
13/07/27 23:14:27 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:14:27 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:14:27 INFO storage.MemoryStore: ensureFreeSpace(73224723) called with curMem=211087067, maxMem=1358297825
13/07/27 23:14:27 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 69.8 MB, free 1024.2 MB)
13/07/27 23:14:27 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:58429 (size: 69.8 MB, free: 1024.3 MB)
13/07/27 23:14:27 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:14:27 INFO local.LocalScheduler: Finished 3
13/07/27 23:14:27 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:14:27 INFO local.LocalTaskSetManager: Size of task 4 is 1491 bytes
13/07/27 23:14:27 INFO local.LocalScheduler: Running 4
13/07/27 23:14:27 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:14:27 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@695
13/07/27 23:14:28 INFO storage.MemoryStore: ensureFreeSpace(72058182) called with curMem=284311790, maxMem=1358297825
13/07/27 23:14:28 INFO storage.MemoryStore: Block rdd_1_4 stored as values to memory (estimated size 68.7 MB, free 955.5 MB)
13/07/27 23:14:28 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_4 in memory on tachyon-ec2-0:58429 (size: 68.7 MB, free: 955.6 MB)
13/07/27 23:14:28 INFO storage.BlockManagerMaster: Updated info of block rdd_1_4
13/07/27 23:14:28 INFO local.LocalScheduler: Finished 4
13/07/27 23:14:28 INFO scheduler.DAGScheduler: Completed ResultTask(0, 4)
13/07/27 23:14:28 INFO local.LocalTaskSetManager: Size of task 5 is 1491 bytes
13/07/27 23:14:28 INFO local.LocalScheduler: Running 5
13/07/27 23:14:28 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:14:28 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@696
13/07/27 23:14:28 INFO storage.MemoryStore: ensureFreeSpace(69756558) called with curMem=356369972, maxMem=1358297825
13/07/27 23:14:28 INFO storage.MemoryStore: Block rdd_1_5 stored as values to memory (estimated size 66.5 MB, free 889.0 MB)
13/07/27 23:14:28 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_5 in memory on tachyon-ec2-0:58429 (size: 66.5 MB, free: 889.0 MB)
13/07/27 23:14:28 INFO storage.BlockManagerMaster: Updated info of block rdd_1_5
13/07/27 23:14:28 INFO local.LocalScheduler: Finished 5
13/07/27 23:14:28 INFO scheduler.DAGScheduler: Completed ResultTask(0, 5)
13/07/27 23:14:28 INFO local.LocalTaskSetManager: Size of task 6 is 1491 bytes
13/07/27 23:14:28 INFO local.LocalScheduler: Running 6
13/07/27 23:14:28 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:14:28 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@697
13/07/27 23:14:28 INFO storage.MemoryStore: ensureFreeSpace(71337286) called with curMem=426126530, maxMem=1358297825
13/07/27 23:14:28 INFO storage.MemoryStore: Block rdd_1_6 stored as values to memory (estimated size 68.0 MB, free 821.0 MB)
13/07/27 23:14:28 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_6 in memory on tachyon-ec2-0:58429 (size: 68.0 MB, free: 821.0 MB)
13/07/27 23:14:28 INFO storage.BlockManagerMaster: Updated info of block rdd_1_6
13/07/27 23:14:28 INFO local.LocalScheduler: Finished 6
13/07/27 23:14:28 INFO scheduler.DAGScheduler: Completed ResultTask(0, 6)
13/07/27 23:14:28 INFO local.LocalTaskSetManager: Size of task 7 is 1491 bytes
13/07/27 23:14:28 INFO local.LocalScheduler: Running 7
13/07/27 23:14:28 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:14:28 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@698
13/07/27 23:14:29 INFO storage.MemoryStore: ensureFreeSpace(71927110) called with curMem=497463816, maxMem=1358297825
13/07/27 23:14:29 INFO storage.MemoryStore: Block rdd_1_7 stored as values to memory (estimated size 68.6 MB, free 752.4 MB)
13/07/27 23:14:29 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_7 in memory on tachyon-ec2-0:58429 (size: 68.6 MB, free: 752.4 MB)
13/07/27 23:14:29 INFO storage.BlockManagerMaster: Updated info of block rdd_1_7
13/07/27 23:14:29 INFO local.LocalScheduler: Finished 7
13/07/27 23:14:29 INFO scheduler.DAGScheduler: Completed ResultTask(0, 7)
13/07/27 23:14:29 INFO local.LocalTaskSetManager: Size of task 8 is 1491 bytes
13/07/27 23:14:29 INFO local.LocalScheduler: Running 8
13/07/27 23:14:29 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:14:29 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@699
13/07/27 23:14:29 INFO storage.MemoryStore: ensureFreeSpace(68354088) called with curMem=569390926, maxMem=1358297825
13/07/27 23:14:29 INFO storage.MemoryStore: Block rdd_1_8 stored as values to memory (estimated size 65.2 MB, free 687.2 MB)
13/07/27 23:14:29 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_8 in memory on tachyon-ec2-0:58429 (size: 65.2 MB, free: 687.2 MB)
13/07/27 23:14:29 INFO storage.BlockManagerMaster: Updated info of block rdd_1_8
13/07/27 23:14:29 INFO local.LocalScheduler: Finished 8
13/07/27 23:14:29 INFO scheduler.DAGScheduler: Completed ResultTask(0, 8)
13/07/27 23:14:29 INFO local.LocalTaskSetManager: Size of task 9 is 1491 bytes
13/07/27 23:14:29 INFO local.LocalScheduler: Running 9
13/07/27 23:14:29 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:14:29 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69a
13/07/27 23:14:29 INFO storage.MemoryStore: ensureFreeSpace(72189254) called with curMem=637745014, maxMem=1358297825
13/07/27 23:14:29 INFO storage.MemoryStore: Block rdd_1_9 stored as values to memory (estimated size 68.8 MB, free 618.3 MB)
13/07/27 23:14:29 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_9 in memory on tachyon-ec2-0:58429 (size: 68.8 MB, free: 618.4 MB)
13/07/27 23:14:29 INFO storage.BlockManagerMaster: Updated info of block rdd_1_9
13/07/27 23:14:29 INFO local.LocalScheduler: Finished 9
13/07/27 23:14:29 INFO scheduler.DAGScheduler: Completed ResultTask(0, 9)
13/07/27 23:14:29 INFO local.LocalTaskSetManager: Size of task 10 is 1491 bytes
13/07/27 23:14:29 INFO local.LocalScheduler: Running 10
13/07/27 23:14:29 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:14:29 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69b
13/07/27 23:14:30 INFO storage.MemoryStore: ensureFreeSpace(69900737) called with curMem=709934268, maxMem=1358297825
13/07/27 23:14:30 INFO storage.MemoryStore: Block rdd_1_10 stored as values to memory (estimated size 66.7 MB, free 551.7 MB)
13/07/27 23:14:30 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_10 in memory on tachyon-ec2-0:58429 (size: 66.7 MB, free: 551.7 MB)
13/07/27 23:14:30 INFO storage.BlockManagerMaster: Updated info of block rdd_1_10
13/07/27 23:14:30 INFO local.LocalScheduler: Finished 10
13/07/27 23:14:30 INFO scheduler.DAGScheduler: Completed ResultTask(0, 10)
13/07/27 23:14:30 INFO local.LocalTaskSetManager: Size of task 11 is 1491 bytes
13/07/27 23:14:30 INFO local.LocalScheduler: Running 11
13/07/27 23:14:30 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:14:30 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69c
13/07/27 23:14:30 INFO storage.MemoryStore: ensureFreeSpace(71945460) called with curMem=779835005, maxMem=1358297825
13/07/27 23:14:30 INFO storage.MemoryStore: Block rdd_1_11 stored as values to memory (estimated size 68.6 MB, free 483.1 MB)
13/07/27 23:14:30 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_11 in memory on tachyon-ec2-0:58429 (size: 68.6 MB, free: 483.1 MB)
13/07/27 23:14:30 INFO storage.BlockManagerMaster: Updated info of block rdd_1_11
13/07/27 23:14:30 INFO local.LocalScheduler: Finished 11
13/07/27 23:14:30 INFO scheduler.DAGScheduler: Completed ResultTask(0, 11)
13/07/27 23:14:30 INFO local.LocalTaskSetManager: Size of task 12 is 1491 bytes
13/07/27 23:14:30 INFO local.LocalScheduler: Running 12
13/07/27 23:14:30 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:14:30 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69d
13/07/27 23:14:30 INFO storage.MemoryStore: ensureFreeSpace(71937596) called with curMem=851780465, maxMem=1358297825
13/07/27 23:14:30 INFO storage.MemoryStore: Block rdd_1_12 stored as values to memory (estimated size 68.6 MB, free 414.4 MB)
13/07/27 23:14:30 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_12 in memory on tachyon-ec2-0:58429 (size: 68.6 MB, free: 414.5 MB)
13/07/27 23:14:30 INFO storage.BlockManagerMaster: Updated info of block rdd_1_12
13/07/27 23:14:30 INFO local.LocalScheduler: Finished 12
13/07/27 23:14:30 INFO scheduler.DAGScheduler: Completed ResultTask(0, 12)
13/07/27 23:14:30 INFO local.LocalTaskSetManager: Size of task 13 is 1491 bytes
13/07/27 23:14:30 INFO local.LocalScheduler: Running 13
13/07/27 23:14:30 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:14:30 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69e
13/07/27 23:14:31 INFO storage.MemoryStore: ensureFreeSpace(72915393) called with curMem=923718061, maxMem=1358297825
13/07/27 23:14:31 INFO storage.MemoryStore: Block rdd_1_13 stored as values to memory (estimated size 69.5 MB, free 344.9 MB)
13/07/27 23:14:31 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_13 in memory on tachyon-ec2-0:58429 (size: 69.5 MB, free: 345.0 MB)
13/07/27 23:14:31 INFO storage.BlockManagerMaster: Updated info of block rdd_1_13
13/07/27 23:14:31 INFO local.LocalScheduler: Finished 13
13/07/27 23:14:31 INFO scheduler.DAGScheduler: Completed ResultTask(0, 13)
13/07/27 23:14:31 INFO local.LocalTaskSetManager: Size of task 14 is 1491 bytes
13/07/27 23:14:31 INFO local.LocalScheduler: Running 14
13/07/27 23:14:31 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:14:31 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69f
13/07/27 23:14:31 INFO storage.MemoryStore: ensureFreeSpace(71974296) called with curMem=996633454, maxMem=1358297825
13/07/27 23:14:31 INFO storage.MemoryStore: Block rdd_1_14 stored as values to memory (estimated size 68.6 MB, free 276.3 MB)
13/07/27 23:14:31 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_14 in memory on tachyon-ec2-0:58429 (size: 68.6 MB, free: 276.3 MB)
13/07/27 23:14:31 INFO storage.BlockManagerMaster: Updated info of block rdd_1_14
13/07/27 23:14:31 INFO local.LocalScheduler: Finished 14
13/07/27 23:14:31 INFO scheduler.DAGScheduler: Completed ResultTask(0, 14)
13/07/27 23:14:31 INFO local.LocalTaskSetManager: Size of task 15 is 1491 bytes
13/07/27 23:14:31 INFO local.LocalScheduler: Running 15
13/07/27 23:14:31 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:14:31 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a0
13/07/27 23:14:32 INFO storage.MemoryStore: ensureFreeSpace(71051549) called with curMem=1068607750, maxMem=1358297825
13/07/27 23:14:32 INFO storage.MemoryStore: Block rdd_1_15 stored as values to memory (estimated size 67.8 MB, free 208.5 MB)
13/07/27 23:14:32 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_15 in memory on tachyon-ec2-0:58429 (size: 67.8 MB, free: 208.6 MB)
13/07/27 23:14:32 INFO storage.BlockManagerMaster: Updated info of block rdd_1_15
13/07/27 23:14:32 INFO local.LocalScheduler: Finished 15
13/07/27 23:14:32 INFO scheduler.DAGScheduler: Completed ResultTask(0, 15)
13/07/27 23:14:32 INFO local.LocalTaskSetManager: Size of task 16 is 1491 bytes
13/07/27 23:14:32 INFO local.LocalScheduler: Running 16
13/07/27 23:14:32 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:14:32 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a1
13/07/27 23:14:32 INFO storage.MemoryStore: ensureFreeSpace(71565352) called with curMem=1139659299, maxMem=1358297825
13/07/27 23:14:32 INFO storage.MemoryStore: Block rdd_1_16 stored as values to memory (estimated size 68.3 MB, free 140.3 MB)
13/07/27 23:14:32 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_16 in memory on tachyon-ec2-0:58429 (size: 68.3 MB, free: 140.3 MB)
13/07/27 23:14:32 INFO storage.BlockManagerMaster: Updated info of block rdd_1_16
13/07/27 23:14:32 INFO local.LocalScheduler: Finished 16
13/07/27 23:14:32 INFO scheduler.DAGScheduler: Completed ResultTask(0, 16)
13/07/27 23:14:32 INFO local.LocalTaskSetManager: Size of task 17 is 1491 bytes
13/07/27 23:14:32 INFO local.LocalScheduler: Running 17
13/07/27 23:14:32 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:14:32 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a2
13/07/27 23:14:32 INFO storage.MemoryStore: ensureFreeSpace(72682085) called with curMem=1211224651, maxMem=1358297825
13/07/27 23:14:32 INFO storage.MemoryStore: Block rdd_1_17 stored as values to memory (estimated size 69.3 MB, free 70.9 MB)
13/07/27 23:14:32 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_17 in memory on tachyon-ec2-0:58429 (size: 69.3 MB, free: 71.0 MB)
13/07/27 23:14:32 INFO storage.BlockManagerMaster: Updated info of block rdd_1_17
13/07/27 23:14:32 INFO local.LocalScheduler: Finished 17
13/07/27 23:14:32 INFO scheduler.DAGScheduler: Completed ResultTask(0, 17)
13/07/27 23:14:32 INFO local.LocalTaskSetManager: Size of task 18 is 1491 bytes
13/07/27 23:14:32 INFO local.LocalScheduler: Running 18
13/07/27 23:14:32 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:14:32 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a3
13/07/27 23:14:33 INFO storage.MemoryStore: ensureFreeSpace(30062713) called with curMem=1283906736, maxMem=1358297825
13/07/27 23:14:33 INFO storage.MemoryStore: Block rdd_1_18 stored as values to memory (estimated size 28.7 MB, free 42.3 MB)
13/07/27 23:14:33 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_18 in memory on tachyon-ec2-0:58429 (size: 28.7 MB, free: 42.3 MB)
13/07/27 23:14:33 INFO storage.BlockManagerMaster: Updated info of block rdd_1_18
13/07/27 23:14:33 INFO local.LocalScheduler: Finished 18
13/07/27 23:14:33 INFO scheduler.DAGScheduler: Completed ResultTask(0, 18)
13/07/27 23:14:33 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:14:33 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 6.877 s
13/07/27 23:14:33 INFO spark.SparkContext: Job finished: count at <console>:15, took 6.927353262 s
res0: Long = 500094

scala> 13/07/27 23:14:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:14:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:14:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:14:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:14:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:14:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:14:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:14:33 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 4

spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1 as mode POSIX_FADV_DONTNEED
offset: 0
length: 525
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:14:35 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:14:35 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60207
Creating SparkContext...
13/07/27 23:14:45 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:14:45 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:14:45 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:14:45 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231445-61f2
13/07/27 23:14:45 INFO network.ConnectionManager: Bound socket to port 37795 with id = ConnectionManagerId(tachyon-ec2-0,37795)
13/07/27 23:14:45 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:14:45 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:37795 with 1295.4 MB RAM
13/07/27 23:14:45 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:14:45 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:14:45 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:42720
13/07/27 23:14:45 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:42720
13/07/27 23:14:45 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:14:45 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-a4e1b1f9-2cb3-4cc5-b2ed-1880ad33ac20
13/07/27 23:14:45 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:14:45 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:42860
13/07/27 23:14:45 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:14:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:14:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:14:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:14:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:14:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:14:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:14:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:14:45 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:14:45 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:14:45 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1").cache()
13/07/27 23:14:46 INFO storage.MemoryStore: ensureFreeSpace(58391) called with curMem=0, maxMem=1358297825
13/07/27 23:14:46 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:14:47 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:14:47 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:14:47 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:14:47 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:14:47 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:14:47 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:14:47 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:14:47 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:14:47 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:14:47 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:14:47 INFO local.LocalTaskSetManager: Size of task 0 is 1486 bytes
13/07/27 23:14:47 INFO local.LocalScheduler: Running 0
13/07/27 23:14:47 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:14:47 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:14:47 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58391, maxMem=1358297825
13/07/27 23:14:47 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/27 23:14:47 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:37795 (size: 1192.0 B, free: 1295.4 MB)
13/07/27 23:14:47 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:14:47 INFO local.LocalScheduler: Finished 0
13/07/27 23:14:47 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:14:47 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:14:47 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.201 s
13/07/27 23:14:47 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.246357918 s
res0: Long = 1

scala> 13/07/27 23:14:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:14:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:14:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:14:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:14:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:14:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:14:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:14:47 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100 as mode POSIX_FADV_DONTNEED
offset: 0
length: 55735
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:14:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:14:50 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:33840
Creating SparkContext...
13/07/27 23:14:59 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:14:59 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:14:59 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:14:59 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231459-5ad3
13/07/27 23:14:59 INFO network.ConnectionManager: Bound socket to port 34803 with id = ConnectionManagerId(tachyon-ec2-0,34803)
13/07/27 23:14:59 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:14:59 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:34803 with 1295.4 MB RAM
13/07/27 23:14:59 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:14:59 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:14:59 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55933
13/07/27 23:14:59 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:55933
13/07/27 23:14:59 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:14:59 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-708772b0-ca5b-4a77-b34e-184e4dc8ab07
13/07/27 23:14:59 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:14:59 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59527
13/07/27 23:14:59 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:14:59 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:14:59 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:14:59 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:14:59 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:14:59 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:14:59 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:14:59 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:14:59 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:14:59 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:14:59 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100").cache()
13/07/27 23:15:01 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:15:01 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:15:01 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:15:01 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:15:01 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:15:01 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:15:01 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:15:01 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:15:01 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:15:01 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:15:01 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:15:01 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:15:01 INFO local.LocalTaskSetManager: Size of task 0 is 1488 bytes
13/07/27 23:15:01 INFO local.LocalScheduler: Running 0
13/07/27 23:15:01 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:15:01 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:15:01 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58399, maxMem=1358297825
13/07/27 23:15:01 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/27 23:15:01 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:34803 (size: 113.4 KB, free: 1295.3 MB)
13/07/27 23:15:01 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:15:01 INFO local.LocalScheduler: Finished 0
13/07/27 23:15:01 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:15:01 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:15:01 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.207 s
13/07/27 23:15:01 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.251010411 s
res0: Long = 100

scala> 13/07/27 23:15:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:15:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:15:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:15:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:15:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:15:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:15:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:15:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 776400
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:15:04 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:15:04 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:48799
Creating SparkContext...
13/07/27 23:15:13 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:15:13 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:15:13 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:15:13 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231513-0040
13/07/27 23:15:13 INFO network.ConnectionManager: Bound socket to port 44198 with id = ConnectionManagerId(tachyon-ec2-0,44198)
13/07/27 23:15:13 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:15:13 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:44198 with 1295.4 MB RAM
13/07/27 23:15:13 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:15:13 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:15:13 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:49691
13/07/27 23:15:13 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:49691
13/07/27 23:15:13 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:15:13 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-cb79847f-5088-451c-9df9-2b2a519c1d42
13/07/27 23:15:13 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:15:13 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:56193
13/07/27 23:15:13 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:15:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:15:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:15:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:15:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:15:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:15:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:15:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:15:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:15:13 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:15:13 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1000").cache()
13/07/27 23:15:15 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:15:15 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:15:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:15:15 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:15:15 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:15:15 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:15:15 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:15:15 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:15:15 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:15:15 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:15:15 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:15:15 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:15:15 INFO local.LocalTaskSetManager: Size of task 0 is 1489 bytes
13/07/27 23:15:15 INFO local.LocalScheduler: Running 0
13/07/27 23:15:15 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:15:15 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:15:15 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58399, maxMem=1358297825
13/07/27 23:15:15 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/27 23:15:15 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:44198 (size: 1580.2 KB, free: 1293.8 MB)
13/07/27 23:15:15 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:15:15 INFO local.LocalScheduler: Finished 0
13/07/27 23:15:15 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:15:15 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:15:15 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.240 s
13/07/27 23:15:15 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.285093816 s
res0: Long = 1000

scala> 13/07/27 23:15:15 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:15:15 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:15:15 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:15:15 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:15:15 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:15:15 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:15:15 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:15:15 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.10000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 12330369
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:15:18 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:15:18 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:34660
Creating SparkContext...
13/07/27 23:15:27 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:15:27 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:15:27 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:15:27 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231527-116b
13/07/27 23:15:28 INFO network.ConnectionManager: Bound socket to port 36503 with id = ConnectionManagerId(tachyon-ec2-0,36503)
13/07/27 23:15:28 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:15:28 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:36503 with 1295.4 MB RAM
13/07/27 23:15:28 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:15:28 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:15:28 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:56582
13/07/27 23:15:28 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:56582
13/07/27 23:15:28 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:15:28 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-41e4b9df-2ac1-435f-80ae-f930a31cb0f8
13/07/27 23:15:28 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:15:28 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:46780
13/07/27 23:15:28 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:15:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:15:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:15:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:15:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:15:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:15:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:15:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:15:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:15:28 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:15:28 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.10000").cache()
13/07/27 23:15:29 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:15:29 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:15:29 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:15:29 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:15:29 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:15:29 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:15:29 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:15:29 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:15:29 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:15:29 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:15:29 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:15:29 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:15:30 INFO local.LocalTaskSetManager: Size of task 0 is 1490 bytes
13/07/27 23:15:30 INFO local.LocalScheduler: Running 0
13/07/27 23:15:30 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:15:30 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:15:30 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58399, maxMem=1358297825
13/07/27 23:15:30 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/27 23:15:30 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:36503 (size: 25.0 MB, free: 1270.4 MB)
13/07/27 23:15:30 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:15:30 INFO local.LocalScheduler: Finished 0
13/07/27 23:15:30 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:15:30 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:15:30 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.409 s
13/07/27 23:15:30 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.453525376 s
res0: Long = 10000

scala> 13/07/27 23:15:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:15:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:15:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:15:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:15:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:15:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:15:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:15:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 125141299
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:15:32 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:15:32 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:46542
Creating SparkContext...
13/07/27 23:15:42 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:15:42 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:15:42 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:15:42 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231542-58aa
13/07/27 23:15:42 INFO network.ConnectionManager: Bound socket to port 49311 with id = ConnectionManagerId(tachyon-ec2-0,49311)
13/07/27 23:15:42 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:15:42 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:49311 with 1295.4 MB RAM
13/07/27 23:15:42 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:15:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:15:42 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:44970
13/07/27 23:15:42 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:44970
13/07/27 23:15:42 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:15:42 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-e22390ed-a874-4a16-ad05-0ffcf7cd5532
13/07/27 23:15:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:15:42 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:42833
13/07/27 23:15:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:15:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:15:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:15:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:15:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:15:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:15:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:15:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:15:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:15:42 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:15:42 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100000").cache()
13/07/27 23:15:43 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:15:43 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:15:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:15:44 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:15:44 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:15:44 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:15:44 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:15:44 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:15:44 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:15:44 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:15:44 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:15:44 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:15:44 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:15:44 INFO local.LocalScheduler: Running 0
13/07/27 23:15:44 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:15:44 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:15:44 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:15:44 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:15:44 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:49311 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:15:44 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:15:44 INFO local.LocalScheduler: Finished 0
13/07/27 23:15:44 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:15:44 INFO local.LocalScheduler: Running 1
13/07/27 23:15:44 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:15:44 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:15:44 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:15:45 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:15:45 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:15:45 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:49311 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:15:45 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:15:45 INFO local.LocalScheduler: Finished 1
13/07/27 23:15:45 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:15:45 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:15:45 INFO local.LocalScheduler: Running 2
13/07/27 23:15:45 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:15:45 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:15:45 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:15:45 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:15:45 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:49311 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:15:45 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:15:45 INFO local.LocalScheduler: Finished 2
13/07/27 23:15:45 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:15:45 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:15:45 INFO local.LocalScheduler: Running 3
13/07/27 23:15:45 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:15:45 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:15:45 INFO storage.MemoryStore: ensureFreeSpace(52232232) called with curMem=211087067, maxMem=1358297825
13/07/27 23:15:45 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 49.8 MB, free 1044.3 MB)
13/07/27 23:15:45 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:49311 (size: 49.8 MB, free: 1044.3 MB)
13/07/27 23:15:45 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:15:45 INFO local.LocalScheduler: Finished 3
13/07/27 23:15:45 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:15:45 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:15:45 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.545 s
13/07/27 23:15:45 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.591634765 s
res0: Long = 100002

scala> 13/07/27 23:15:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:15:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:15:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:15:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:15:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:15:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:15:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:15:45 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.500000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 618418417
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:15:48 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:15:48 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:44019
Creating SparkContext...
13/07/27 23:15:57 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:15:57 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:15:57 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:15:57 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231557-8c43
13/07/27 23:15:57 INFO network.ConnectionManager: Bound socket to port 60159 with id = ConnectionManagerId(tachyon-ec2-0,60159)
13/07/27 23:15:57 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:15:57 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:60159 with 1295.4 MB RAM
13/07/27 23:15:57 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:15:57 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:15:57 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:43957
13/07/27 23:15:57 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:43957
13/07/27 23:15:58 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:15:58 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-565ad463-dc1a-4ae4-9d1f-d41d213b7bf4
13/07/27 23:15:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:15:58 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53068
13/07/27 23:15:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:15:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:15:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:15:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:15:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:15:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:15:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:15:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:15:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:15:58 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:15:58 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.500000").cache()
13/07/27 23:15:59 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:15:59 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:15:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:15:59 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:15:59 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:15:59 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:15:59 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:15:59 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:15:59 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:15:59 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:15:59 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:15:59 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:15:59 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:15:59 INFO local.LocalScheduler: Running 0
13/07/27 23:15:59 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:15:59 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:16:00 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:16:00 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:16:00 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:60159 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:16:00 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:16:00 INFO local.LocalScheduler: Finished 0
13/07/27 23:16:00 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:16:00 INFO local.LocalScheduler: Running 1
13/07/27 23:16:00 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:16:00 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:16:00 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:16:00 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:16:00 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:16:00 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:60159 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:16:00 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:16:00 INFO local.LocalScheduler: Finished 1
13/07/27 23:16:00 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:16:00 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:16:00 INFO local.LocalScheduler: Running 2
13/07/27 23:16:00 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:16:00 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:16:01 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:16:01 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:16:01 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:60159 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:16:01 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:16:01 INFO local.LocalScheduler: Finished 2
13/07/27 23:16:01 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:16:01 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:16:01 INFO local.LocalScheduler: Running 3
13/07/27 23:16:01 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:16:01 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:16:01 INFO storage.MemoryStore: ensureFreeSpace(73224723) called with curMem=211087067, maxMem=1358297825
13/07/27 23:16:01 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 69.8 MB, free 1024.2 MB)
13/07/27 23:16:01 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:60159 (size: 69.8 MB, free: 1024.3 MB)
13/07/27 23:16:01 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:16:01 INFO local.LocalScheduler: Finished 3
13/07/27 23:16:01 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:16:01 INFO local.LocalTaskSetManager: Size of task 4 is 1491 bytes
13/07/27 23:16:01 INFO local.LocalScheduler: Running 4
13/07/27 23:16:01 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:16:01 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@695
13/07/27 23:16:01 INFO storage.MemoryStore: ensureFreeSpace(72058182) called with curMem=284311790, maxMem=1358297825
13/07/27 23:16:01 INFO storage.MemoryStore: Block rdd_1_4 stored as values to memory (estimated size 68.7 MB, free 955.5 MB)
13/07/27 23:16:01 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_4 in memory on tachyon-ec2-0:60159 (size: 68.7 MB, free: 955.6 MB)
13/07/27 23:16:01 INFO storage.BlockManagerMaster: Updated info of block rdd_1_4
13/07/27 23:16:01 INFO local.LocalScheduler: Finished 4
13/07/27 23:16:01 INFO scheduler.DAGScheduler: Completed ResultTask(0, 4)
13/07/27 23:16:01 INFO local.LocalTaskSetManager: Size of task 5 is 1491 bytes
13/07/27 23:16:01 INFO local.LocalScheduler: Running 5
13/07/27 23:16:01 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:16:01 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@696
13/07/27 23:16:01 INFO storage.MemoryStore: ensureFreeSpace(69756558) called with curMem=356369972, maxMem=1358297825
13/07/27 23:16:01 INFO storage.MemoryStore: Block rdd_1_5 stored as values to memory (estimated size 66.5 MB, free 889.0 MB)
13/07/27 23:16:01 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_5 in memory on tachyon-ec2-0:60159 (size: 66.5 MB, free: 889.0 MB)
13/07/27 23:16:01 INFO storage.BlockManagerMaster: Updated info of block rdd_1_5
13/07/27 23:16:01 INFO local.LocalScheduler: Finished 5
13/07/27 23:16:01 INFO scheduler.DAGScheduler: Completed ResultTask(0, 5)
13/07/27 23:16:02 INFO local.LocalTaskSetManager: Size of task 6 is 1491 bytes
13/07/27 23:16:02 INFO local.LocalScheduler: Running 6
13/07/27 23:16:02 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:16:02 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@697
13/07/27 23:16:02 INFO storage.MemoryStore: ensureFreeSpace(71337286) called with curMem=426126530, maxMem=1358297825
13/07/27 23:16:02 INFO storage.MemoryStore: Block rdd_1_6 stored as values to memory (estimated size 68.0 MB, free 821.0 MB)
13/07/27 23:16:02 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_6 in memory on tachyon-ec2-0:60159 (size: 68.0 MB, free: 821.0 MB)
13/07/27 23:16:02 INFO storage.BlockManagerMaster: Updated info of block rdd_1_6
13/07/27 23:16:02 INFO local.LocalScheduler: Finished 6
13/07/27 23:16:02 INFO scheduler.DAGScheduler: Completed ResultTask(0, 6)
13/07/27 23:16:02 INFO local.LocalTaskSetManager: Size of task 7 is 1491 bytes
13/07/27 23:16:02 INFO local.LocalScheduler: Running 7
13/07/27 23:16:02 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:16:02 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@698
13/07/27 23:16:02 INFO storage.MemoryStore: ensureFreeSpace(71927110) called with curMem=497463816, maxMem=1358297825
13/07/27 23:16:02 INFO storage.MemoryStore: Block rdd_1_7 stored as values to memory (estimated size 68.6 MB, free 752.4 MB)
13/07/27 23:16:02 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_7 in memory on tachyon-ec2-0:60159 (size: 68.6 MB, free: 752.4 MB)
13/07/27 23:16:02 INFO storage.BlockManagerMaster: Updated info of block rdd_1_7
13/07/27 23:16:02 INFO local.LocalScheduler: Finished 7
13/07/27 23:16:02 INFO scheduler.DAGScheduler: Completed ResultTask(0, 7)
13/07/27 23:16:02 INFO local.LocalTaskSetManager: Size of task 8 is 1491 bytes
13/07/27 23:16:02 INFO local.LocalScheduler: Running 8
13/07/27 23:16:02 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:16:02 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@699
13/07/27 23:16:02 INFO storage.MemoryStore: ensureFreeSpace(68354088) called with curMem=569390926, maxMem=1358297825
13/07/27 23:16:02 INFO storage.MemoryStore: Block rdd_1_8 stored as values to memory (estimated size 65.2 MB, free 687.2 MB)
13/07/27 23:16:02 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_8 in memory on tachyon-ec2-0:60159 (size: 65.2 MB, free: 687.2 MB)
13/07/27 23:16:02 INFO storage.BlockManagerMaster: Updated info of block rdd_1_8
13/07/27 23:16:02 INFO local.LocalScheduler: Finished 8
13/07/27 23:16:02 INFO scheduler.DAGScheduler: Completed ResultTask(0, 8)
13/07/27 23:16:02 INFO local.LocalTaskSetManager: Size of task 9 is 1491 bytes
13/07/27 23:16:02 INFO local.LocalScheduler: Running 9
13/07/27 23:16:02 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:16:02 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69a
13/07/27 23:16:03 INFO storage.MemoryStore: ensureFreeSpace(72189254) called with curMem=637745014, maxMem=1358297825
13/07/27 23:16:03 INFO storage.MemoryStore: Block rdd_1_9 stored as values to memory (estimated size 68.8 MB, free 618.3 MB)
13/07/27 23:16:03 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_9 in memory on tachyon-ec2-0:60159 (size: 68.8 MB, free: 618.4 MB)
13/07/27 23:16:03 INFO storage.BlockManagerMaster: Updated info of block rdd_1_9
13/07/27 23:16:03 INFO local.LocalScheduler: Finished 9
13/07/27 23:16:03 INFO scheduler.DAGScheduler: Completed ResultTask(0, 9)
13/07/27 23:16:03 INFO local.LocalTaskSetManager: Size of task 10 is 1491 bytes
13/07/27 23:16:03 INFO local.LocalScheduler: Running 10
13/07/27 23:16:03 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:16:03 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69b
13/07/27 23:16:03 INFO storage.MemoryStore: ensureFreeSpace(69900737) called with curMem=709934268, maxMem=1358297825
13/07/27 23:16:03 INFO storage.MemoryStore: Block rdd_1_10 stored as values to memory (estimated size 66.7 MB, free 551.7 MB)
13/07/27 23:16:03 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_10 in memory on tachyon-ec2-0:60159 (size: 66.7 MB, free: 551.7 MB)
13/07/27 23:16:03 INFO storage.BlockManagerMaster: Updated info of block rdd_1_10
13/07/27 23:16:03 INFO local.LocalScheduler: Finished 10
13/07/27 23:16:03 INFO scheduler.DAGScheduler: Completed ResultTask(0, 10)
13/07/27 23:16:03 INFO local.LocalTaskSetManager: Size of task 11 is 1491 bytes
13/07/27 23:16:03 INFO local.LocalScheduler: Running 11
13/07/27 23:16:03 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:16:03 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69c
13/07/27 23:16:03 INFO storage.MemoryStore: ensureFreeSpace(71945460) called with curMem=779835005, maxMem=1358297825
13/07/27 23:16:03 INFO storage.MemoryStore: Block rdd_1_11 stored as values to memory (estimated size 68.6 MB, free 483.1 MB)
13/07/27 23:16:03 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_11 in memory on tachyon-ec2-0:60159 (size: 68.6 MB, free: 483.1 MB)
13/07/27 23:16:03 INFO storage.BlockManagerMaster: Updated info of block rdd_1_11
13/07/27 23:16:03 INFO local.LocalScheduler: Finished 11
13/07/27 23:16:03 INFO scheduler.DAGScheduler: Completed ResultTask(0, 11)
13/07/27 23:16:03 INFO local.LocalTaskSetManager: Size of task 12 is 1491 bytes
13/07/27 23:16:03 INFO local.LocalScheduler: Running 12
13/07/27 23:16:03 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:16:03 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69d
13/07/27 23:16:03 INFO storage.MemoryStore: ensureFreeSpace(71937596) called with curMem=851780465, maxMem=1358297825
13/07/27 23:16:03 INFO storage.MemoryStore: Block rdd_1_12 stored as values to memory (estimated size 68.6 MB, free 414.4 MB)
13/07/27 23:16:03 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_12 in memory on tachyon-ec2-0:60159 (size: 68.6 MB, free: 414.5 MB)
13/07/27 23:16:03 INFO storage.BlockManagerMaster: Updated info of block rdd_1_12
13/07/27 23:16:03 INFO local.LocalScheduler: Finished 12
13/07/27 23:16:03 INFO scheduler.DAGScheduler: Completed ResultTask(0, 12)
13/07/27 23:16:03 INFO local.LocalTaskSetManager: Size of task 13 is 1491 bytes
13/07/27 23:16:03 INFO local.LocalScheduler: Running 13
13/07/27 23:16:03 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:16:03 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69e
13/07/27 23:16:05 INFO storage.MemoryStore: ensureFreeSpace(72915393) called with curMem=923718061, maxMem=1358297825
13/07/27 23:16:05 INFO storage.MemoryStore: Block rdd_1_13 stored as values to memory (estimated size 69.5 MB, free 344.9 MB)
13/07/27 23:16:05 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_13 in memory on tachyon-ec2-0:60159 (size: 69.5 MB, free: 345.0 MB)
13/07/27 23:16:05 INFO storage.BlockManagerMaster: Updated info of block rdd_1_13
13/07/27 23:16:05 INFO local.LocalScheduler: Finished 13
13/07/27 23:16:05 INFO scheduler.DAGScheduler: Completed ResultTask(0, 13)
13/07/27 23:16:05 INFO local.LocalTaskSetManager: Size of task 14 is 1491 bytes
13/07/27 23:16:05 INFO local.LocalScheduler: Running 14
13/07/27 23:16:05 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:16:05 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69f
13/07/27 23:16:05 INFO storage.MemoryStore: ensureFreeSpace(71974296) called with curMem=996633454, maxMem=1358297825
13/07/27 23:16:05 INFO storage.MemoryStore: Block rdd_1_14 stored as values to memory (estimated size 68.6 MB, free 276.3 MB)
13/07/27 23:16:05 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_14 in memory on tachyon-ec2-0:60159 (size: 68.6 MB, free: 276.3 MB)
13/07/27 23:16:05 INFO storage.BlockManagerMaster: Updated info of block rdd_1_14
13/07/27 23:16:05 INFO local.LocalScheduler: Finished 14
13/07/27 23:16:05 INFO scheduler.DAGScheduler: Completed ResultTask(0, 14)
13/07/27 23:16:05 INFO local.LocalTaskSetManager: Size of task 15 is 1491 bytes
13/07/27 23:16:05 INFO local.LocalScheduler: Running 15
13/07/27 23:16:05 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:16:05 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a0
13/07/27 23:16:05 INFO storage.MemoryStore: ensureFreeSpace(71051549) called with curMem=1068607750, maxMem=1358297825
13/07/27 23:16:05 INFO storage.MemoryStore: Block rdd_1_15 stored as values to memory (estimated size 67.8 MB, free 208.5 MB)
13/07/27 23:16:05 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_15 in memory on tachyon-ec2-0:60159 (size: 67.8 MB, free: 208.6 MB)
13/07/27 23:16:05 INFO storage.BlockManagerMaster: Updated info of block rdd_1_15
13/07/27 23:16:05 INFO local.LocalScheduler: Finished 15
13/07/27 23:16:05 INFO scheduler.DAGScheduler: Completed ResultTask(0, 15)
13/07/27 23:16:05 INFO local.LocalTaskSetManager: Size of task 16 is 1491 bytes
13/07/27 23:16:05 INFO local.LocalScheduler: Running 16
13/07/27 23:16:05 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:16:05 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a1
13/07/27 23:16:05 INFO storage.MemoryStore: ensureFreeSpace(71565352) called with curMem=1139659299, maxMem=1358297825
13/07/27 23:16:05 INFO storage.MemoryStore: Block rdd_1_16 stored as values to memory (estimated size 68.3 MB, free 140.3 MB)
13/07/27 23:16:05 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_16 in memory on tachyon-ec2-0:60159 (size: 68.3 MB, free: 140.3 MB)
13/07/27 23:16:05 INFO storage.BlockManagerMaster: Updated info of block rdd_1_16
13/07/27 23:16:05 INFO local.LocalScheduler: Finished 16
13/07/27 23:16:05 INFO scheduler.DAGScheduler: Completed ResultTask(0, 16)
13/07/27 23:16:05 INFO local.LocalTaskSetManager: Size of task 17 is 1491 bytes
13/07/27 23:16:05 INFO local.LocalScheduler: Running 17
13/07/27 23:16:05 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:16:05 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a2
13/07/27 23:16:06 INFO storage.MemoryStore: ensureFreeSpace(72682085) called with curMem=1211224651, maxMem=1358297825
13/07/27 23:16:06 INFO storage.MemoryStore: Block rdd_1_17 stored as values to memory (estimated size 69.3 MB, free 70.9 MB)
13/07/27 23:16:06 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_17 in memory on tachyon-ec2-0:60159 (size: 69.3 MB, free: 71.0 MB)
13/07/27 23:16:06 INFO storage.BlockManagerMaster: Updated info of block rdd_1_17
13/07/27 23:16:06 INFO local.LocalScheduler: Finished 17
13/07/27 23:16:06 INFO scheduler.DAGScheduler: Completed ResultTask(0, 17)
13/07/27 23:16:06 INFO local.LocalTaskSetManager: Size of task 18 is 1491 bytes
13/07/27 23:16:06 INFO local.LocalScheduler: Running 18
13/07/27 23:16:06 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:16:06 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a3
13/07/27 23:16:06 INFO storage.MemoryStore: ensureFreeSpace(30062713) called with curMem=1283906736, maxMem=1358297825
13/07/27 23:16:06 INFO storage.MemoryStore: Block rdd_1_18 stored as values to memory (estimated size 28.7 MB, free 42.3 MB)
13/07/27 23:16:06 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_18 in memory on tachyon-ec2-0:60159 (size: 28.7 MB, free: 42.3 MB)
13/07/27 23:16:06 INFO storage.BlockManagerMaster: Updated info of block rdd_1_18
13/07/27 23:16:06 INFO local.LocalScheduler: Finished 18
13/07/27 23:16:06 INFO scheduler.DAGScheduler: Completed ResultTask(0, 18)
13/07/27 23:16:06 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:16:06 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 6.678 s
13/07/27 23:16:06 INFO spark.SparkContext: Job finished: count at <console>:15, took 6.729956989 s
res0: Long = 500094

scala> 13/07/27 23:16:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:16:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:16:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:16:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:16:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:16:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:16:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:16:06 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 5

spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1 as mode POSIX_FADV_DONTNEED
offset: 0
length: 525
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:16:09 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:16:09 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:51581
Creating SparkContext...
13/07/27 23:16:18 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:16:18 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:16:18 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:16:18 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231618-8e72
13/07/27 23:16:18 INFO network.ConnectionManager: Bound socket to port 47280 with id = ConnectionManagerId(tachyon-ec2-0,47280)
13/07/27 23:16:18 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:16:18 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:47280 with 1295.4 MB RAM
13/07/27 23:16:18 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:16:18 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:16:18 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60176
13/07/27 23:16:18 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:60176
13/07/27 23:16:18 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:16:18 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-69807575-403e-44aa-9ab7-0b028add3088
13/07/27 23:16:18 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:16:18 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:40476
13/07/27 23:16:18 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:16:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:16:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:16:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:16:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:16:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:16:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:16:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:16:18 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:16:18 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:16:18 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1").cache()
13/07/27 23:16:20 INFO storage.MemoryStore: ensureFreeSpace(58391) called with curMem=0, maxMem=1358297825
13/07/27 23:16:20 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:16:20 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:16:20 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:16:20 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:16:20 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:16:20 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:16:20 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:16:20 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:16:20 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:16:20 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:16:20 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:16:20 INFO local.LocalTaskSetManager: Size of task 0 is 1486 bytes
13/07/27 23:16:20 INFO local.LocalScheduler: Running 0
13/07/27 23:16:20 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:16:20 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:16:20 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58391, maxMem=1358297825
13/07/27 23:16:20 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/27 23:16:20 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:47280 (size: 1192.0 B, free: 1295.4 MB)
13/07/27 23:16:20 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:16:20 INFO local.LocalScheduler: Finished 0
13/07/27 23:16:20 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:16:20 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:16:20 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.211 s
13/07/27 23:16:20 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.256052473 s
res0: Long = 1

scala> 13/07/27 23:16:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:16:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:16:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:16:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:16:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:16:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:16:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:16:20 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100 as mode POSIX_FADV_DONTNEED
offset: 0
length: 55735
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:16:23 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:16:23 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:57898
Creating SparkContext...
13/07/27 23:16:32 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:16:32 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:16:32 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:16:32 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231632-3c42
13/07/27 23:16:32 INFO network.ConnectionManager: Bound socket to port 54568 with id = ConnectionManagerId(tachyon-ec2-0,54568)
13/07/27 23:16:32 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:16:32 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:54568 with 1295.4 MB RAM
13/07/27 23:16:32 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:16:32 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:16:32 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:48715
13/07/27 23:16:32 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:48715
13/07/27 23:16:32 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:16:32 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-1c20f388-7fa0-494d-bfef-3eff89878f85
13/07/27 23:16:32 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:16:32 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55738
13/07/27 23:16:32 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:16:32 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:16:32 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:16:32 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:16:32 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:16:32 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:16:32 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:16:32 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:16:32 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:16:32 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:16:32 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100").cache()
13/07/27 23:16:34 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:16:34 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:16:34 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:16:34 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:16:34 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:16:34 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:16:34 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:16:34 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:16:34 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:16:34 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:16:34 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:16:34 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:16:34 INFO local.LocalTaskSetManager: Size of task 0 is 1488 bytes
13/07/27 23:16:34 INFO local.LocalScheduler: Running 0
13/07/27 23:16:34 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:16:34 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:16:34 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58399, maxMem=1358297825
13/07/27 23:16:34 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/27 23:16:34 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:54568 (size: 113.4 KB, free: 1295.3 MB)
13/07/27 23:16:34 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:16:34 INFO local.LocalScheduler: Finished 0
13/07/27 23:16:34 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:16:34 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:16:34 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.217 s
13/07/27 23:16:34 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.261685308 s
res0: Long = 100

scala> 13/07/27 23:16:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:16:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:16:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:16:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:16:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:16:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:16:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:16:35 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 776400
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:16:37 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:16:37 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:43453
Creating SparkContext...
13/07/27 23:16:46 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:16:46 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:16:46 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:16:46 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231646-2b04
13/07/27 23:16:47 INFO network.ConnectionManager: Bound socket to port 54345 with id = ConnectionManagerId(tachyon-ec2-0,54345)
13/07/27 23:16:47 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:16:47 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:54345 with 1295.4 MB RAM
13/07/27 23:16:47 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:16:47 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:16:47 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:54737
13/07/27 23:16:47 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:54737
13/07/27 23:16:47 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:16:47 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-2105f765-da01-46f1-a22e-2e3be8116361
13/07/27 23:16:47 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:16:47 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59427
13/07/27 23:16:47 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:16:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:16:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:16:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:16:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:16:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:16:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:16:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:16:47 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:16:47 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:16:47 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1000").cache()
13/07/27 23:16:48 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:16:48 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:16:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:16:48 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:16:48 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:16:48 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:16:48 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:16:48 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:16:48 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:16:48 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:16:48 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:16:48 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:16:48 INFO local.LocalTaskSetManager: Size of task 0 is 1489 bytes
13/07/27 23:16:48 INFO local.LocalScheduler: Running 0
13/07/27 23:16:48 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:16:48 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:16:49 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58399, maxMem=1358297825
13/07/27 23:16:49 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/27 23:16:49 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:54345 (size: 1580.2 KB, free: 1293.8 MB)
13/07/27 23:16:49 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:16:49 INFO local.LocalScheduler: Finished 0
13/07/27 23:16:49 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:16:49 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:16:49 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.243 s
13/07/27 23:16:49 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.28757436 s
res0: Long = 1000

scala> 13/07/27 23:16:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:16:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:16:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:16:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:16:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:16:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:16:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:16:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.10000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 12330369
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:16:51 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:16:51 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:36508
Creating SparkContext...
13/07/27 23:17:00 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:17:01 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:17:01 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:17:01 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231701-37b4
13/07/27 23:17:01 INFO network.ConnectionManager: Bound socket to port 38219 with id = ConnectionManagerId(tachyon-ec2-0,38219)
13/07/27 23:17:01 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:17:01 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:38219 with 1295.4 MB RAM
13/07/27 23:17:01 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:17:01 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:17:01 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:56442
13/07/27 23:17:01 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:56442
13/07/27 23:17:01 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:17:01 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-e83eec05-3b4d-4936-a441-4630b5ac2105
13/07/27 23:17:01 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:17:01 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55966
13/07/27 23:17:01 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:17:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:17:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:17:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:17:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:17:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:17:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:17:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:17:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:17:01 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:17:01 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.10000").cache()
13/07/27 23:17:02 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:17:02 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:17:02 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:17:02 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:17:02 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:17:02 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:17:02 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:17:02 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:17:02 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:17:02 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:17:02 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:17:02 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:17:03 INFO local.LocalTaskSetManager: Size of task 0 is 1490 bytes
13/07/27 23:17:03 INFO local.LocalScheduler: Running 0
13/07/27 23:17:03 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:17:03 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:17:03 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58399, maxMem=1358297825
13/07/27 23:17:03 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/27 23:17:03 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:38219 (size: 25.0 MB, free: 1270.4 MB)
13/07/27 23:17:03 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:17:03 INFO local.LocalScheduler: Finished 0
13/07/27 23:17:03 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:17:03 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:17:03 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.445 s
13/07/27 23:17:03 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.490708553 s
res0: Long = 10000

scala> 13/07/27 23:17:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:17:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:17:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:17:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:17:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:17:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:17:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:17:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 125141299
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:17:05 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:17:06 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:51515
Creating SparkContext...
13/07/27 23:17:15 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:17:15 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:17:15 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:17:15 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231715-d788
13/07/27 23:17:15 INFO network.ConnectionManager: Bound socket to port 41450 with id = ConnectionManagerId(tachyon-ec2-0,41450)
13/07/27 23:17:15 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:17:15 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:41450 with 1295.4 MB RAM
13/07/27 23:17:15 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:17:15 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:17:15 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:35541
13/07/27 23:17:15 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:35541
13/07/27 23:17:15 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:17:15 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-cf1c2bf8-1ec2-49d5-af66-378de9461cc7
13/07/27 23:17:15 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:17:15 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:51530
13/07/27 23:17:15 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:17:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:17:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:17:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:17:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:17:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:17:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:17:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:17:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:17:15 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:17:15 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100000").cache()
13/07/27 23:17:17 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:17:17 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:17:17 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:17:17 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:17:17 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:17:17 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:17:17 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:17:17 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:17:17 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:17:17 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:17:17 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:17:17 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:17:17 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:17:17 INFO local.LocalScheduler: Running 0
13/07/27 23:17:17 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:17:17 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:17:18 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:17:18 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:17:18 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:41450 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:17:18 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:17:18 INFO local.LocalScheduler: Finished 0
13/07/27 23:17:18 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:17:18 INFO local.LocalScheduler: Running 1
13/07/27 23:17:18 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:17:18 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:17:18 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:17:18 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:17:18 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:17:18 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:41450 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:17:18 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:17:18 INFO local.LocalScheduler: Finished 1
13/07/27 23:17:18 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:17:18 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:17:18 INFO local.LocalScheduler: Running 2
13/07/27 23:17:18 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:17:18 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:17:18 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:17:18 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:17:18 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:41450 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:17:18 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:17:18 INFO local.LocalScheduler: Finished 2
13/07/27 23:17:18 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:17:18 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:17:18 INFO local.LocalScheduler: Running 3
13/07/27 23:17:18 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:17:18 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:17:19 INFO storage.MemoryStore: ensureFreeSpace(52232232) called with curMem=211087067, maxMem=1358297825
13/07/27 23:17:19 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 49.8 MB, free 1044.3 MB)
13/07/27 23:17:19 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:41450 (size: 49.8 MB, free: 1044.3 MB)
13/07/27 23:17:19 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:17:19 INFO local.LocalScheduler: Finished 3
13/07/27 23:17:19 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:17:19 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:17:19 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.578 s
13/07/27 23:17:19 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.62466011 s
res0: Long = 100002

scala> 13/07/27 23:17:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:17:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:17:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:17:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:17:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:17:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:17:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:17:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.500000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 618418417
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:17:21 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:17:21 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59100
Creating SparkContext...
13/07/27 23:17:31 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:17:31 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:17:31 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:17:31 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231731-2c3f
13/07/27 23:17:31 INFO network.ConnectionManager: Bound socket to port 38074 with id = ConnectionManagerId(tachyon-ec2-0,38074)
13/07/27 23:17:31 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:17:31 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:38074 with 1295.4 MB RAM
13/07/27 23:17:31 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:17:31 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:17:31 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:48186
13/07/27 23:17:31 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:48186
13/07/27 23:17:31 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:17:31 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-7c5c3196-dacc-4a8c-9831-1653b98948a9
13/07/27 23:17:31 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:17:31 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:40853
13/07/27 23:17:31 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:17:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:17:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:17:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:17:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:17:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:17:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:17:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:17:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:17:31 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:17:31 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.500000").cache()
13/07/27 23:17:32 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:17:32 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:17:33 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:17:33 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:17:33 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:17:33 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:17:33 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:17:33 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:17:33 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:17:33 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:17:33 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:17:33 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:17:33 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:17:33 INFO local.LocalScheduler: Running 0
13/07/27 23:17:33 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:17:33 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:17:33 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:17:33 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:17:33 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:38074 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:17:33 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:17:33 INFO local.LocalScheduler: Finished 0
13/07/27 23:17:33 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:17:33 INFO local.LocalScheduler: Running 1
13/07/27 23:17:33 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:17:33 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:17:33 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:17:34 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:17:34 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:17:34 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:38074 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:17:34 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:17:34 INFO local.LocalScheduler: Finished 1
13/07/27 23:17:34 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:17:34 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:17:34 INFO local.LocalScheduler: Running 2
13/07/27 23:17:34 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:17:34 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:17:34 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:17:34 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:17:34 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:38074 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:17:34 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:17:34 INFO local.LocalScheduler: Finished 2
13/07/27 23:17:34 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:17:34 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:17:34 INFO local.LocalScheduler: Running 3
13/07/27 23:17:34 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:17:34 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:17:34 INFO storage.MemoryStore: ensureFreeSpace(73224723) called with curMem=211087067, maxMem=1358297825
13/07/27 23:17:34 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 69.8 MB, free 1024.2 MB)
13/07/27 23:17:34 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:38074 (size: 69.8 MB, free: 1024.3 MB)
13/07/27 23:17:34 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:17:34 INFO local.LocalScheduler: Finished 3
13/07/27 23:17:34 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:17:34 INFO local.LocalTaskSetManager: Size of task 4 is 1491 bytes
13/07/27 23:17:34 INFO local.LocalScheduler: Running 4
13/07/27 23:17:34 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:17:34 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@695
13/07/27 23:17:35 INFO storage.MemoryStore: ensureFreeSpace(72058182) called with curMem=284311790, maxMem=1358297825
13/07/27 23:17:35 INFO storage.MemoryStore: Block rdd_1_4 stored as values to memory (estimated size 68.7 MB, free 955.5 MB)
13/07/27 23:17:35 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_4 in memory on tachyon-ec2-0:38074 (size: 68.7 MB, free: 955.6 MB)
13/07/27 23:17:35 INFO storage.BlockManagerMaster: Updated info of block rdd_1_4
13/07/27 23:17:35 INFO local.LocalScheduler: Finished 4
13/07/27 23:17:35 INFO scheduler.DAGScheduler: Completed ResultTask(0, 4)
13/07/27 23:17:35 INFO local.LocalTaskSetManager: Size of task 5 is 1491 bytes
13/07/27 23:17:35 INFO local.LocalScheduler: Running 5
13/07/27 23:17:35 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:17:35 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@696
13/07/27 23:17:35 INFO storage.MemoryStore: ensureFreeSpace(69756558) called with curMem=356369972, maxMem=1358297825
13/07/27 23:17:35 INFO storage.MemoryStore: Block rdd_1_5 stored as values to memory (estimated size 66.5 MB, free 889.0 MB)
13/07/27 23:17:35 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_5 in memory on tachyon-ec2-0:38074 (size: 66.5 MB, free: 889.0 MB)
13/07/27 23:17:35 INFO storage.BlockManagerMaster: Updated info of block rdd_1_5
13/07/27 23:17:35 INFO local.LocalScheduler: Finished 5
13/07/27 23:17:35 INFO scheduler.DAGScheduler: Completed ResultTask(0, 5)
13/07/27 23:17:35 INFO local.LocalTaskSetManager: Size of task 6 is 1491 bytes
13/07/27 23:17:35 INFO local.LocalScheduler: Running 6
13/07/27 23:17:35 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:17:35 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@697
13/07/27 23:17:35 INFO storage.MemoryStore: ensureFreeSpace(71337286) called with curMem=426126530, maxMem=1358297825
13/07/27 23:17:35 INFO storage.MemoryStore: Block rdd_1_6 stored as values to memory (estimated size 68.0 MB, free 821.0 MB)
13/07/27 23:17:35 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_6 in memory on tachyon-ec2-0:38074 (size: 68.0 MB, free: 821.0 MB)
13/07/27 23:17:35 INFO storage.BlockManagerMaster: Updated info of block rdd_1_6
13/07/27 23:17:35 INFO local.LocalScheduler: Finished 6
13/07/27 23:17:35 INFO scheduler.DAGScheduler: Completed ResultTask(0, 6)
13/07/27 23:17:35 INFO local.LocalTaskSetManager: Size of task 7 is 1491 bytes
13/07/27 23:17:35 INFO local.LocalScheduler: Running 7
13/07/27 23:17:35 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:17:35 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@698
13/07/27 23:17:36 INFO storage.MemoryStore: ensureFreeSpace(71927110) called with curMem=497463816, maxMem=1358297825
13/07/27 23:17:36 INFO storage.MemoryStore: Block rdd_1_7 stored as values to memory (estimated size 68.6 MB, free 752.4 MB)
13/07/27 23:17:36 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_7 in memory on tachyon-ec2-0:38074 (size: 68.6 MB, free: 752.4 MB)
13/07/27 23:17:36 INFO storage.BlockManagerMaster: Updated info of block rdd_1_7
13/07/27 23:17:36 INFO local.LocalScheduler: Finished 7
13/07/27 23:17:36 INFO scheduler.DAGScheduler: Completed ResultTask(0, 7)
13/07/27 23:17:36 INFO local.LocalTaskSetManager: Size of task 8 is 1491 bytes
13/07/27 23:17:36 INFO local.LocalScheduler: Running 8
13/07/27 23:17:36 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:17:36 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@699
13/07/27 23:17:36 INFO storage.MemoryStore: ensureFreeSpace(68354088) called with curMem=569390926, maxMem=1358297825
13/07/27 23:17:36 INFO storage.MemoryStore: Block rdd_1_8 stored as values to memory (estimated size 65.2 MB, free 687.2 MB)
13/07/27 23:17:36 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_8 in memory on tachyon-ec2-0:38074 (size: 65.2 MB, free: 687.2 MB)
13/07/27 23:17:36 INFO storage.BlockManagerMaster: Updated info of block rdd_1_8
13/07/27 23:17:36 INFO local.LocalScheduler: Finished 8
13/07/27 23:17:36 INFO scheduler.DAGScheduler: Completed ResultTask(0, 8)
13/07/27 23:17:36 INFO local.LocalTaskSetManager: Size of task 9 is 1491 bytes
13/07/27 23:17:36 INFO local.LocalScheduler: Running 9
13/07/27 23:17:36 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:17:36 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69a
13/07/27 23:17:36 INFO storage.MemoryStore: ensureFreeSpace(72189254) called with curMem=637745014, maxMem=1358297825
13/07/27 23:17:36 INFO storage.MemoryStore: Block rdd_1_9 stored as values to memory (estimated size 68.8 MB, free 618.3 MB)
13/07/27 23:17:36 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_9 in memory on tachyon-ec2-0:38074 (size: 68.8 MB, free: 618.4 MB)
13/07/27 23:17:36 INFO storage.BlockManagerMaster: Updated info of block rdd_1_9
13/07/27 23:17:36 INFO local.LocalScheduler: Finished 9
13/07/27 23:17:36 INFO scheduler.DAGScheduler: Completed ResultTask(0, 9)
13/07/27 23:17:36 INFO local.LocalTaskSetManager: Size of task 10 is 1491 bytes
13/07/27 23:17:36 INFO local.LocalScheduler: Running 10
13/07/27 23:17:36 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:17:36 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69b
13/07/27 23:17:37 INFO storage.MemoryStore: ensureFreeSpace(69900737) called with curMem=709934268, maxMem=1358297825
13/07/27 23:17:37 INFO storage.MemoryStore: Block rdd_1_10 stored as values to memory (estimated size 66.7 MB, free 551.7 MB)
13/07/27 23:17:37 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_10 in memory on tachyon-ec2-0:38074 (size: 66.7 MB, free: 551.7 MB)
13/07/27 23:17:37 INFO storage.BlockManagerMaster: Updated info of block rdd_1_10
13/07/27 23:17:37 INFO local.LocalScheduler: Finished 10
13/07/27 23:17:37 INFO scheduler.DAGScheduler: Completed ResultTask(0, 10)
13/07/27 23:17:37 INFO local.LocalTaskSetManager: Size of task 11 is 1491 bytes
13/07/27 23:17:37 INFO local.LocalScheduler: Running 11
13/07/27 23:17:37 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:17:37 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69c
13/07/27 23:17:37 INFO storage.MemoryStore: ensureFreeSpace(71945460) called with curMem=779835005, maxMem=1358297825
13/07/27 23:17:37 INFO storage.MemoryStore: Block rdd_1_11 stored as values to memory (estimated size 68.6 MB, free 483.1 MB)
13/07/27 23:17:37 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_11 in memory on tachyon-ec2-0:38074 (size: 68.6 MB, free: 483.1 MB)
13/07/27 23:17:37 INFO storage.BlockManagerMaster: Updated info of block rdd_1_11
13/07/27 23:17:37 INFO local.LocalScheduler: Finished 11
13/07/27 23:17:37 INFO scheduler.DAGScheduler: Completed ResultTask(0, 11)
13/07/27 23:17:37 INFO local.LocalTaskSetManager: Size of task 12 is 1491 bytes
13/07/27 23:17:37 INFO local.LocalScheduler: Running 12
13/07/27 23:17:37 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:17:37 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69d
13/07/27 23:17:38 INFO storage.MemoryStore: ensureFreeSpace(71937596) called with curMem=851780465, maxMem=1358297825
13/07/27 23:17:38 INFO storage.MemoryStore: Block rdd_1_12 stored as values to memory (estimated size 68.6 MB, free 414.4 MB)
13/07/27 23:17:38 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_12 in memory on tachyon-ec2-0:38074 (size: 68.6 MB, free: 414.5 MB)
13/07/27 23:17:38 INFO storage.BlockManagerMaster: Updated info of block rdd_1_12
13/07/27 23:17:38 INFO local.LocalScheduler: Finished 12
13/07/27 23:17:38 INFO scheduler.DAGScheduler: Completed ResultTask(0, 12)
13/07/27 23:17:38 INFO local.LocalTaskSetManager: Size of task 13 is 1491 bytes
13/07/27 23:17:38 INFO local.LocalScheduler: Running 13
13/07/27 23:17:38 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:17:38 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69e
13/07/27 23:17:39 INFO storage.MemoryStore: ensureFreeSpace(72915393) called with curMem=923718061, maxMem=1358297825
13/07/27 23:17:39 INFO storage.MemoryStore: Block rdd_1_13 stored as values to memory (estimated size 69.5 MB, free 344.9 MB)
13/07/27 23:17:39 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_13 in memory on tachyon-ec2-0:38074 (size: 69.5 MB, free: 345.0 MB)
13/07/27 23:17:39 INFO storage.BlockManagerMaster: Updated info of block rdd_1_13
13/07/27 23:17:39 INFO local.LocalScheduler: Finished 13
13/07/27 23:17:39 INFO scheduler.DAGScheduler: Completed ResultTask(0, 13)
13/07/27 23:17:39 INFO local.LocalTaskSetManager: Size of task 14 is 1491 bytes
13/07/27 23:17:39 INFO local.LocalScheduler: Running 14
13/07/27 23:17:39 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:17:39 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69f
13/07/27 23:17:39 INFO storage.MemoryStore: ensureFreeSpace(71974296) called with curMem=996633454, maxMem=1358297825
13/07/27 23:17:39 INFO storage.MemoryStore: Block rdd_1_14 stored as values to memory (estimated size 68.6 MB, free 276.3 MB)
13/07/27 23:17:39 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_14 in memory on tachyon-ec2-0:38074 (size: 68.6 MB, free: 276.3 MB)
13/07/27 23:17:39 INFO storage.BlockManagerMaster: Updated info of block rdd_1_14
13/07/27 23:17:39 INFO local.LocalScheduler: Finished 14
13/07/27 23:17:39 INFO scheduler.DAGScheduler: Completed ResultTask(0, 14)
13/07/27 23:17:39 INFO local.LocalTaskSetManager: Size of task 15 is 1491 bytes
13/07/27 23:17:39 INFO local.LocalScheduler: Running 15
13/07/27 23:17:39 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:17:39 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a0
13/07/27 23:17:39 INFO storage.MemoryStore: ensureFreeSpace(71051549) called with curMem=1068607750, maxMem=1358297825
13/07/27 23:17:39 INFO storage.MemoryStore: Block rdd_1_15 stored as values to memory (estimated size 67.8 MB, free 208.5 MB)
13/07/27 23:17:39 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_15 in memory on tachyon-ec2-0:38074 (size: 67.8 MB, free: 208.6 MB)
13/07/27 23:17:39 INFO storage.BlockManagerMaster: Updated info of block rdd_1_15
13/07/27 23:17:39 INFO local.LocalScheduler: Finished 15
13/07/27 23:17:39 INFO scheduler.DAGScheduler: Completed ResultTask(0, 15)
13/07/27 23:17:39 INFO local.LocalTaskSetManager: Size of task 16 is 1491 bytes
13/07/27 23:17:39 INFO local.LocalScheduler: Running 16
13/07/27 23:17:39 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:17:39 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a1
13/07/27 23:17:40 INFO storage.MemoryStore: ensureFreeSpace(71565352) called with curMem=1139659299, maxMem=1358297825
13/07/27 23:17:40 INFO storage.MemoryStore: Block rdd_1_16 stored as values to memory (estimated size 68.3 MB, free 140.3 MB)
13/07/27 23:17:40 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_16 in memory on tachyon-ec2-0:38074 (size: 68.3 MB, free: 140.3 MB)
13/07/27 23:17:40 INFO storage.BlockManagerMaster: Updated info of block rdd_1_16
13/07/27 23:17:40 INFO local.LocalScheduler: Finished 16
13/07/27 23:17:40 INFO scheduler.DAGScheduler: Completed ResultTask(0, 16)
13/07/27 23:17:40 INFO local.LocalTaskSetManager: Size of task 17 is 1491 bytes
13/07/27 23:17:40 INFO local.LocalScheduler: Running 17
13/07/27 23:17:40 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:17:40 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a2
13/07/27 23:17:40 INFO storage.MemoryStore: ensureFreeSpace(72682085) called with curMem=1211224651, maxMem=1358297825
13/07/27 23:17:40 INFO storage.MemoryStore: Block rdd_1_17 stored as values to memory (estimated size 69.3 MB, free 70.9 MB)
13/07/27 23:17:40 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_17 in memory on tachyon-ec2-0:38074 (size: 69.3 MB, free: 71.0 MB)
13/07/27 23:17:40 INFO storage.BlockManagerMaster: Updated info of block rdd_1_17
13/07/27 23:17:40 INFO local.LocalScheduler: Finished 17
13/07/27 23:17:40 INFO scheduler.DAGScheduler: Completed ResultTask(0, 17)
13/07/27 23:17:40 INFO local.LocalTaskSetManager: Size of task 18 is 1491 bytes
13/07/27 23:17:40 INFO local.LocalScheduler: Running 18
13/07/27 23:17:40 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:17:40 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a3
13/07/27 23:17:41 INFO storage.MemoryStore: ensureFreeSpace(30062713) called with curMem=1283906736, maxMem=1358297825
13/07/27 23:17:41 INFO storage.MemoryStore: Block rdd_1_18 stored as values to memory (estimated size 28.7 MB, free 42.3 MB)
13/07/27 23:17:41 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_18 in memory on tachyon-ec2-0:38074 (size: 28.7 MB, free: 42.3 MB)
13/07/27 23:17:41 INFO storage.BlockManagerMaster: Updated info of block rdd_1_18
13/07/27 23:17:41 INFO local.LocalScheduler: Finished 18
13/07/27 23:17:41 INFO scheduler.DAGScheduler: Completed ResultTask(0, 18)
13/07/27 23:17:41 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:17:41 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 7.800 s
13/07/27 23:17:41 INFO spark.SparkContext: Job finished: count at <console>:15, took 7.850463973 s
res0: Long = 500094

scala> 13/07/27 23:17:41 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:17:41 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:17:41 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:17:41 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:17:41 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:17:41 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:17:41 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:17:41 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 6

spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1 as mode POSIX_FADV_DONTNEED
offset: 0
length: 525
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:17:43 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:17:43 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:57815
Creating SparkContext...
13/07/27 23:17:52 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:17:53 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:17:53 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:17:53 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231753-6b0d
13/07/27 23:17:53 INFO network.ConnectionManager: Bound socket to port 45270 with id = ConnectionManagerId(tachyon-ec2-0,45270)
13/07/27 23:17:53 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:17:53 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:45270 with 1295.4 MB RAM
13/07/27 23:17:53 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:17:53 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:17:53 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:45440
13/07/27 23:17:53 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:45440
13/07/27 23:17:53 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:17:53 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-4a0722db-2b8a-4a40-a651-f79d60dc9e86
13/07/27 23:17:53 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:17:53 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:40133
13/07/27 23:17:53 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:17:53 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:17:53 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:17:53 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:17:53 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:17:53 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:17:53 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:17:53 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:17:53 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:17:53 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:17:53 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1").cache()
13/07/27 23:17:54 INFO storage.MemoryStore: ensureFreeSpace(58391) called with curMem=0, maxMem=1358297825
13/07/27 23:17:54 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:17:55 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:17:55 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:17:55 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:17:55 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:17:55 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:17:55 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:17:55 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:17:55 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:17:55 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:17:55 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:17:55 INFO local.LocalTaskSetManager: Size of task 0 is 1486 bytes
13/07/27 23:17:55 INFO local.LocalScheduler: Running 0
13/07/27 23:17:55 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:17:55 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:17:55 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58391, maxMem=1358297825
13/07/27 23:17:55 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/27 23:17:55 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:45270 (size: 1192.0 B, free: 1295.4 MB)
13/07/27 23:17:55 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:17:55 INFO local.LocalScheduler: Finished 0
13/07/27 23:17:55 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:17:55 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:17:55 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.206 s
13/07/27 23:17:55 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.24998577 s
res0: Long = 1

scala> 13/07/27 23:17:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:17:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:17:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:17:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:17:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:17:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:17:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:17:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100 as mode POSIX_FADV_DONTNEED
offset: 0
length: 55735
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:17:57 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:17:57 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59500
Creating SparkContext...
13/07/27 23:18:07 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:18:07 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:18:07 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:18:07 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231807-2090
13/07/27 23:18:07 INFO network.ConnectionManager: Bound socket to port 51963 with id = ConnectionManagerId(tachyon-ec2-0,51963)
13/07/27 23:18:07 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:18:07 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:51963 with 1295.4 MB RAM
13/07/27 23:18:07 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:18:07 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:18:07 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:57108
13/07/27 23:18:07 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:57108
13/07/27 23:18:07 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:18:07 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-8cfffca9-e71e-4ff3-98cd-9797455f0c4a
13/07/27 23:18:07 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:18:07 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:40927
13/07/27 23:18:07 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:18:07 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:18:07 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:18:07 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:18:07 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:18:07 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:18:07 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:18:07 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:18:07 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:18:07 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:18:07 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100").cache()
13/07/27 23:18:08 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:18:08 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:18:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:18:09 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:18:09 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:18:09 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:18:09 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:18:09 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:18:09 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:18:09 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:18:09 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:18:09 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:18:09 INFO local.LocalTaskSetManager: Size of task 0 is 1488 bytes
13/07/27 23:18:09 INFO local.LocalScheduler: Running 0
13/07/27 23:18:09 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:18:09 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:18:09 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58399, maxMem=1358297825
13/07/27 23:18:09 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/27 23:18:09 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:51963 (size: 113.4 KB, free: 1295.3 MB)
13/07/27 23:18:09 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:18:09 INFO local.LocalScheduler: Finished 0
13/07/27 23:18:09 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:18:09 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:18:09 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.223 s
13/07/27 23:18:09 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.267281203 s
res0: Long = 100

scala> 13/07/27 23:18:09 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:18:09 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:18:09 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:18:09 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:18:09 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:18:09 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:18:09 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:18:09 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 776400
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:18:12 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:18:12 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:54346
Creating SparkContext...
13/07/27 23:18:21 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:18:21 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:18:21 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:18:21 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231821-f66b
13/07/27 23:18:21 INFO network.ConnectionManager: Bound socket to port 40226 with id = ConnectionManagerId(tachyon-ec2-0,40226)
13/07/27 23:18:21 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:18:21 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:40226 with 1295.4 MB RAM
13/07/27 23:18:21 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:18:21 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:18:21 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:54776
13/07/27 23:18:21 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:54776
13/07/27 23:18:21 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:18:21 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-dd77e1a9-1017-47ce-b40e-9eca6bed8dee
13/07/27 23:18:21 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:18:21 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50621
13/07/27 23:18:21 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:18:21 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:18:21 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:18:21 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:18:21 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:18:21 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:18:21 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:18:21 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:18:21 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:18:21 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:18:21 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1000").cache()
13/07/27 23:18:23 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:18:23 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:18:23 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:18:23 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:18:23 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:18:23 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:18:23 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:18:23 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:18:23 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:18:23 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:18:23 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:18:23 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:18:23 INFO local.LocalTaskSetManager: Size of task 0 is 1489 bytes
13/07/27 23:18:23 INFO local.LocalScheduler: Running 0
13/07/27 23:18:23 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:18:23 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:18:23 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58399, maxMem=1358297825
13/07/27 23:18:23 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/27 23:18:23 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:40226 (size: 1580.2 KB, free: 1293.8 MB)
13/07/27 23:18:23 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:18:23 INFO local.LocalScheduler: Finished 0
13/07/27 23:18:23 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:18:23 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:18:23 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.250 s
13/07/27 23:18:23 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.295524307 s
res0: Long = 1000

scala> 13/07/27 23:18:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:18:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:18:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:18:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:18:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:18:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:18:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:18:23 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.10000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 12330369
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:18:26 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:18:26 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:51771
Creating SparkContext...
13/07/27 23:18:35 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:18:35 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:18:35 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:18:35 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231835-d4db
13/07/27 23:18:35 INFO network.ConnectionManager: Bound socket to port 45430 with id = ConnectionManagerId(tachyon-ec2-0,45430)
13/07/27 23:18:35 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:18:35 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:45430 with 1295.4 MB RAM
13/07/27 23:18:35 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:18:35 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:18:35 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:42445
13/07/27 23:18:35 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:42445
13/07/27 23:18:35 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:18:35 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-0a93654d-cf2b-4fb7-b5f9-28928f142f68
13/07/27 23:18:35 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:18:35 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50583
13/07/27 23:18:35 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:18:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:18:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:18:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:18:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:18:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:18:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:18:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:18:35 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:18:35 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:18:35 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.10000").cache()
13/07/27 23:18:37 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:18:37 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:18:37 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:18:37 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:18:37 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:18:37 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:18:37 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:18:37 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:18:37 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:18:37 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:18:37 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:18:37 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:18:37 INFO local.LocalTaskSetManager: Size of task 0 is 1490 bytes
13/07/27 23:18:37 INFO local.LocalScheduler: Running 0
13/07/27 23:18:37 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:18:37 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:18:38 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58399, maxMem=1358297825
13/07/27 23:18:38 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/27 23:18:38 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:45430 (size: 25.0 MB, free: 1270.4 MB)
13/07/27 23:18:38 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:18:38 INFO local.LocalScheduler: Finished 0
13/07/27 23:18:38 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:18:38 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:18:38 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.424 s
13/07/27 23:18:38 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.468627144 s
res0: Long = 10000

scala> 13/07/27 23:18:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:18:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:18:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:18:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:18:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:18:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:18:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:18:38 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 125141299
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:18:40 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:18:40 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:50260
Creating SparkContext...
13/07/27 23:18:49 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:18:50 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:18:50 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:18:50 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231850-4850
13/07/27 23:18:50 INFO network.ConnectionManager: Bound socket to port 40265 with id = ConnectionManagerId(tachyon-ec2-0,40265)
13/07/27 23:18:50 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:18:50 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:40265 with 1295.4 MB RAM
13/07/27 23:18:50 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:18:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:18:50 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:40525
13/07/27 23:18:50 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:40525
13/07/27 23:18:50 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:18:50 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-b8c961d7-d08e-4dd8-9923-28c9094dd464
13/07/27 23:18:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:18:50 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:54734
13/07/27 23:18:50 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:18:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:18:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:18:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:18:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:18:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:18:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:18:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:18:50 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:18:50 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:18:50 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100000").cache()
13/07/27 23:18:51 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:18:51 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:18:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:18:52 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:18:52 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:18:52 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:18:52 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:18:52 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:18:52 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:18:52 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:18:52 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:18:52 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:18:52 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:18:52 INFO local.LocalScheduler: Running 0
13/07/27 23:18:52 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:18:52 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:18:52 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:18:52 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:18:52 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:40265 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:18:52 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:18:52 INFO local.LocalScheduler: Finished 0
13/07/27 23:18:52 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:18:52 INFO local.LocalScheduler: Running 1
13/07/27 23:18:52 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:18:52 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:18:52 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:18:53 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:18:53 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:18:53 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:40265 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:18:53 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:18:53 INFO local.LocalScheduler: Finished 1
13/07/27 23:18:53 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:18:53 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:18:53 INFO local.LocalScheduler: Running 2
13/07/27 23:18:53 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:18:53 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:18:53 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:18:53 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:18:53 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:40265 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:18:53 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:18:53 INFO local.LocalScheduler: Finished 2
13/07/27 23:18:53 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:18:53 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:18:53 INFO local.LocalScheduler: Running 3
13/07/27 23:18:53 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:18:53 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:18:53 INFO storage.MemoryStore: ensureFreeSpace(52232232) called with curMem=211087067, maxMem=1358297825
13/07/27 23:18:53 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 49.8 MB, free 1044.3 MB)
13/07/27 23:18:53 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:40265 (size: 49.8 MB, free: 1044.3 MB)
13/07/27 23:18:53 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:18:53 INFO local.LocalScheduler: Finished 3
13/07/27 23:18:53 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:18:53 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.670 s
13/07/27 23:18:53 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:18:53 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.719235253 s
res0: Long = 100002

scala> 13/07/27 23:18:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:18:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:18:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:18:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:18:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:18:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:18:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:18:53 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.500000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 618418417
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:18:56 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:18:56 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:58007
Creating SparkContext...
13/07/27 23:19:05 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:19:05 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:19:05 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:19:06 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231906-ae9b
13/07/27 23:19:06 INFO network.ConnectionManager: Bound socket to port 53336 with id = ConnectionManagerId(tachyon-ec2-0,53336)
13/07/27 23:19:06 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:19:06 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:53336 with 1295.4 MB RAM
13/07/27 23:19:06 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:19:06 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:19:06 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38871
13/07/27 23:19:06 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:38871
13/07/27 23:19:06 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:19:06 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-4ca065a4-fee7-4d93-9a5c-76762c3eb15b
13/07/27 23:19:06 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:19:06 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:52170
13/07/27 23:19:06 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:19:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:19:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:19:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:19:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:19:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:19:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:19:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:19:06 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:19:06 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:19:06 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.500000").cache()
13/07/27 23:19:07 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:19:07 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:19:07 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:19:07 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:19:07 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:19:07 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:19:07 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:19:07 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:19:07 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:19:07 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:19:07 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:19:07 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:19:08 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:19:08 INFO local.LocalScheduler: Running 0
13/07/27 23:19:08 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:19:08 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:19:08 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:19:08 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:19:08 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:53336 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:19:08 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:19:08 INFO local.LocalScheduler: Finished 0
13/07/27 23:19:08 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:19:08 INFO local.LocalScheduler: Running 1
13/07/27 23:19:08 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:19:08 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:19:08 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:19:08 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:19:08 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:19:08 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:53336 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:19:08 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:19:08 INFO local.LocalScheduler: Finished 1
13/07/27 23:19:08 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:19:08 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:19:08 INFO local.LocalScheduler: Running 2
13/07/27 23:19:08 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:19:08 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:19:09 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:19:09 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:19:09 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:53336 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:19:09 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:19:09 INFO local.LocalScheduler: Finished 2
13/07/27 23:19:09 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:19:09 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:19:09 INFO local.LocalScheduler: Running 3
13/07/27 23:19:09 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:19:09 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:19:09 INFO storage.MemoryStore: ensureFreeSpace(73224723) called with curMem=211087067, maxMem=1358297825
13/07/27 23:19:09 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 69.8 MB, free 1024.2 MB)
13/07/27 23:19:09 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:53336 (size: 69.8 MB, free: 1024.3 MB)
13/07/27 23:19:09 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:19:09 INFO local.LocalScheduler: Finished 3
13/07/27 23:19:09 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:19:09 INFO local.LocalTaskSetManager: Size of task 4 is 1491 bytes
13/07/27 23:19:09 INFO local.LocalScheduler: Running 4
13/07/27 23:19:09 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:19:09 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@695
13/07/27 23:19:10 INFO storage.MemoryStore: ensureFreeSpace(72058182) called with curMem=284311790, maxMem=1358297825
13/07/27 23:19:10 INFO storage.MemoryStore: Block rdd_1_4 stored as values to memory (estimated size 68.7 MB, free 955.5 MB)
13/07/27 23:19:10 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_4 in memory on tachyon-ec2-0:53336 (size: 68.7 MB, free: 955.6 MB)
13/07/27 23:19:10 INFO storage.BlockManagerMaster: Updated info of block rdd_1_4
13/07/27 23:19:10 INFO local.LocalScheduler: Finished 4
13/07/27 23:19:10 INFO scheduler.DAGScheduler: Completed ResultTask(0, 4)
13/07/27 23:19:10 INFO local.LocalTaskSetManager: Size of task 5 is 1491 bytes
13/07/27 23:19:10 INFO local.LocalScheduler: Running 5
13/07/27 23:19:10 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:19:10 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@696
13/07/27 23:19:10 INFO storage.MemoryStore: ensureFreeSpace(69756558) called with curMem=356369972, maxMem=1358297825
13/07/27 23:19:10 INFO storage.MemoryStore: Block rdd_1_5 stored as values to memory (estimated size 66.5 MB, free 889.0 MB)
13/07/27 23:19:10 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_5 in memory on tachyon-ec2-0:53336 (size: 66.5 MB, free: 889.0 MB)
13/07/27 23:19:10 INFO storage.BlockManagerMaster: Updated info of block rdd_1_5
13/07/27 23:19:10 INFO local.LocalScheduler: Finished 5
13/07/27 23:19:10 INFO scheduler.DAGScheduler: Completed ResultTask(0, 5)
13/07/27 23:19:10 INFO local.LocalTaskSetManager: Size of task 6 is 1491 bytes
13/07/27 23:19:10 INFO local.LocalScheduler: Running 6
13/07/27 23:19:10 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:19:10 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@697
13/07/27 23:19:11 INFO storage.MemoryStore: ensureFreeSpace(71337286) called with curMem=426126530, maxMem=1358297825
13/07/27 23:19:11 INFO storage.MemoryStore: Block rdd_1_6 stored as values to memory (estimated size 68.0 MB, free 821.0 MB)
13/07/27 23:19:11 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_6 in memory on tachyon-ec2-0:53336 (size: 68.0 MB, free: 821.0 MB)
13/07/27 23:19:11 INFO storage.BlockManagerMaster: Updated info of block rdd_1_6
13/07/27 23:19:11 INFO local.LocalScheduler: Finished 6
13/07/27 23:19:11 INFO scheduler.DAGScheduler: Completed ResultTask(0, 6)
13/07/27 23:19:11 INFO local.LocalTaskSetManager: Size of task 7 is 1491 bytes
13/07/27 23:19:11 INFO local.LocalScheduler: Running 7
13/07/27 23:19:11 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:19:11 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@698
13/07/27 23:19:11 INFO storage.MemoryStore: ensureFreeSpace(71927110) called with curMem=497463816, maxMem=1358297825
13/07/27 23:19:11 INFO storage.MemoryStore: Block rdd_1_7 stored as values to memory (estimated size 68.6 MB, free 752.4 MB)
13/07/27 23:19:11 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_7 in memory on tachyon-ec2-0:53336 (size: 68.6 MB, free: 752.4 MB)
13/07/27 23:19:11 INFO storage.BlockManagerMaster: Updated info of block rdd_1_7
13/07/27 23:19:11 INFO local.LocalScheduler: Finished 7
13/07/27 23:19:11 INFO scheduler.DAGScheduler: Completed ResultTask(0, 7)
13/07/27 23:19:11 INFO local.LocalTaskSetManager: Size of task 8 is 1491 bytes
13/07/27 23:19:11 INFO local.LocalScheduler: Running 8
13/07/27 23:19:11 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:19:11 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@699
13/07/27 23:19:12 INFO storage.MemoryStore: ensureFreeSpace(68354088) called with curMem=569390926, maxMem=1358297825
13/07/27 23:19:12 INFO storage.MemoryStore: Block rdd_1_8 stored as values to memory (estimated size 65.2 MB, free 687.2 MB)
13/07/27 23:19:12 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_8 in memory on tachyon-ec2-0:53336 (size: 65.2 MB, free: 687.2 MB)
13/07/27 23:19:12 INFO storage.BlockManagerMaster: Updated info of block rdd_1_8
13/07/27 23:19:12 INFO local.LocalScheduler: Finished 8
13/07/27 23:19:12 INFO scheduler.DAGScheduler: Completed ResultTask(0, 8)
13/07/27 23:19:12 INFO local.LocalTaskSetManager: Size of task 9 is 1491 bytes
13/07/27 23:19:12 INFO local.LocalScheduler: Running 9
13/07/27 23:19:12 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:19:12 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69a
13/07/27 23:19:12 INFO storage.MemoryStore: ensureFreeSpace(72189254) called with curMem=637745014, maxMem=1358297825
13/07/27 23:19:12 INFO storage.MemoryStore: Block rdd_1_9 stored as values to memory (estimated size 68.8 MB, free 618.3 MB)
13/07/27 23:19:12 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_9 in memory on tachyon-ec2-0:53336 (size: 68.8 MB, free: 618.4 MB)
13/07/27 23:19:12 INFO storage.BlockManagerMaster: Updated info of block rdd_1_9
13/07/27 23:19:12 INFO local.LocalScheduler: Finished 9
13/07/27 23:19:12 INFO scheduler.DAGScheduler: Completed ResultTask(0, 9)
13/07/27 23:19:12 INFO local.LocalTaskSetManager: Size of task 10 is 1491 bytes
13/07/27 23:19:12 INFO local.LocalScheduler: Running 10
13/07/27 23:19:12 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:19:12 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69b
13/07/27 23:19:13 INFO storage.MemoryStore: ensureFreeSpace(69900737) called with curMem=709934268, maxMem=1358297825
13/07/27 23:19:13 INFO storage.MemoryStore: Block rdd_1_10 stored as values to memory (estimated size 66.7 MB, free 551.7 MB)
13/07/27 23:19:13 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_10 in memory on tachyon-ec2-0:53336 (size: 66.7 MB, free: 551.7 MB)
13/07/27 23:19:13 INFO storage.BlockManagerMaster: Updated info of block rdd_1_10
13/07/27 23:19:13 INFO local.LocalScheduler: Finished 10
13/07/27 23:19:13 INFO scheduler.DAGScheduler: Completed ResultTask(0, 10)
13/07/27 23:19:13 INFO local.LocalTaskSetManager: Size of task 11 is 1491 bytes
13/07/27 23:19:13 INFO local.LocalScheduler: Running 11
13/07/27 23:19:13 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:19:13 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69c
13/07/27 23:19:13 INFO storage.MemoryStore: ensureFreeSpace(71945460) called with curMem=779835005, maxMem=1358297825
13/07/27 23:19:13 INFO storage.MemoryStore: Block rdd_1_11 stored as values to memory (estimated size 68.6 MB, free 483.1 MB)
13/07/27 23:19:13 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_11 in memory on tachyon-ec2-0:53336 (size: 68.6 MB, free: 483.1 MB)
13/07/27 23:19:13 INFO storage.BlockManagerMaster: Updated info of block rdd_1_11
13/07/27 23:19:13 INFO local.LocalScheduler: Finished 11
13/07/27 23:19:13 INFO scheduler.DAGScheduler: Completed ResultTask(0, 11)
13/07/27 23:19:13 INFO local.LocalTaskSetManager: Size of task 12 is 1491 bytes
13/07/27 23:19:13 INFO local.LocalScheduler: Running 12
13/07/27 23:19:13 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:19:13 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69d
13/07/27 23:19:13 INFO storage.MemoryStore: ensureFreeSpace(71937596) called with curMem=851780465, maxMem=1358297825
13/07/27 23:19:13 INFO storage.MemoryStore: Block rdd_1_12 stored as values to memory (estimated size 68.6 MB, free 414.4 MB)
13/07/27 23:19:13 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_12 in memory on tachyon-ec2-0:53336 (size: 68.6 MB, free: 414.5 MB)
13/07/27 23:19:13 INFO storage.BlockManagerMaster: Updated info of block rdd_1_12
13/07/27 23:19:13 INFO local.LocalScheduler: Finished 12
13/07/27 23:19:13 INFO scheduler.DAGScheduler: Completed ResultTask(0, 12)
13/07/27 23:19:13 INFO local.LocalTaskSetManager: Size of task 13 is 1491 bytes
13/07/27 23:19:13 INFO local.LocalScheduler: Running 13
13/07/27 23:19:13 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:19:13 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69e
13/07/27 23:19:14 INFO storage.MemoryStore: ensureFreeSpace(72915393) called with curMem=923718061, maxMem=1358297825
13/07/27 23:19:14 INFO storage.MemoryStore: Block rdd_1_13 stored as values to memory (estimated size 69.5 MB, free 344.9 MB)
13/07/27 23:19:14 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_13 in memory on tachyon-ec2-0:53336 (size: 69.5 MB, free: 345.0 MB)
13/07/27 23:19:14 INFO storage.BlockManagerMaster: Updated info of block rdd_1_13
13/07/27 23:19:14 INFO local.LocalScheduler: Finished 13
13/07/27 23:19:14 INFO scheduler.DAGScheduler: Completed ResultTask(0, 13)
13/07/27 23:19:14 INFO local.LocalTaskSetManager: Size of task 14 is 1491 bytes
13/07/27 23:19:14 INFO local.LocalScheduler: Running 14
13/07/27 23:19:14 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:19:14 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69f
13/07/27 23:19:14 INFO storage.MemoryStore: ensureFreeSpace(71974296) called with curMem=996633454, maxMem=1358297825
13/07/27 23:19:14 INFO storage.MemoryStore: Block rdd_1_14 stored as values to memory (estimated size 68.6 MB, free 276.3 MB)
13/07/27 23:19:14 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_14 in memory on tachyon-ec2-0:53336 (size: 68.6 MB, free: 276.3 MB)
13/07/27 23:19:14 INFO storage.BlockManagerMaster: Updated info of block rdd_1_14
13/07/27 23:19:14 INFO local.LocalScheduler: Finished 14
13/07/27 23:19:14 INFO scheduler.DAGScheduler: Completed ResultTask(0, 14)
13/07/27 23:19:14 INFO local.LocalTaskSetManager: Size of task 15 is 1491 bytes
13/07/27 23:19:14 INFO local.LocalScheduler: Running 15
13/07/27 23:19:14 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:19:14 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a0
13/07/27 23:19:15 INFO storage.MemoryStore: ensureFreeSpace(71051549) called with curMem=1068607750, maxMem=1358297825
13/07/27 23:19:15 INFO storage.MemoryStore: Block rdd_1_15 stored as values to memory (estimated size 67.8 MB, free 208.5 MB)
13/07/27 23:19:15 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_15 in memory on tachyon-ec2-0:53336 (size: 67.8 MB, free: 208.6 MB)
13/07/27 23:19:15 INFO storage.BlockManagerMaster: Updated info of block rdd_1_15
13/07/27 23:19:15 INFO local.LocalScheduler: Finished 15
13/07/27 23:19:15 INFO scheduler.DAGScheduler: Completed ResultTask(0, 15)
13/07/27 23:19:15 INFO local.LocalTaskSetManager: Size of task 16 is 1491 bytes
13/07/27 23:19:15 INFO local.LocalScheduler: Running 16
13/07/27 23:19:15 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:19:15 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a1
13/07/27 23:19:15 INFO storage.MemoryStore: ensureFreeSpace(71565352) called with curMem=1139659299, maxMem=1358297825
13/07/27 23:19:15 INFO storage.MemoryStore: Block rdd_1_16 stored as values to memory (estimated size 68.3 MB, free 140.3 MB)
13/07/27 23:19:15 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_16 in memory on tachyon-ec2-0:53336 (size: 68.3 MB, free: 140.3 MB)
13/07/27 23:19:15 INFO storage.BlockManagerMaster: Updated info of block rdd_1_16
13/07/27 23:19:15 INFO local.LocalScheduler: Finished 16
13/07/27 23:19:15 INFO scheduler.DAGScheduler: Completed ResultTask(0, 16)
13/07/27 23:19:15 INFO local.LocalTaskSetManager: Size of task 17 is 1491 bytes
13/07/27 23:19:15 INFO local.LocalScheduler: Running 17
13/07/27 23:19:15 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:19:15 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a2
13/07/27 23:19:15 INFO storage.MemoryStore: ensureFreeSpace(72682085) called with curMem=1211224651, maxMem=1358297825
13/07/27 23:19:15 INFO storage.MemoryStore: Block rdd_1_17 stored as values to memory (estimated size 69.3 MB, free 70.9 MB)
13/07/27 23:19:15 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_17 in memory on tachyon-ec2-0:53336 (size: 69.3 MB, free: 71.0 MB)
13/07/27 23:19:15 INFO storage.BlockManagerMaster: Updated info of block rdd_1_17
13/07/27 23:19:15 INFO local.LocalScheduler: Finished 17
13/07/27 23:19:15 INFO scheduler.DAGScheduler: Completed ResultTask(0, 17)
13/07/27 23:19:15 INFO local.LocalTaskSetManager: Size of task 18 is 1491 bytes
13/07/27 23:19:15 INFO local.LocalScheduler: Running 18
13/07/27 23:19:15 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:19:15 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a3
13/07/27 23:19:16 INFO storage.MemoryStore: ensureFreeSpace(30062713) called with curMem=1283906736, maxMem=1358297825
13/07/27 23:19:16 INFO storage.MemoryStore: Block rdd_1_18 stored as values to memory (estimated size 28.7 MB, free 42.3 MB)
13/07/27 23:19:16 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_18 in memory on tachyon-ec2-0:53336 (size: 28.7 MB, free: 42.3 MB)
13/07/27 23:19:16 INFO storage.BlockManagerMaster: Updated info of block rdd_1_18
13/07/27 23:19:16 INFO local.LocalScheduler: Finished 18
13/07/27 23:19:16 INFO scheduler.DAGScheduler: Completed ResultTask(0, 18)
13/07/27 23:19:16 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:19:16 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 8.116 s
13/07/27 23:19:16 INFO spark.SparkContext: Job finished: count at <console>:15, took 8.168041713 s
res0: Long = 500094

scala> 13/07/27 23:19:16 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:19:16 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:19:16 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:19:16 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:19:16 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:19:16 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:19:16 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:19:16 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 7

spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1 as mode POSIX_FADV_DONTNEED
offset: 0
length: 525
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:19:18 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:19:18 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:46043
Creating SparkContext...
13/07/27 23:19:27 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:19:28 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:19:28 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:19:28 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231928-f871
13/07/27 23:19:28 INFO network.ConnectionManager: Bound socket to port 42948 with id = ConnectionManagerId(tachyon-ec2-0,42948)
13/07/27 23:19:28 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:19:28 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:42948 with 1295.4 MB RAM
13/07/27 23:19:28 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:19:28 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:19:28 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:51335
13/07/27 23:19:28 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:51335
13/07/27 23:19:28 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:19:28 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-a093df33-48d8-40c6-9df4-a3b8fd3c4ac4
13/07/27 23:19:28 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:19:28 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:46211
13/07/27 23:19:28 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:19:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:19:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:19:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:19:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:19:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:19:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:19:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:19:28 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:19:28 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:19:28 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1").cache()
13/07/27 23:19:29 INFO storage.MemoryStore: ensureFreeSpace(58391) called with curMem=0, maxMem=1358297825
13/07/27 23:19:29 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:19:30 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:19:30 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:19:30 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:19:30 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:19:30 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:19:30 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:19:30 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:19:30 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:19:30 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:19:30 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:19:30 INFO local.LocalTaskSetManager: Size of task 0 is 1486 bytes
13/07/27 23:19:30 INFO local.LocalScheduler: Running 0
13/07/27 23:19:30 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:19:30 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:19:30 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58391, maxMem=1358297825
13/07/27 23:19:30 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/27 23:19:30 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:42948 (size: 1192.0 B, free: 1295.4 MB)
13/07/27 23:19:30 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:19:30 INFO local.LocalScheduler: Finished 0
13/07/27 23:19:30 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:19:30 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:19:30 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.207 s
13/07/27 23:19:30 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.252734367 s
res0: Long = 1

scala> 13/07/27 23:19:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:19:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:19:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:19:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:19:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:19:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:19:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:19:30 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100 as mode POSIX_FADV_DONTNEED
offset: 0
length: 55735
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:19:32 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:19:32 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:46946
Creating SparkContext...
13/07/27 23:19:42 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:19:42 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:19:42 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:19:42 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231942-8c7d
13/07/27 23:19:42 INFO network.ConnectionManager: Bound socket to port 53947 with id = ConnectionManagerId(tachyon-ec2-0,53947)
13/07/27 23:19:42 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:19:42 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:53947 with 1295.4 MB RAM
13/07/27 23:19:42 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:19:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:19:42 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:47047
13/07/27 23:19:42 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:47047
13/07/27 23:19:42 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:19:42 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-b6fec7d9-560b-46dc-ae18-0dd1e810642e
13/07/27 23:19:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:19:42 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:57795
13/07/27 23:19:42 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:19:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:19:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:19:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:19:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:19:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:19:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:19:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:19:42 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:19:42 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:19:42 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100").cache()
13/07/27 23:19:43 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:19:43 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:19:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:19:44 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:19:44 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:19:44 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:19:44 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:19:44 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:19:44 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:19:44 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:19:44 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:19:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:19:44 INFO local.LocalTaskSetManager: Size of task 0 is 1488 bytes
13/07/27 23:19:44 INFO local.LocalScheduler: Running 0
13/07/27 23:19:44 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:19:44 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:19:44 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58399, maxMem=1358297825
13/07/27 23:19:44 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/27 23:19:44 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:53947 (size: 113.4 KB, free: 1295.3 MB)
13/07/27 23:19:44 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:19:44 INFO local.LocalScheduler: Finished 0
13/07/27 23:19:44 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:19:44 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:19:44 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.213 s
13/07/27 23:19:44 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.258770474 s
res0: Long = 100

scala> 13/07/27 23:19:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:19:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:19:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:19:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:19:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:19:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:19:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:19:44 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 776400
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:19:47 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:19:47 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:57095
Creating SparkContext...
13/07/27 23:19:56 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:19:56 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:19:56 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:19:56 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727231956-a25f
13/07/27 23:19:56 INFO network.ConnectionManager: Bound socket to port 39964 with id = ConnectionManagerId(tachyon-ec2-0,39964)
13/07/27 23:19:56 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:19:56 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:39964 with 1295.4 MB RAM
13/07/27 23:19:56 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:19:56 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:19:56 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60753
13/07/27 23:19:56 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:60753
13/07/27 23:19:56 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:19:56 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-3c08c0ff-defa-4a80-a516-5d67ac52099c
13/07/27 23:19:56 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:19:56 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55919
13/07/27 23:19:56 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:19:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:19:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:19:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:19:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:19:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:19:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:19:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:19:56 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:19:56 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:19:56 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1000").cache()
13/07/27 23:19:57 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:19:57 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:19:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:19:58 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:19:58 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:19:58 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:19:58 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:19:58 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:19:58 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:19:58 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:19:58 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:19:58 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:19:58 INFO local.LocalTaskSetManager: Size of task 0 is 1489 bytes
13/07/27 23:19:58 INFO local.LocalScheduler: Running 0
13/07/27 23:19:58 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:19:58 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:19:58 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58399, maxMem=1358297825
13/07/27 23:19:58 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/27 23:19:58 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:39964 (size: 1580.2 KB, free: 1293.8 MB)
13/07/27 23:19:58 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:19:58 INFO local.LocalScheduler: Finished 0
13/07/27 23:19:58 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:19:58 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:19:58 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.259 s
13/07/27 23:19:58 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.303284399 s
res0: Long = 1000

scala> 13/07/27 23:19:58 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:19:58 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:19:58 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:19:58 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:19:58 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:19:58 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:19:58 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:19:58 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.10000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 12330369
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:20:01 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:20:01 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53260
Creating SparkContext...
13/07/27 23:20:10 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:20:10 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:20:10 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:20:10 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232010-e7b0
13/07/27 23:20:10 INFO network.ConnectionManager: Bound socket to port 34192 with id = ConnectionManagerId(tachyon-ec2-0,34192)
13/07/27 23:20:10 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:20:10 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:34192 with 1295.4 MB RAM
13/07/27 23:20:10 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:20:10 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:20:10 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:57603
13/07/27 23:20:10 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:57603
13/07/27 23:20:10 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:20:10 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-5c07207a-322e-4b42-a209-9afa7902f63d
13/07/27 23:20:10 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:20:10 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53996
13/07/27 23:20:10 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:20:10 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:20:10 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:20:10 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:20:10 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:20:10 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:20:10 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:20:10 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:20:10 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:20:10 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:20:10 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.10000").cache()
13/07/27 23:20:12 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:20:12 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:20:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:20:12 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:20:12 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:20:12 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:20:12 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:20:12 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:20:12 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:20:12 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:20:12 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:20:12 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:20:12 INFO local.LocalTaskSetManager: Size of task 0 is 1490 bytes
13/07/27 23:20:12 INFO local.LocalScheduler: Running 0
13/07/27 23:20:12 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:20:12 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:20:12 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58399, maxMem=1358297825
13/07/27 23:20:12 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/27 23:20:12 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:34192 (size: 25.0 MB, free: 1270.4 MB)
13/07/27 23:20:12 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:20:12 INFO local.LocalScheduler: Finished 0
13/07/27 23:20:12 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:20:13 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:20:13 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.416 s
13/07/27 23:20:13 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.461939581 s
res0: Long = 10000

scala> 13/07/27 23:20:13 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:20:13 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:20:13 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:20:13 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:20:13 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:20:13 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:20:13 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:20:13 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 125141299
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:20:15 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:20:15 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:45995
Creating SparkContext...
13/07/27 23:20:24 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:20:24 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:20:25 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:20:25 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232025-b42e
13/07/27 23:20:25 INFO network.ConnectionManager: Bound socket to port 48267 with id = ConnectionManagerId(tachyon-ec2-0,48267)
13/07/27 23:20:25 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:20:25 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:48267 with 1295.4 MB RAM
13/07/27 23:20:25 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:20:25 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:20:25 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:49594
13/07/27 23:20:25 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:49594
13/07/27 23:20:25 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:20:25 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-2ae9edf8-48f0-4b48-a74b-8ee10d9d1eac
13/07/27 23:20:25 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:20:25 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:42417
13/07/27 23:20:25 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:20:25 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:20:25 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:20:25 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:20:25 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:20:25 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:20:25 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:20:25 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:20:25 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:20:25 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:20:25 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100000").cache()
13/07/27 23:20:26 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:20:26 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:20:26 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:20:26 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:20:26 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:20:26 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:20:26 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:20:26 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:20:26 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:20:26 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:20:26 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:20:26 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:20:26 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:20:26 INFO local.LocalScheduler: Running 0
13/07/27 23:20:27 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:20:27 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:20:27 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:20:27 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:20:27 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:48267 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:20:27 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:20:27 INFO local.LocalScheduler: Finished 0
13/07/27 23:20:27 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:20:27 INFO local.LocalScheduler: Running 1
13/07/27 23:20:27 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:20:27 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:20:27 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:20:27 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:20:27 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:20:27 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:48267 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:20:27 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:20:27 INFO local.LocalScheduler: Finished 1
13/07/27 23:20:27 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:20:27 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:20:27 INFO local.LocalScheduler: Running 2
13/07/27 23:20:28 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:20:28 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:20:28 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:20:28 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:20:28 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:48267 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:20:28 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:20:28 INFO local.LocalScheduler: Finished 2
13/07/27 23:20:28 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:20:28 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:20:28 INFO local.LocalScheduler: Running 3
13/07/27 23:20:28 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:20:28 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:20:28 INFO storage.MemoryStore: ensureFreeSpace(52232232) called with curMem=211087067, maxMem=1358297825
13/07/27 23:20:28 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 49.8 MB, free 1044.3 MB)
13/07/27 23:20:28 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:48267 (size: 49.8 MB, free: 1044.3 MB)
13/07/27 23:20:28 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:20:28 INFO local.LocalScheduler: Finished 3
13/07/27 23:20:28 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:20:28 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:20:28 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.830 s
13/07/27 23:20:28 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.876665088 s
res0: Long = 100002

scala> 13/07/27 23:20:28 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:20:28 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:20:28 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:20:28 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:20:28 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:20:28 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:20:28 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:20:28 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.500000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 618418417
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:20:31 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:20:31 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:58213
Creating SparkContext...
13/07/27 23:20:40 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:20:40 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:20:40 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:20:40 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232040-0240
13/07/27 23:20:40 INFO network.ConnectionManager: Bound socket to port 38380 with id = ConnectionManagerId(tachyon-ec2-0,38380)
13/07/27 23:20:40 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:20:40 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:38380 with 1295.4 MB RAM
13/07/27 23:20:40 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:20:40 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:20:40 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:48533
13/07/27 23:20:40 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:48533
13/07/27 23:20:40 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:20:40 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-ff2ea752-0238-4f0e-afca-121663068974
13/07/27 23:20:40 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:20:40 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55247
13/07/27 23:20:41 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:20:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:20:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:20:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:20:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:20:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:20:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:20:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:20:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:20:41 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:20:41 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.500000").cache()
13/07/27 23:20:42 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:20:42 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:20:42 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:20:42 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:20:42 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:20:42 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:20:42 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:20:42 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:20:42 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:20:42 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:20:42 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:20:42 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:20:42 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:20:42 INFO local.LocalScheduler: Running 0
13/07/27 23:20:42 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:20:42 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:20:43 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:20:43 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:20:43 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:38380 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:20:43 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:20:43 INFO local.LocalScheduler: Finished 0
13/07/27 23:20:43 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:20:43 INFO local.LocalScheduler: Running 1
13/07/27 23:20:43 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:20:43 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:20:43 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:20:43 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:20:43 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:20:43 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:38380 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:20:43 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:20:43 INFO local.LocalScheduler: Finished 1
13/07/27 23:20:43 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:20:43 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:20:43 INFO local.LocalScheduler: Running 2
13/07/27 23:20:43 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:20:43 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:20:44 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:20:44 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:20:44 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:38380 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:20:44 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:20:44 INFO local.LocalScheduler: Finished 2
13/07/27 23:20:44 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:20:44 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:20:44 INFO local.LocalScheduler: Running 3
13/07/27 23:20:44 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:20:44 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:20:44 INFO storage.MemoryStore: ensureFreeSpace(73224723) called with curMem=211087067, maxMem=1358297825
13/07/27 23:20:44 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 69.8 MB, free 1024.2 MB)
13/07/27 23:20:44 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:38380 (size: 69.8 MB, free: 1024.3 MB)
13/07/27 23:20:44 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:20:44 INFO local.LocalScheduler: Finished 3
13/07/27 23:20:44 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:20:44 INFO local.LocalTaskSetManager: Size of task 4 is 1491 bytes
13/07/27 23:20:44 INFO local.LocalScheduler: Running 4
13/07/27 23:20:44 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:20:44 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@695
13/07/27 23:20:44 INFO storage.MemoryStore: ensureFreeSpace(72058182) called with curMem=284311790, maxMem=1358297825
13/07/27 23:20:44 INFO storage.MemoryStore: Block rdd_1_4 stored as values to memory (estimated size 68.7 MB, free 955.5 MB)
13/07/27 23:20:44 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_4 in memory on tachyon-ec2-0:38380 (size: 68.7 MB, free: 955.6 MB)
13/07/27 23:20:44 INFO storage.BlockManagerMaster: Updated info of block rdd_1_4
13/07/27 23:20:44 INFO local.LocalScheduler: Finished 4
13/07/27 23:20:44 INFO scheduler.DAGScheduler: Completed ResultTask(0, 4)
13/07/27 23:20:44 INFO local.LocalTaskSetManager: Size of task 5 is 1491 bytes
13/07/27 23:20:44 INFO local.LocalScheduler: Running 5
13/07/27 23:20:44 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:20:44 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@696
13/07/27 23:20:45 INFO storage.MemoryStore: ensureFreeSpace(69756558) called with curMem=356369972, maxMem=1358297825
13/07/27 23:20:45 INFO storage.MemoryStore: Block rdd_1_5 stored as values to memory (estimated size 66.5 MB, free 889.0 MB)
13/07/27 23:20:45 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_5 in memory on tachyon-ec2-0:38380 (size: 66.5 MB, free: 889.0 MB)
13/07/27 23:20:45 INFO storage.BlockManagerMaster: Updated info of block rdd_1_5
13/07/27 23:20:45 INFO local.LocalScheduler: Finished 5
13/07/27 23:20:45 INFO scheduler.DAGScheduler: Completed ResultTask(0, 5)
13/07/27 23:20:45 INFO local.LocalTaskSetManager: Size of task 6 is 1491 bytes
13/07/27 23:20:45 INFO local.LocalScheduler: Running 6
13/07/27 23:20:45 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:20:45 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@697
13/07/27 23:20:45 INFO storage.MemoryStore: ensureFreeSpace(71337286) called with curMem=426126530, maxMem=1358297825
13/07/27 23:20:45 INFO storage.MemoryStore: Block rdd_1_6 stored as values to memory (estimated size 68.0 MB, free 821.0 MB)
13/07/27 23:20:45 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_6 in memory on tachyon-ec2-0:38380 (size: 68.0 MB, free: 821.0 MB)
13/07/27 23:20:45 INFO storage.BlockManagerMaster: Updated info of block rdd_1_6
13/07/27 23:20:45 INFO local.LocalScheduler: Finished 6
13/07/27 23:20:45 INFO scheduler.DAGScheduler: Completed ResultTask(0, 6)
13/07/27 23:20:45 INFO local.LocalTaskSetManager: Size of task 7 is 1491 bytes
13/07/27 23:20:45 INFO local.LocalScheduler: Running 7
13/07/27 23:20:45 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:20:45 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@698
13/07/27 23:20:45 INFO storage.MemoryStore: ensureFreeSpace(71927110) called with curMem=497463816, maxMem=1358297825
13/07/27 23:20:45 INFO storage.MemoryStore: Block rdd_1_7 stored as values to memory (estimated size 68.6 MB, free 752.4 MB)
13/07/27 23:20:45 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_7 in memory on tachyon-ec2-0:38380 (size: 68.6 MB, free: 752.4 MB)
13/07/27 23:20:45 INFO storage.BlockManagerMaster: Updated info of block rdd_1_7
13/07/27 23:20:45 INFO local.LocalScheduler: Finished 7
13/07/27 23:20:45 INFO scheduler.DAGScheduler: Completed ResultTask(0, 7)
13/07/27 23:20:45 INFO local.LocalTaskSetManager: Size of task 8 is 1491 bytes
13/07/27 23:20:45 INFO local.LocalScheduler: Running 8
13/07/27 23:20:45 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:20:45 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@699
13/07/27 23:20:45 INFO storage.MemoryStore: ensureFreeSpace(68354088) called with curMem=569390926, maxMem=1358297825
13/07/27 23:20:45 INFO storage.MemoryStore: Block rdd_1_8 stored as values to memory (estimated size 65.2 MB, free 687.2 MB)
13/07/27 23:20:45 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_8 in memory on tachyon-ec2-0:38380 (size: 65.2 MB, free: 687.2 MB)
13/07/27 23:20:45 INFO storage.BlockManagerMaster: Updated info of block rdd_1_8
13/07/27 23:20:45 INFO local.LocalScheduler: Finished 8
13/07/27 23:20:45 INFO scheduler.DAGScheduler: Completed ResultTask(0, 8)
13/07/27 23:20:45 INFO local.LocalTaskSetManager: Size of task 9 is 1491 bytes
13/07/27 23:20:45 INFO local.LocalScheduler: Running 9
13/07/27 23:20:45 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:20:45 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69a
13/07/27 23:20:46 INFO storage.MemoryStore: ensureFreeSpace(72189254) called with curMem=637745014, maxMem=1358297825
13/07/27 23:20:46 INFO storage.MemoryStore: Block rdd_1_9 stored as values to memory (estimated size 68.8 MB, free 618.3 MB)
13/07/27 23:20:46 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_9 in memory on tachyon-ec2-0:38380 (size: 68.8 MB, free: 618.4 MB)
13/07/27 23:20:46 INFO storage.BlockManagerMaster: Updated info of block rdd_1_9
13/07/27 23:20:46 INFO local.LocalScheduler: Finished 9
13/07/27 23:20:46 INFO scheduler.DAGScheduler: Completed ResultTask(0, 9)
13/07/27 23:20:46 INFO local.LocalTaskSetManager: Size of task 10 is 1491 bytes
13/07/27 23:20:46 INFO local.LocalScheduler: Running 10
13/07/27 23:20:46 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:20:46 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69b
13/07/27 23:20:46 INFO storage.MemoryStore: ensureFreeSpace(69900737) called with curMem=709934268, maxMem=1358297825
13/07/27 23:20:46 INFO storage.MemoryStore: Block rdd_1_10 stored as values to memory (estimated size 66.7 MB, free 551.7 MB)
13/07/27 23:20:46 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_10 in memory on tachyon-ec2-0:38380 (size: 66.7 MB, free: 551.7 MB)
13/07/27 23:20:46 INFO storage.BlockManagerMaster: Updated info of block rdd_1_10
13/07/27 23:20:46 INFO local.LocalScheduler: Finished 10
13/07/27 23:20:46 INFO scheduler.DAGScheduler: Completed ResultTask(0, 10)
13/07/27 23:20:46 INFO local.LocalTaskSetManager: Size of task 11 is 1491 bytes
13/07/27 23:20:46 INFO local.LocalScheduler: Running 11
13/07/27 23:20:46 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:20:46 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69c
13/07/27 23:20:46 INFO storage.MemoryStore: ensureFreeSpace(71945460) called with curMem=779835005, maxMem=1358297825
13/07/27 23:20:46 INFO storage.MemoryStore: Block rdd_1_11 stored as values to memory (estimated size 68.6 MB, free 483.1 MB)
13/07/27 23:20:46 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_11 in memory on tachyon-ec2-0:38380 (size: 68.6 MB, free: 483.1 MB)
13/07/27 23:20:46 INFO storage.BlockManagerMaster: Updated info of block rdd_1_11
13/07/27 23:20:46 INFO local.LocalScheduler: Finished 11
13/07/27 23:20:46 INFO scheduler.DAGScheduler: Completed ResultTask(0, 11)
13/07/27 23:20:46 INFO local.LocalTaskSetManager: Size of task 12 is 1491 bytes
13/07/27 23:20:46 INFO local.LocalScheduler: Running 12
13/07/27 23:20:46 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:20:46 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69d
13/07/27 23:20:46 INFO storage.MemoryStore: ensureFreeSpace(71937596) called with curMem=851780465, maxMem=1358297825
13/07/27 23:20:46 INFO storage.MemoryStore: Block rdd_1_12 stored as values to memory (estimated size 68.6 MB, free 414.4 MB)
13/07/27 23:20:46 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_12 in memory on tachyon-ec2-0:38380 (size: 68.6 MB, free: 414.5 MB)
13/07/27 23:20:46 INFO storage.BlockManagerMaster: Updated info of block rdd_1_12
13/07/27 23:20:46 INFO local.LocalScheduler: Finished 12
13/07/27 23:20:46 INFO scheduler.DAGScheduler: Completed ResultTask(0, 12)
13/07/27 23:20:46 INFO local.LocalTaskSetManager: Size of task 13 is 1491 bytes
13/07/27 23:20:46 INFO local.LocalScheduler: Running 13
13/07/27 23:20:46 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:20:46 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69e
13/07/27 23:20:47 INFO storage.MemoryStore: ensureFreeSpace(72915393) called with curMem=923718061, maxMem=1358297825
13/07/27 23:20:47 INFO storage.MemoryStore: Block rdd_1_13 stored as values to memory (estimated size 69.5 MB, free 344.9 MB)
13/07/27 23:20:47 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_13 in memory on tachyon-ec2-0:38380 (size: 69.5 MB, free: 345.0 MB)
13/07/27 23:20:47 INFO storage.BlockManagerMaster: Updated info of block rdd_1_13
13/07/27 23:20:47 INFO local.LocalScheduler: Finished 13
13/07/27 23:20:47 INFO scheduler.DAGScheduler: Completed ResultTask(0, 13)
13/07/27 23:20:47 INFO local.LocalTaskSetManager: Size of task 14 is 1491 bytes
13/07/27 23:20:47 INFO local.LocalScheduler: Running 14
13/07/27 23:20:47 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:20:47 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69f
13/07/27 23:20:48 INFO storage.MemoryStore: ensureFreeSpace(71974296) called with curMem=996633454, maxMem=1358297825
13/07/27 23:20:48 INFO storage.MemoryStore: Block rdd_1_14 stored as values to memory (estimated size 68.6 MB, free 276.3 MB)
13/07/27 23:20:48 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_14 in memory on tachyon-ec2-0:38380 (size: 68.6 MB, free: 276.3 MB)
13/07/27 23:20:48 INFO storage.BlockManagerMaster: Updated info of block rdd_1_14
13/07/27 23:20:48 INFO local.LocalScheduler: Finished 14
13/07/27 23:20:48 INFO scheduler.DAGScheduler: Completed ResultTask(0, 14)
13/07/27 23:20:48 INFO local.LocalTaskSetManager: Size of task 15 is 1491 bytes
13/07/27 23:20:48 INFO local.LocalScheduler: Running 15
13/07/27 23:20:48 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:20:48 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a0
13/07/27 23:20:48 INFO storage.MemoryStore: ensureFreeSpace(71051549) called with curMem=1068607750, maxMem=1358297825
13/07/27 23:20:48 INFO storage.MemoryStore: Block rdd_1_15 stored as values to memory (estimated size 67.8 MB, free 208.5 MB)
13/07/27 23:20:48 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_15 in memory on tachyon-ec2-0:38380 (size: 67.8 MB, free: 208.6 MB)
13/07/27 23:20:48 INFO storage.BlockManagerMaster: Updated info of block rdd_1_15
13/07/27 23:20:48 INFO local.LocalScheduler: Finished 15
13/07/27 23:20:48 INFO scheduler.DAGScheduler: Completed ResultTask(0, 15)
13/07/27 23:20:48 INFO local.LocalTaskSetManager: Size of task 16 is 1491 bytes
13/07/27 23:20:48 INFO local.LocalScheduler: Running 16
13/07/27 23:20:48 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:20:48 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a1
13/07/27 23:20:48 INFO storage.MemoryStore: ensureFreeSpace(71565352) called with curMem=1139659299, maxMem=1358297825
13/07/27 23:20:48 INFO storage.MemoryStore: Block rdd_1_16 stored as values to memory (estimated size 68.3 MB, free 140.3 MB)
13/07/27 23:20:48 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_16 in memory on tachyon-ec2-0:38380 (size: 68.3 MB, free: 140.3 MB)
13/07/27 23:20:48 INFO storage.BlockManagerMaster: Updated info of block rdd_1_16
13/07/27 23:20:48 INFO local.LocalScheduler: Finished 16
13/07/27 23:20:48 INFO scheduler.DAGScheduler: Completed ResultTask(0, 16)
13/07/27 23:20:48 INFO local.LocalTaskSetManager: Size of task 17 is 1491 bytes
13/07/27 23:20:48 INFO local.LocalScheduler: Running 17
13/07/27 23:20:48 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:20:48 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a2
13/07/27 23:20:49 INFO storage.MemoryStore: ensureFreeSpace(72682085) called with curMem=1211224651, maxMem=1358297825
13/07/27 23:20:49 INFO storage.MemoryStore: Block rdd_1_17 stored as values to memory (estimated size 69.3 MB, free 70.9 MB)
13/07/27 23:20:49 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_17 in memory on tachyon-ec2-0:38380 (size: 69.3 MB, free: 71.0 MB)
13/07/27 23:20:49 INFO storage.BlockManagerMaster: Updated info of block rdd_1_17
13/07/27 23:20:49 INFO local.LocalScheduler: Finished 17
13/07/27 23:20:49 INFO scheduler.DAGScheduler: Completed ResultTask(0, 17)
13/07/27 23:20:49 INFO local.LocalTaskSetManager: Size of task 18 is 1491 bytes
13/07/27 23:20:49 INFO local.LocalScheduler: Running 18
13/07/27 23:20:49 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:20:49 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a3
13/07/27 23:20:49 INFO storage.MemoryStore: ensureFreeSpace(30062713) called with curMem=1283906736, maxMem=1358297825
13/07/27 23:20:49 INFO storage.MemoryStore: Block rdd_1_18 stored as values to memory (estimated size 28.7 MB, free 42.3 MB)
13/07/27 23:20:49 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_18 in memory on tachyon-ec2-0:38380 (size: 28.7 MB, free: 42.3 MB)
13/07/27 23:20:49 INFO storage.BlockManagerMaster: Updated info of block rdd_1_18
13/07/27 23:20:49 INFO local.LocalScheduler: Finished 18
13/07/27 23:20:49 INFO scheduler.DAGScheduler: Completed ResultTask(0, 18)
13/07/27 23:20:49 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:20:49 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 6.773 s
13/07/27 23:20:49 INFO spark.SparkContext: Job finished: count at <console>:15, took 6.824695175 s
res0: Long = 500094

scala> 13/07/27 23:20:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:20:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:20:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:20:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:20:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:20:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:20:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:20:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 8

spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1 as mode POSIX_FADV_DONTNEED
offset: 0
length: 525
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:20:52 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:20:52 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:52487
Creating SparkContext...
13/07/27 23:21:01 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:21:01 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:21:01 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:21:01 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232101-b718
13/07/27 23:21:01 INFO network.ConnectionManager: Bound socket to port 33810 with id = ConnectionManagerId(tachyon-ec2-0,33810)
13/07/27 23:21:01 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:21:01 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:33810 with 1295.4 MB RAM
13/07/27 23:21:01 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:21:01 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:01 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:41783
13/07/27 23:21:01 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:41783
13/07/27 23:21:01 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:21:01 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-a452e9f0-97ea-4cf0-ac88-9b763af7c5ef
13/07/27 23:21:01 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:01 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:46699
13/07/27 23:21:01 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:21:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:21:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:21:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:21:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:21:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:21:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:21:01 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:21:01 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:21:01 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1").cache()
13/07/27 23:21:03 INFO storage.MemoryStore: ensureFreeSpace(58391) called with curMem=0, maxMem=1358297825
13/07/27 23:21:03 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:21:03 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:21:03 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:21:03 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:21:03 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:21:03 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:21:03 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:21:03 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:21:03 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:21:03 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:21:03 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:21:03 INFO local.LocalTaskSetManager: Size of task 0 is 1486 bytes
13/07/27 23:21:03 INFO local.LocalScheduler: Running 0
13/07/27 23:21:03 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:21:03 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:21:03 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58391, maxMem=1358297825
13/07/27 23:21:03 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/27 23:21:03 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:33810 (size: 1192.0 B, free: 1295.4 MB)
13/07/27 23:21:03 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:21:03 INFO local.LocalScheduler: Finished 0
13/07/27 23:21:03 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:21:03 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:21:03 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.210 s
13/07/27 23:21:03 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.255298931 s
res0: Long = 1

scala> 13/07/27 23:21:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:21:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:21:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:21:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:21:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:21:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:21:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:21:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100 as mode POSIX_FADV_DONTNEED
offset: 0
length: 55735
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:21:06 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:06 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:52910
Creating SparkContext...
13/07/27 23:21:15 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:21:15 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:21:15 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:21:15 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232115-f4cb
13/07/27 23:21:15 INFO network.ConnectionManager: Bound socket to port 51134 with id = ConnectionManagerId(tachyon-ec2-0,51134)
13/07/27 23:21:15 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:21:15 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:51134 with 1295.4 MB RAM
13/07/27 23:21:15 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:21:15 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:15 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:45873
13/07/27 23:21:15 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:45873
13/07/27 23:21:15 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:21:15 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-26dc6d8e-95ea-4689-a65b-2218246ddd5f
13/07/27 23:21:15 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:15 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:36382
13/07/27 23:21:15 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:21:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:21:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:21:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:21:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:21:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:21:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:21:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:21:15 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:21:15 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100").cache()
13/07/27 23:21:17 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:21:17 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:21:17 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:21:17 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:21:17 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:21:17 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:21:17 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:21:17 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:21:17 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:21:17 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:21:17 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:21:17 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:21:17 INFO local.LocalTaskSetManager: Size of task 0 is 1488 bytes
13/07/27 23:21:17 INFO local.LocalScheduler: Running 0
13/07/27 23:21:17 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:21:17 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:21:17 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58399, maxMem=1358297825
13/07/27 23:21:17 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/27 23:21:17 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:51134 (size: 113.4 KB, free: 1295.3 MB)
13/07/27 23:21:17 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:21:17 INFO local.LocalScheduler: Finished 0
13/07/27 23:21:17 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:21:17 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:21:17 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.217 s
13/07/27 23:21:17 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.261153293 s
res0: Long = 100

scala> 13/07/27 23:21:17 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:21:17 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:21:17 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:21:17 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:21:17 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:21:17 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:21:17 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:21:17 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 776400
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:21:20 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:20 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38970
Creating SparkContext...
13/07/27 23:21:29 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:21:29 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:21:29 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:21:29 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232129-5ef6
13/07/27 23:21:29 INFO network.ConnectionManager: Bound socket to port 40740 with id = ConnectionManagerId(tachyon-ec2-0,40740)
13/07/27 23:21:29 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:21:29 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:40740 with 1295.4 MB RAM
13/07/27 23:21:29 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:21:29 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:29 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:41215
13/07/27 23:21:29 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:41215
13/07/27 23:21:29 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:21:29 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-28c2b500-2f2f-4684-8855-b6129eee08a2
13/07/27 23:21:29 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:29 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:47011
13/07/27 23:21:29 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:29 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:21:29 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:21:29 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:21:29 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:21:29 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:21:29 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:21:29 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:21:29 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:21:29 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:21:29 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1000").cache()
13/07/27 23:21:31 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:21:31 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:21:31 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:21:31 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:21:31 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:21:31 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:21:31 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:21:31 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:21:31 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:21:31 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:21:31 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:21:31 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:21:31 INFO local.LocalTaskSetManager: Size of task 0 is 1489 bytes
13/07/27 23:21:31 INFO local.LocalScheduler: Running 0
13/07/27 23:21:31 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:21:31 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:21:31 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58399, maxMem=1358297825
13/07/27 23:21:31 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/27 23:21:31 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:40740 (size: 1580.2 KB, free: 1293.8 MB)
13/07/27 23:21:31 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:21:31 INFO local.LocalScheduler: Finished 0
13/07/27 23:21:31 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:21:31 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:21:31 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.245 s
13/07/27 23:21:31 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.290709256 s
res0: Long = 1000

scala> 13/07/27 23:21:32 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:21:32 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:21:32 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:21:32 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:21:32 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:21:32 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:21:32 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:21:32 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.10000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 12330369
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:21:34 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:34 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:54547
Creating SparkContext...
13/07/27 23:21:43 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:21:43 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:21:43 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:21:43 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232143-faec
13/07/27 23:21:44 INFO network.ConnectionManager: Bound socket to port 50029 with id = ConnectionManagerId(tachyon-ec2-0,50029)
13/07/27 23:21:44 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:21:44 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:50029 with 1295.4 MB RAM
13/07/27 23:21:44 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:21:44 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:44 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:54779
13/07/27 23:21:44 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:54779
13/07/27 23:21:44 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:21:44 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-da7eba7f-770c-4a06-a920-628c5eb07403
13/07/27 23:21:44 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:44 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:52039
13/07/27 23:21:44 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:44 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:21:44 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:21:44 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:21:44 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:21:44 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:21:44 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:21:44 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:21:44 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:21:44 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:21:44 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.10000").cache()
13/07/27 23:21:45 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:21:45 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:21:45 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:21:45 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:21:45 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:21:45 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:21:45 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:21:45 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:21:45 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:21:45 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:21:45 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:21:45 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:21:45 INFO local.LocalTaskSetManager: Size of task 0 is 1490 bytes
13/07/27 23:21:45 INFO local.LocalScheduler: Running 0
13/07/27 23:21:45 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:21:45 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:21:46 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58399, maxMem=1358297825
13/07/27 23:21:46 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/27 23:21:46 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:50029 (size: 25.0 MB, free: 1270.4 MB)
13/07/27 23:21:46 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:21:46 INFO local.LocalScheduler: Finished 0
13/07/27 23:21:46 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:21:46 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:21:46 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.415 s
13/07/27 23:21:46 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.458337749 s
res0: Long = 10000

scala> 13/07/27 23:21:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:21:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:21:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:21:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:21:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:21:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:21:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:21:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 125141299
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:21:48 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:48 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:36278
Creating SparkContext...
13/07/27 23:21:58 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:21:58 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:21:58 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:21:58 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232158-a1c2
13/07/27 23:21:58 INFO network.ConnectionManager: Bound socket to port 57549 with id = ConnectionManagerId(tachyon-ec2-0,57549)
13/07/27 23:21:58 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:21:58 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:57549 with 1295.4 MB RAM
13/07/27 23:21:58 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:21:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:58 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38361
13/07/27 23:21:58 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:38361
13/07/27 23:21:58 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:21:58 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-29feb1cf-6ce4-40f7-8280-2507f6b61a6f
13/07/27 23:21:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:58 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:41654
13/07/27 23:21:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:21:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:21:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:21:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:21:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:21:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:21:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:21:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:21:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:21:58 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:21:58 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100000").cache()
13/07/27 23:21:59 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:21:59 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:22:00 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:22:00 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:22:00 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:22:00 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:22:00 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:22:00 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:22:00 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:22:00 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:22:00 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:22:00 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:22:00 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:22:00 INFO local.LocalScheduler: Running 0
13/07/27 23:22:00 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:22:00 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:22:00 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:22:00 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:22:00 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:57549 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:22:00 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:22:00 INFO local.LocalScheduler: Finished 0
13/07/27 23:22:00 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:22:00 INFO local.LocalScheduler: Running 1
13/07/27 23:22:00 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:22:00 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:22:00 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:22:00 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:22:00 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:22:00 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:57549 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:22:00 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:22:00 INFO local.LocalScheduler: Finished 1
13/07/27 23:22:00 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:22:00 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:22:00 INFO local.LocalScheduler: Running 2
13/07/27 23:22:01 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:22:01 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:22:01 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:22:01 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:22:01 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:57549 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:22:01 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:22:01 INFO local.LocalScheduler: Finished 2
13/07/27 23:22:01 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:22:01 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:22:01 INFO local.LocalScheduler: Running 3
13/07/27 23:22:01 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:22:01 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:22:01 INFO storage.MemoryStore: ensureFreeSpace(52232232) called with curMem=211087067, maxMem=1358297825
13/07/27 23:22:01 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 49.8 MB, free 1044.3 MB)
13/07/27 23:22:01 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:57549 (size: 49.8 MB, free: 1044.3 MB)
13/07/27 23:22:01 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:22:01 INFO local.LocalScheduler: Finished 3
13/07/27 23:22:01 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:22:01 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:22:01 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.487 s
13/07/27 23:22:01 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.533065284 s
res0: Long = 100002

scala> 13/07/27 23:22:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:22:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:22:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:22:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:22:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:22:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:22:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:22:01 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.500000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 618418417
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:22:04 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:22:04 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:56030
Creating SparkContext...
13/07/27 23:22:13 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:22:13 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:22:13 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:22:13 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232213-fc43
13/07/27 23:22:13 INFO network.ConnectionManager: Bound socket to port 53000 with id = ConnectionManagerId(tachyon-ec2-0,53000)
13/07/27 23:22:13 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:22:13 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:53000 with 1295.4 MB RAM
13/07/27 23:22:13 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:22:13 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:22:13 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37819
13/07/27 23:22:13 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:37819
13/07/27 23:22:13 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:22:13 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-b419981b-f830-4401-baef-a81029e5ca64
13/07/27 23:22:13 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:22:13 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:39218
13/07/27 23:22:13 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:22:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:22:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:22:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:22:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:22:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:22:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:22:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:22:13 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:22:13 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:22:13 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.500000").cache()
13/07/27 23:22:15 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:22:15 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:22:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:22:15 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:22:15 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:22:15 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:22:15 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:22:15 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:22:15 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:22:15 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:22:15 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:22:15 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:22:15 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:22:15 INFO local.LocalScheduler: Running 0
13/07/27 23:22:15 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:22:15 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:22:16 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:22:16 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:22:16 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:53000 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:22:16 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:22:16 INFO local.LocalScheduler: Finished 0
13/07/27 23:22:16 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:22:16 INFO local.LocalScheduler: Running 1
13/07/27 23:22:16 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:22:16 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:22:16 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:22:16 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:22:16 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:22:16 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:53000 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:22:16 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:22:16 INFO local.LocalScheduler: Finished 1
13/07/27 23:22:16 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:22:16 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:22:16 INFO local.LocalScheduler: Running 2
13/07/27 23:22:16 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:22:16 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:22:16 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:22:16 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:22:16 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:53000 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:22:16 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:22:16 INFO local.LocalScheduler: Finished 2
13/07/27 23:22:16 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:22:16 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:22:16 INFO local.LocalScheduler: Running 3
13/07/27 23:22:16 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:22:16 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:22:17 INFO storage.MemoryStore: ensureFreeSpace(73224723) called with curMem=211087067, maxMem=1358297825
13/07/27 23:22:17 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 69.8 MB, free 1024.2 MB)
13/07/27 23:22:17 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:53000 (size: 69.8 MB, free: 1024.3 MB)
13/07/27 23:22:17 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:22:17 INFO local.LocalScheduler: Finished 3
13/07/27 23:22:17 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:22:17 INFO local.LocalTaskSetManager: Size of task 4 is 1491 bytes
13/07/27 23:22:17 INFO local.LocalScheduler: Running 4
13/07/27 23:22:17 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:22:17 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@695
13/07/27 23:22:17 INFO storage.MemoryStore: ensureFreeSpace(72058182) called with curMem=284311790, maxMem=1358297825
13/07/27 23:22:17 INFO storage.MemoryStore: Block rdd_1_4 stored as values to memory (estimated size 68.7 MB, free 955.5 MB)
13/07/27 23:22:17 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_4 in memory on tachyon-ec2-0:53000 (size: 68.7 MB, free: 955.6 MB)
13/07/27 23:22:17 INFO storage.BlockManagerMaster: Updated info of block rdd_1_4
13/07/27 23:22:17 INFO local.LocalScheduler: Finished 4
13/07/27 23:22:17 INFO scheduler.DAGScheduler: Completed ResultTask(0, 4)
13/07/27 23:22:17 INFO local.LocalTaskSetManager: Size of task 5 is 1491 bytes
13/07/27 23:22:17 INFO local.LocalScheduler: Running 5
13/07/27 23:22:17 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:22:17 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@696
13/07/27 23:22:17 INFO storage.MemoryStore: ensureFreeSpace(69756558) called with curMem=356369972, maxMem=1358297825
13/07/27 23:22:17 INFO storage.MemoryStore: Block rdd_1_5 stored as values to memory (estimated size 66.5 MB, free 889.0 MB)
13/07/27 23:22:17 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_5 in memory on tachyon-ec2-0:53000 (size: 66.5 MB, free: 889.0 MB)
13/07/27 23:22:17 INFO storage.BlockManagerMaster: Updated info of block rdd_1_5
13/07/27 23:22:17 INFO local.LocalScheduler: Finished 5
13/07/27 23:22:17 INFO scheduler.DAGScheduler: Completed ResultTask(0, 5)
13/07/27 23:22:17 INFO local.LocalTaskSetManager: Size of task 6 is 1491 bytes
13/07/27 23:22:17 INFO local.LocalScheduler: Running 6
13/07/27 23:22:17 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:22:17 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@697
13/07/27 23:22:18 INFO storage.MemoryStore: ensureFreeSpace(71337286) called with curMem=426126530, maxMem=1358297825
13/07/27 23:22:18 INFO storage.MemoryStore: Block rdd_1_6 stored as values to memory (estimated size 68.0 MB, free 821.0 MB)
13/07/27 23:22:18 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_6 in memory on tachyon-ec2-0:53000 (size: 68.0 MB, free: 821.0 MB)
13/07/27 23:22:18 INFO storage.BlockManagerMaster: Updated info of block rdd_1_6
13/07/27 23:22:18 INFO local.LocalScheduler: Finished 6
13/07/27 23:22:18 INFO scheduler.DAGScheduler: Completed ResultTask(0, 6)
13/07/27 23:22:18 INFO local.LocalTaskSetManager: Size of task 7 is 1491 bytes
13/07/27 23:22:18 INFO local.LocalScheduler: Running 7
13/07/27 23:22:18 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:22:18 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@698
13/07/27 23:22:18 INFO storage.MemoryStore: ensureFreeSpace(71927110) called with curMem=497463816, maxMem=1358297825
13/07/27 23:22:18 INFO storage.MemoryStore: Block rdd_1_7 stored as values to memory (estimated size 68.6 MB, free 752.4 MB)
13/07/27 23:22:18 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_7 in memory on tachyon-ec2-0:53000 (size: 68.6 MB, free: 752.4 MB)
13/07/27 23:22:18 INFO storage.BlockManagerMaster: Updated info of block rdd_1_7
13/07/27 23:22:18 INFO local.LocalScheduler: Finished 7
13/07/27 23:22:18 INFO scheduler.DAGScheduler: Completed ResultTask(0, 7)
13/07/27 23:22:18 INFO local.LocalTaskSetManager: Size of task 8 is 1491 bytes
13/07/27 23:22:18 INFO local.LocalScheduler: Running 8
13/07/27 23:22:18 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:22:18 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@699
13/07/27 23:22:18 INFO storage.MemoryStore: ensureFreeSpace(68354088) called with curMem=569390926, maxMem=1358297825
13/07/27 23:22:18 INFO storage.MemoryStore: Block rdd_1_8 stored as values to memory (estimated size 65.2 MB, free 687.2 MB)
13/07/27 23:22:18 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_8 in memory on tachyon-ec2-0:53000 (size: 65.2 MB, free: 687.2 MB)
13/07/27 23:22:18 INFO storage.BlockManagerMaster: Updated info of block rdd_1_8
13/07/27 23:22:18 INFO local.LocalScheduler: Finished 8
13/07/27 23:22:18 INFO scheduler.DAGScheduler: Completed ResultTask(0, 8)
13/07/27 23:22:18 INFO local.LocalTaskSetManager: Size of task 9 is 1491 bytes
13/07/27 23:22:18 INFO local.LocalScheduler: Running 9
13/07/27 23:22:18 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:22:18 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69a
13/07/27 23:22:19 INFO storage.MemoryStore: ensureFreeSpace(72189254) called with curMem=637745014, maxMem=1358297825
13/07/27 23:22:19 INFO storage.MemoryStore: Block rdd_1_9 stored as values to memory (estimated size 68.8 MB, free 618.3 MB)
13/07/27 23:22:19 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_9 in memory on tachyon-ec2-0:53000 (size: 68.8 MB, free: 618.4 MB)
13/07/27 23:22:19 INFO storage.BlockManagerMaster: Updated info of block rdd_1_9
13/07/27 23:22:19 INFO local.LocalScheduler: Finished 9
13/07/27 23:22:19 INFO scheduler.DAGScheduler: Completed ResultTask(0, 9)
13/07/27 23:22:19 INFO local.LocalTaskSetManager: Size of task 10 is 1491 bytes
13/07/27 23:22:19 INFO local.LocalScheduler: Running 10
13/07/27 23:22:19 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:22:19 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69b
13/07/27 23:22:19 INFO storage.MemoryStore: ensureFreeSpace(69900737) called with curMem=709934268, maxMem=1358297825
13/07/27 23:22:19 INFO storage.MemoryStore: Block rdd_1_10 stored as values to memory (estimated size 66.7 MB, free 551.7 MB)
13/07/27 23:22:19 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_10 in memory on tachyon-ec2-0:53000 (size: 66.7 MB, free: 551.7 MB)
13/07/27 23:22:19 INFO storage.BlockManagerMaster: Updated info of block rdd_1_10
13/07/27 23:22:19 INFO local.LocalScheduler: Finished 10
13/07/27 23:22:19 INFO scheduler.DAGScheduler: Completed ResultTask(0, 10)
13/07/27 23:22:19 INFO local.LocalTaskSetManager: Size of task 11 is 1491 bytes
13/07/27 23:22:19 INFO local.LocalScheduler: Running 11
13/07/27 23:22:19 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:22:19 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69c
13/07/27 23:22:19 INFO storage.MemoryStore: ensureFreeSpace(71945460) called with curMem=779835005, maxMem=1358297825
13/07/27 23:22:19 INFO storage.MemoryStore: Block rdd_1_11 stored as values to memory (estimated size 68.6 MB, free 483.1 MB)
13/07/27 23:22:19 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_11 in memory on tachyon-ec2-0:53000 (size: 68.6 MB, free: 483.1 MB)
13/07/27 23:22:19 INFO storage.BlockManagerMaster: Updated info of block rdd_1_11
13/07/27 23:22:19 INFO local.LocalScheduler: Finished 11
13/07/27 23:22:19 INFO scheduler.DAGScheduler: Completed ResultTask(0, 11)
13/07/27 23:22:19 INFO local.LocalTaskSetManager: Size of task 12 is 1491 bytes
13/07/27 23:22:19 INFO local.LocalScheduler: Running 12
13/07/27 23:22:19 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:22:19 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69d
13/07/27 23:22:19 INFO storage.MemoryStore: ensureFreeSpace(71937596) called with curMem=851780465, maxMem=1358297825
13/07/27 23:22:19 INFO storage.MemoryStore: Block rdd_1_12 stored as values to memory (estimated size 68.6 MB, free 414.4 MB)
13/07/27 23:22:19 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_12 in memory on tachyon-ec2-0:53000 (size: 68.6 MB, free: 414.5 MB)
13/07/27 23:22:19 INFO storage.BlockManagerMaster: Updated info of block rdd_1_12
13/07/27 23:22:19 INFO local.LocalScheduler: Finished 12
13/07/27 23:22:19 INFO scheduler.DAGScheduler: Completed ResultTask(0, 12)
13/07/27 23:22:19 INFO local.LocalTaskSetManager: Size of task 13 is 1491 bytes
13/07/27 23:22:19 INFO local.LocalScheduler: Running 13
13/07/27 23:22:19 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:22:19 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69e
13/07/27 23:22:20 INFO storage.MemoryStore: ensureFreeSpace(72915393) called with curMem=923718061, maxMem=1358297825
13/07/27 23:22:20 INFO storage.MemoryStore: Block rdd_1_13 stored as values to memory (estimated size 69.5 MB, free 344.9 MB)
13/07/27 23:22:20 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_13 in memory on tachyon-ec2-0:53000 (size: 69.5 MB, free: 345.0 MB)
13/07/27 23:22:20 INFO storage.BlockManagerMaster: Updated info of block rdd_1_13
13/07/27 23:22:20 INFO local.LocalScheduler: Finished 13
13/07/27 23:22:20 INFO scheduler.DAGScheduler: Completed ResultTask(0, 13)
13/07/27 23:22:20 INFO local.LocalTaskSetManager: Size of task 14 is 1491 bytes
13/07/27 23:22:20 INFO local.LocalScheduler: Running 14
13/07/27 23:22:20 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:22:20 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69f
13/07/27 23:22:21 INFO storage.MemoryStore: ensureFreeSpace(71974296) called with curMem=996633454, maxMem=1358297825
13/07/27 23:22:21 INFO storage.MemoryStore: Block rdd_1_14 stored as values to memory (estimated size 68.6 MB, free 276.3 MB)
13/07/27 23:22:21 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_14 in memory on tachyon-ec2-0:53000 (size: 68.6 MB, free: 276.3 MB)
13/07/27 23:22:21 INFO storage.BlockManagerMaster: Updated info of block rdd_1_14
13/07/27 23:22:21 INFO local.LocalScheduler: Finished 14
13/07/27 23:22:21 INFO scheduler.DAGScheduler: Completed ResultTask(0, 14)
13/07/27 23:22:21 INFO local.LocalTaskSetManager: Size of task 15 is 1491 bytes
13/07/27 23:22:21 INFO local.LocalScheduler: Running 15
13/07/27 23:22:21 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:22:21 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a0
13/07/27 23:22:21 INFO storage.MemoryStore: ensureFreeSpace(71051549) called with curMem=1068607750, maxMem=1358297825
13/07/27 23:22:21 INFO storage.MemoryStore: Block rdd_1_15 stored as values to memory (estimated size 67.8 MB, free 208.5 MB)
13/07/27 23:22:21 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_15 in memory on tachyon-ec2-0:53000 (size: 67.8 MB, free: 208.6 MB)
13/07/27 23:22:21 INFO storage.BlockManagerMaster: Updated info of block rdd_1_15
13/07/27 23:22:21 INFO local.LocalScheduler: Finished 15
13/07/27 23:22:21 INFO scheduler.DAGScheduler: Completed ResultTask(0, 15)
13/07/27 23:22:21 INFO local.LocalTaskSetManager: Size of task 16 is 1491 bytes
13/07/27 23:22:21 INFO local.LocalScheduler: Running 16
13/07/27 23:22:21 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:22:21 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a1
13/07/27 23:22:21 INFO storage.MemoryStore: ensureFreeSpace(71565352) called with curMem=1139659299, maxMem=1358297825
13/07/27 23:22:21 INFO storage.MemoryStore: Block rdd_1_16 stored as values to memory (estimated size 68.3 MB, free 140.3 MB)
13/07/27 23:22:21 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_16 in memory on tachyon-ec2-0:53000 (size: 68.3 MB, free: 140.3 MB)
13/07/27 23:22:21 INFO storage.BlockManagerMaster: Updated info of block rdd_1_16
13/07/27 23:22:21 INFO local.LocalScheduler: Finished 16
13/07/27 23:22:21 INFO scheduler.DAGScheduler: Completed ResultTask(0, 16)
13/07/27 23:22:21 INFO local.LocalTaskSetManager: Size of task 17 is 1491 bytes
13/07/27 23:22:21 INFO local.LocalScheduler: Running 17
13/07/27 23:22:21 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:22:21 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a2
13/07/27 23:22:22 INFO storage.MemoryStore: ensureFreeSpace(72682085) called with curMem=1211224651, maxMem=1358297825
13/07/27 23:22:22 INFO storage.MemoryStore: Block rdd_1_17 stored as values to memory (estimated size 69.3 MB, free 70.9 MB)
13/07/27 23:22:22 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_17 in memory on tachyon-ec2-0:53000 (size: 69.3 MB, free: 71.0 MB)
13/07/27 23:22:22 INFO storage.BlockManagerMaster: Updated info of block rdd_1_17
13/07/27 23:22:22 INFO local.LocalScheduler: Finished 17
13/07/27 23:22:22 INFO scheduler.DAGScheduler: Completed ResultTask(0, 17)
13/07/27 23:22:22 INFO local.LocalTaskSetManager: Size of task 18 is 1491 bytes
13/07/27 23:22:22 INFO local.LocalScheduler: Running 18
13/07/27 23:22:22 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:22:22 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a3
13/07/27 23:22:22 INFO storage.MemoryStore: ensureFreeSpace(30062713) called with curMem=1283906736, maxMem=1358297825
13/07/27 23:22:22 INFO storage.MemoryStore: Block rdd_1_18 stored as values to memory (estimated size 28.7 MB, free 42.3 MB)
13/07/27 23:22:22 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_18 in memory on tachyon-ec2-0:53000 (size: 28.7 MB, free: 42.3 MB)
13/07/27 23:22:22 INFO storage.BlockManagerMaster: Updated info of block rdd_1_18
13/07/27 23:22:22 INFO local.LocalScheduler: Finished 18
13/07/27 23:22:22 INFO scheduler.DAGScheduler: Completed ResultTask(0, 18)
13/07/27 23:22:22 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:22:22 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 6.588 s
13/07/27 23:22:22 INFO spark.SparkContext: Job finished: count at <console>:15, took 6.638741183 s
res0: Long = 500094

scala> 13/07/27 23:22:22 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:22:22 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:22:22 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:22:22 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:22:22 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:22:22 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:22:22 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:22:22 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run1 #: 9

spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1 as mode POSIX_FADV_DONTNEED
offset: 0
length: 525
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:22:24 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:22:25 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:41560
Creating SparkContext...
13/07/27 23:22:34 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:22:34 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:22:34 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:22:34 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232234-776b
13/07/27 23:22:34 INFO network.ConnectionManager: Bound socket to port 41881 with id = ConnectionManagerId(tachyon-ec2-0,41881)
13/07/27 23:22:34 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:22:34 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:41881 with 1295.4 MB RAM
13/07/27 23:22:34 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:22:34 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:22:34 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60932
13/07/27 23:22:34 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:60932
13/07/27 23:22:34 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:22:34 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-eb865ead-8ed7-4f35-a735-4ae91b05b7fc
13/07/27 23:22:34 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:22:34 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:41295
13/07/27 23:22:34 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:22:34 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:22:34 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:22:34 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:22:34 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:22:34 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:22:34 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:22:34 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:22:34 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:22:34 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:22:34 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1").cache()
13/07/27 23:22:35 INFO storage.MemoryStore: ensureFreeSpace(58391) called with curMem=0, maxMem=1358297825
13/07/27 23:22:35 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:22:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:22:36 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:22:36 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:22:36 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:22:36 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:22:36 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:22:36 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:22:36 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:22:36 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:22:36 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:22:36 INFO local.LocalTaskSetManager: Size of task 0 is 1486 bytes
13/07/27 23:22:36 INFO local.LocalScheduler: Running 0
13/07/27 23:22:36 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:22:36 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:22:36 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58391, maxMem=1358297825
13/07/27 23:22:36 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/27 23:22:36 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:41881 (size: 1192.0 B, free: 1295.4 MB)
13/07/27 23:22:36 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:22:36 INFO local.LocalScheduler: Finished 0
13/07/27 23:22:36 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:22:36 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:22:36 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.202 s
13/07/27 23:22:36 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.24668194 s
res0: Long = 1

scala> 13/07/27 23:22:36 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:22:36 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:22:36 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:22:36 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:22:36 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:22:36 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:22:36 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:22:36 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100 as mode POSIX_FADV_DONTNEED
offset: 0
length: 55735
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:22:39 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:22:39 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:47838
Creating SparkContext...
13/07/27 23:22:48 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:22:48 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:22:48 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:22:48 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232248-addc
13/07/27 23:22:48 INFO network.ConnectionManager: Bound socket to port 58959 with id = ConnectionManagerId(tachyon-ec2-0,58959)
13/07/27 23:22:48 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:22:48 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:58959 with 1295.4 MB RAM
13/07/27 23:22:48 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:22:48 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:22:48 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:55873
13/07/27 23:22:48 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:55873
13/07/27 23:22:48 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:22:48 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-e192e9cd-6dd8-4a20-b0d2-1e4e1eb22955
13/07/27 23:22:48 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:22:48 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:41327
13/07/27 23:22:48 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:22:48 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:22:48 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:22:48 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:22:48 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:22:48 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:22:48 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:22:48 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:22:48 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:22:48 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:22:48 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100").cache()
13/07/27 23:22:50 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:22:50 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:22:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:22:50 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:22:50 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:22:50 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:22:50 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:22:50 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:22:50 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:22:50 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:22:50 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:22:50 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:22:50 INFO local.LocalTaskSetManager: Size of task 0 is 1488 bytes
13/07/27 23:22:50 INFO local.LocalScheduler: Running 0
13/07/27 23:22:50 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:22:50 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:22:50 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58399, maxMem=1358297825
13/07/27 23:22:50 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/27 23:22:50 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:58959 (size: 113.4 KB, free: 1295.3 MB)
13/07/27 23:22:50 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:22:50 INFO local.LocalScheduler: Finished 0
13/07/27 23:22:50 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:22:50 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:22:50 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.212 s
13/07/27 23:22:50 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.256246937 s
res0: Long = 100

scala> 13/07/27 23:22:50 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:22:50 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:22:50 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:22:50 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:22:50 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:22:50 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:22:50 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:22:50 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 776400
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:22:53 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:22:53 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:34626
Creating SparkContext...
13/07/27 23:23:02 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:23:02 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:23:02 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:23:02 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232302-be72
13/07/27 23:23:02 INFO network.ConnectionManager: Bound socket to port 33094 with id = ConnectionManagerId(tachyon-ec2-0,33094)
13/07/27 23:23:02 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:23:02 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:33094 with 1295.4 MB RAM
13/07/27 23:23:02 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:23:02 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:23:02 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:34573
13/07/27 23:23:02 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:34573
13/07/27 23:23:02 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:23:02 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-99822326-6689-4cee-a71e-fb72402e2fbd
13/07/27 23:23:02 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:23:02 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:48971
13/07/27 23:23:02 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:23:02 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:23:02 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:23:02 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:23:02 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:23:02 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:23:02 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:23:02 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:23:02 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:23:02 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:23:02 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1000").cache()
13/07/27 23:23:04 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:23:04 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:23:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:23:04 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:23:04 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:23:04 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:23:04 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:23:04 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:23:04 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:23:04 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:23:04 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:23:04 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:23:04 INFO local.LocalTaskSetManager: Size of task 0 is 1489 bytes
13/07/27 23:23:04 INFO local.LocalScheduler: Running 0
13/07/27 23:23:04 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:23:04 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:23:04 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58399, maxMem=1358297825
13/07/27 23:23:04 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/27 23:23:04 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:33094 (size: 1580.2 KB, free: 1293.8 MB)
13/07/27 23:23:04 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:23:04 INFO local.LocalScheduler: Finished 0
13/07/27 23:23:04 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:23:04 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:23:04 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.250 s
13/07/27 23:23:04 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.294461096 s
res0: Long = 1000

scala> 13/07/27 23:23:04 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:23:04 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:23:04 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:23:04 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:23:04 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:23:04 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:23:04 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:23:04 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.10000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 12330369
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:23:07 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:23:07 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:35002
Creating SparkContext...
13/07/27 23:23:16 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:23:16 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:23:16 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:23:16 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232316-ed53
13/07/27 23:23:16 INFO network.ConnectionManager: Bound socket to port 57489 with id = ConnectionManagerId(tachyon-ec2-0,57489)
13/07/27 23:23:16 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:23:16 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:57489 with 1295.4 MB RAM
13/07/27 23:23:16 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:23:16 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:23:16 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:36316
13/07/27 23:23:16 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:36316
13/07/27 23:23:16 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:23:16 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-bb0ab9be-a057-4ca8-8078-a359bff1c59b
13/07/27 23:23:16 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:23:16 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:54612
13/07/27 23:23:16 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:23:16 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:23:16 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:23:16 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:23:16 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:23:16 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:23:16 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:23:16 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:23:16 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:23:16 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:23:16 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.10000").cache()
13/07/27 23:23:18 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:23:18 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:23:18 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:23:18 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:23:18 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:23:18 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:23:18 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:23:18 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:23:18 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:23:18 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:23:18 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:23:18 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:23:18 INFO local.LocalTaskSetManager: Size of task 0 is 1490 bytes
13/07/27 23:23:18 INFO local.LocalScheduler: Running 0
13/07/27 23:23:18 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:23:18 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:23:19 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58399, maxMem=1358297825
13/07/27 23:23:19 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/27 23:23:19 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:57489 (size: 25.0 MB, free: 1270.4 MB)
13/07/27 23:23:19 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:23:19 INFO local.LocalScheduler: Finished 0
13/07/27 23:23:19 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:23:19 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:23:19 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.420 s
13/07/27 23:23:19 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.465438598 s
res0: Long = 10000

scala> 13/07/27 23:23:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:23:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:23:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:23:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:23:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:23:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:23:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:23:19 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 125141299
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:23:21 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:23:21 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:34437
Creating SparkContext...
13/07/27 23:23:30 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:23:31 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:23:31 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:23:31 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232331-45c7
13/07/27 23:23:31 INFO network.ConnectionManager: Bound socket to port 42610 with id = ConnectionManagerId(tachyon-ec2-0,42610)
13/07/27 23:23:31 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:23:31 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:42610 with 1295.4 MB RAM
13/07/27 23:23:31 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:23:31 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:23:31 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59366
13/07/27 23:23:31 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:59366
13/07/27 23:23:31 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:23:31 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-8082b4a3-4948-49cb-b324-d746bfcf2fda
13/07/27 23:23:31 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:23:31 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53754
13/07/27 23:23:31 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:23:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:23:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:23:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:23:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:23:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:23:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:23:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:23:31 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:23:31 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:23:31 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100000").cache()
13/07/27 23:23:32 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:23:32 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:23:33 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:23:33 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:23:33 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:23:33 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:23:33 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:23:33 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:23:33 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:23:33 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:23:33 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:23:33 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:23:33 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:23:33 INFO local.LocalScheduler: Running 0
13/07/27 23:23:33 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:23:33 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:23:33 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:23:33 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:23:33 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:42610 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:23:33 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:23:33 INFO local.LocalScheduler: Finished 0
13/07/27 23:23:33 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:23:33 INFO local.LocalScheduler: Running 1
13/07/27 23:23:33 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:23:33 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:23:33 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:23:33 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:23:33 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:23:33 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:42610 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:23:33 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:23:33 INFO local.LocalScheduler: Finished 1
13/07/27 23:23:33 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:23:33 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:23:33 INFO local.LocalScheduler: Running 2
13/07/27 23:23:33 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:23:33 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:23:34 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:23:34 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:23:34 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:42610 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:23:34 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:23:34 INFO local.LocalScheduler: Finished 2
13/07/27 23:23:34 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:23:34 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:23:34 INFO local.LocalScheduler: Running 3
13/07/27 23:23:34 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:23:34 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:23:34 INFO storage.MemoryStore: ensureFreeSpace(52232232) called with curMem=211087067, maxMem=1358297825
13/07/27 23:23:34 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 49.8 MB, free 1044.3 MB)
13/07/27 23:23:34 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:42610 (size: 49.8 MB, free: 1044.3 MB)
13/07/27 23:23:34 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:23:34 INFO local.LocalScheduler: Finished 3
13/07/27 23:23:34 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:23:34 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:23:34 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.500 s
13/07/27 23:23:34 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.546350027 s
res0: Long = 100002

scala> 13/07/27 23:23:34 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:23:34 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:23:34 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:23:34 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:23:34 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:23:34 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:23:34 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:23:34 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.500000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 618418417
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:23:37 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:23:37 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:39457
Creating SparkContext...
13/07/27 23:23:46 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:23:46 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:23:46 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:23:46 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232346-afc5
13/07/27 23:23:46 INFO network.ConnectionManager: Bound socket to port 33253 with id = ConnectionManagerId(tachyon-ec2-0,33253)
13/07/27 23:23:46 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:23:46 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:33253 with 1295.4 MB RAM
13/07/27 23:23:46 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:23:46 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:23:46 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:42610
13/07/27 23:23:46 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:42610
13/07/27 23:23:46 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:23:46 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-9f81ede5-c720-451a-bce4-ae2e5f33c571
13/07/27 23:23:46 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:23:46 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:60214
13/07/27 23:23:46 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:23:46 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:23:46 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:23:46 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:23:46 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:23:46 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:23:46 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:23:46 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:23:46 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:23:46 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:23:46 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.500000").cache()
13/07/27 23:23:48 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:23:48 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:23:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:23:48 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:23:48 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:23:48 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:23:48 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:23:48 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:23:48 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:23:48 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:23:48 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:23:48 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:23:48 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:23:48 INFO local.LocalScheduler: Running 0
13/07/27 23:23:48 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:23:48 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:23:49 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:23:49 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:23:49 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:33253 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:23:49 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:23:49 INFO local.LocalScheduler: Finished 0
13/07/27 23:23:49 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:23:49 INFO local.LocalScheduler: Running 1
13/07/27 23:23:49 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:23:49 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:23:49 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:23:49 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:23:49 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:23:49 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:33253 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:23:49 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:23:49 INFO local.LocalScheduler: Finished 1
13/07/27 23:23:49 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:23:49 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:23:49 INFO local.LocalScheduler: Running 2
13/07/27 23:23:49 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:23:49 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:23:49 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:23:49 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:23:49 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:33253 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:23:49 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:23:49 INFO local.LocalScheduler: Finished 2
13/07/27 23:23:49 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:23:49 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:23:49 INFO local.LocalScheduler: Running 3
13/07/27 23:23:49 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:23:49 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:23:50 INFO storage.MemoryStore: ensureFreeSpace(73224723) called with curMem=211087067, maxMem=1358297825
13/07/27 23:23:50 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 69.8 MB, free 1024.2 MB)
13/07/27 23:23:50 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:33253 (size: 69.8 MB, free: 1024.3 MB)
13/07/27 23:23:50 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:23:50 INFO local.LocalScheduler: Finished 3
13/07/27 23:23:50 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:23:50 INFO local.LocalTaskSetManager: Size of task 4 is 1491 bytes
13/07/27 23:23:50 INFO local.LocalScheduler: Running 4
13/07/27 23:23:50 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:23:50 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@695
13/07/27 23:23:50 INFO storage.MemoryStore: ensureFreeSpace(72058182) called with curMem=284311790, maxMem=1358297825
13/07/27 23:23:50 INFO storage.MemoryStore: Block rdd_1_4 stored as values to memory (estimated size 68.7 MB, free 955.5 MB)
13/07/27 23:23:50 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_4 in memory on tachyon-ec2-0:33253 (size: 68.7 MB, free: 955.6 MB)
13/07/27 23:23:50 INFO storage.BlockManagerMaster: Updated info of block rdd_1_4
13/07/27 23:23:50 INFO local.LocalScheduler: Finished 4
13/07/27 23:23:50 INFO scheduler.DAGScheduler: Completed ResultTask(0, 4)
13/07/27 23:23:50 INFO local.LocalTaskSetManager: Size of task 5 is 1491 bytes
13/07/27 23:23:50 INFO local.LocalScheduler: Running 5
13/07/27 23:23:50 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:23:50 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@696
13/07/27 23:23:50 INFO storage.MemoryStore: ensureFreeSpace(69756558) called with curMem=356369972, maxMem=1358297825
13/07/27 23:23:50 INFO storage.MemoryStore: Block rdd_1_5 stored as values to memory (estimated size 66.5 MB, free 889.0 MB)
13/07/27 23:23:50 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_5 in memory on tachyon-ec2-0:33253 (size: 66.5 MB, free: 889.0 MB)
13/07/27 23:23:50 INFO storage.BlockManagerMaster: Updated info of block rdd_1_5
13/07/27 23:23:50 INFO local.LocalScheduler: Finished 5
13/07/27 23:23:50 INFO scheduler.DAGScheduler: Completed ResultTask(0, 5)
13/07/27 23:23:50 INFO local.LocalTaskSetManager: Size of task 6 is 1491 bytes
13/07/27 23:23:50 INFO local.LocalScheduler: Running 6
13/07/27 23:23:50 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:23:50 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@697
13/07/27 23:23:51 INFO storage.MemoryStore: ensureFreeSpace(71337286) called with curMem=426126530, maxMem=1358297825
13/07/27 23:23:51 INFO storage.MemoryStore: Block rdd_1_6 stored as values to memory (estimated size 68.0 MB, free 821.0 MB)
13/07/27 23:23:51 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_6 in memory on tachyon-ec2-0:33253 (size: 68.0 MB, free: 821.0 MB)
13/07/27 23:23:51 INFO storage.BlockManagerMaster: Updated info of block rdd_1_6
13/07/27 23:23:51 INFO local.LocalScheduler: Finished 6
13/07/27 23:23:51 INFO scheduler.DAGScheduler: Completed ResultTask(0, 6)
13/07/27 23:23:51 INFO local.LocalTaskSetManager: Size of task 7 is 1491 bytes
13/07/27 23:23:51 INFO local.LocalScheduler: Running 7
13/07/27 23:23:51 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:23:51 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@698
13/07/27 23:23:51 INFO storage.MemoryStore: ensureFreeSpace(71927110) called with curMem=497463816, maxMem=1358297825
13/07/27 23:23:51 INFO storage.MemoryStore: Block rdd_1_7 stored as values to memory (estimated size 68.6 MB, free 752.4 MB)
13/07/27 23:23:51 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_7 in memory on tachyon-ec2-0:33253 (size: 68.6 MB, free: 752.4 MB)
13/07/27 23:23:51 INFO storage.BlockManagerMaster: Updated info of block rdd_1_7
13/07/27 23:23:51 INFO local.LocalScheduler: Finished 7
13/07/27 23:23:51 INFO scheduler.DAGScheduler: Completed ResultTask(0, 7)
13/07/27 23:23:51 INFO local.LocalTaskSetManager: Size of task 8 is 1491 bytes
13/07/27 23:23:51 INFO local.LocalScheduler: Running 8
13/07/27 23:23:51 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:23:51 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@699
13/07/27 23:23:51 INFO storage.MemoryStore: ensureFreeSpace(68354088) called with curMem=569390926, maxMem=1358297825
13/07/27 23:23:51 INFO storage.MemoryStore: Block rdd_1_8 stored as values to memory (estimated size 65.2 MB, free 687.2 MB)
13/07/27 23:23:51 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_8 in memory on tachyon-ec2-0:33253 (size: 65.2 MB, free: 687.2 MB)
13/07/27 23:23:51 INFO storage.BlockManagerMaster: Updated info of block rdd_1_8
13/07/27 23:23:51 INFO local.LocalScheduler: Finished 8
13/07/27 23:23:51 INFO scheduler.DAGScheduler: Completed ResultTask(0, 8)
13/07/27 23:23:51 INFO local.LocalTaskSetManager: Size of task 9 is 1491 bytes
13/07/27 23:23:51 INFO local.LocalScheduler: Running 9
13/07/27 23:23:51 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:23:51 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69a
13/07/27 23:23:52 INFO storage.MemoryStore: ensureFreeSpace(72189254) called with curMem=637745014, maxMem=1358297825
13/07/27 23:23:52 INFO storage.MemoryStore: Block rdd_1_9 stored as values to memory (estimated size 68.8 MB, free 618.3 MB)
13/07/27 23:23:52 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_9 in memory on tachyon-ec2-0:33253 (size: 68.8 MB, free: 618.4 MB)
13/07/27 23:23:52 INFO storage.BlockManagerMaster: Updated info of block rdd_1_9
13/07/27 23:23:52 INFO local.LocalScheduler: Finished 9
13/07/27 23:23:52 INFO scheduler.DAGScheduler: Completed ResultTask(0, 9)
13/07/27 23:23:52 INFO local.LocalTaskSetManager: Size of task 10 is 1491 bytes
13/07/27 23:23:52 INFO local.LocalScheduler: Running 10
13/07/27 23:23:52 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:23:52 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69b
13/07/27 23:23:52 INFO storage.MemoryStore: ensureFreeSpace(69900737) called with curMem=709934268, maxMem=1358297825
13/07/27 23:23:52 INFO storage.MemoryStore: Block rdd_1_10 stored as values to memory (estimated size 66.7 MB, free 551.7 MB)
13/07/27 23:23:52 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_10 in memory on tachyon-ec2-0:33253 (size: 66.7 MB, free: 551.7 MB)
13/07/27 23:23:52 INFO storage.BlockManagerMaster: Updated info of block rdd_1_10
13/07/27 23:23:52 INFO local.LocalScheduler: Finished 10
13/07/27 23:23:52 INFO scheduler.DAGScheduler: Completed ResultTask(0, 10)
13/07/27 23:23:52 INFO local.LocalTaskSetManager: Size of task 11 is 1491 bytes
13/07/27 23:23:52 INFO local.LocalScheduler: Running 11
13/07/27 23:23:52 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:23:52 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69c
13/07/27 23:23:52 INFO storage.MemoryStore: ensureFreeSpace(71945460) called with curMem=779835005, maxMem=1358297825
13/07/27 23:23:52 INFO storage.MemoryStore: Block rdd_1_11 stored as values to memory (estimated size 68.6 MB, free 483.1 MB)
13/07/27 23:23:52 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_11 in memory on tachyon-ec2-0:33253 (size: 68.6 MB, free: 483.1 MB)
13/07/27 23:23:52 INFO storage.BlockManagerMaster: Updated info of block rdd_1_11
13/07/27 23:23:52 INFO local.LocalScheduler: Finished 11
13/07/27 23:23:52 INFO scheduler.DAGScheduler: Completed ResultTask(0, 11)
13/07/27 23:23:52 INFO local.LocalTaskSetManager: Size of task 12 is 1491 bytes
13/07/27 23:23:52 INFO local.LocalScheduler: Running 12
13/07/27 23:23:52 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:23:52 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69d
13/07/27 23:23:52 INFO storage.MemoryStore: ensureFreeSpace(71937596) called with curMem=851780465, maxMem=1358297825
13/07/27 23:23:52 INFO storage.MemoryStore: Block rdd_1_12 stored as values to memory (estimated size 68.6 MB, free 414.4 MB)
13/07/27 23:23:52 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_12 in memory on tachyon-ec2-0:33253 (size: 68.6 MB, free: 414.5 MB)
13/07/27 23:23:52 INFO storage.BlockManagerMaster: Updated info of block rdd_1_12
13/07/27 23:23:52 INFO local.LocalScheduler: Finished 12
13/07/27 23:23:52 INFO scheduler.DAGScheduler: Completed ResultTask(0, 12)
13/07/27 23:23:52 INFO local.LocalTaskSetManager: Size of task 13 is 1491 bytes
13/07/27 23:23:52 INFO local.LocalScheduler: Running 13
13/07/27 23:23:52 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:23:52 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69e
13/07/27 23:23:53 INFO storage.MemoryStore: ensureFreeSpace(72915393) called with curMem=923718061, maxMem=1358297825
13/07/27 23:23:53 INFO storage.MemoryStore: Block rdd_1_13 stored as values to memory (estimated size 69.5 MB, free 344.9 MB)
13/07/27 23:23:53 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_13 in memory on tachyon-ec2-0:33253 (size: 69.5 MB, free: 345.0 MB)
13/07/27 23:23:53 INFO storage.BlockManagerMaster: Updated info of block rdd_1_13
13/07/27 23:23:53 INFO local.LocalScheduler: Finished 13
13/07/27 23:23:53 INFO scheduler.DAGScheduler: Completed ResultTask(0, 13)
13/07/27 23:23:53 INFO local.LocalTaskSetManager: Size of task 14 is 1491 bytes
13/07/27 23:23:53 INFO local.LocalScheduler: Running 14
13/07/27 23:23:53 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:23:53 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69f
13/07/27 23:23:54 INFO storage.MemoryStore: ensureFreeSpace(71974296) called with curMem=996633454, maxMem=1358297825
13/07/27 23:23:54 INFO storage.MemoryStore: Block rdd_1_14 stored as values to memory (estimated size 68.6 MB, free 276.3 MB)
13/07/27 23:23:54 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_14 in memory on tachyon-ec2-0:33253 (size: 68.6 MB, free: 276.3 MB)
13/07/27 23:23:54 INFO storage.BlockManagerMaster: Updated info of block rdd_1_14
13/07/27 23:23:54 INFO local.LocalScheduler: Finished 14
13/07/27 23:23:54 INFO scheduler.DAGScheduler: Completed ResultTask(0, 14)
13/07/27 23:23:54 INFO local.LocalTaskSetManager: Size of task 15 is 1491 bytes
13/07/27 23:23:54 INFO local.LocalScheduler: Running 15
13/07/27 23:23:54 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:23:54 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a0
13/07/27 23:23:54 INFO storage.MemoryStore: ensureFreeSpace(71051549) called with curMem=1068607750, maxMem=1358297825
13/07/27 23:23:54 INFO storage.MemoryStore: Block rdd_1_15 stored as values to memory (estimated size 67.8 MB, free 208.5 MB)
13/07/27 23:23:54 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_15 in memory on tachyon-ec2-0:33253 (size: 67.8 MB, free: 208.6 MB)
13/07/27 23:23:54 INFO storage.BlockManagerMaster: Updated info of block rdd_1_15
13/07/27 23:23:54 INFO local.LocalScheduler: Finished 15
13/07/27 23:23:54 INFO scheduler.DAGScheduler: Completed ResultTask(0, 15)
13/07/27 23:23:54 INFO local.LocalTaskSetManager: Size of task 16 is 1491 bytes
13/07/27 23:23:54 INFO local.LocalScheduler: Running 16
13/07/27 23:23:54 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:23:54 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a1
13/07/27 23:23:54 INFO storage.MemoryStore: ensureFreeSpace(71565352) called with curMem=1139659299, maxMem=1358297825
13/07/27 23:23:54 INFO storage.MemoryStore: Block rdd_1_16 stored as values to memory (estimated size 68.3 MB, free 140.3 MB)
13/07/27 23:23:54 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_16 in memory on tachyon-ec2-0:33253 (size: 68.3 MB, free: 140.3 MB)
13/07/27 23:23:54 INFO storage.BlockManagerMaster: Updated info of block rdd_1_16
13/07/27 23:23:54 INFO local.LocalScheduler: Finished 16
13/07/27 23:23:54 INFO scheduler.DAGScheduler: Completed ResultTask(0, 16)
13/07/27 23:23:54 INFO local.LocalTaskSetManager: Size of task 17 is 1491 bytes
13/07/27 23:23:54 INFO local.LocalScheduler: Running 17
13/07/27 23:23:54 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:23:54 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a2
13/07/27 23:23:55 INFO storage.MemoryStore: ensureFreeSpace(72682085) called with curMem=1211224651, maxMem=1358297825
13/07/27 23:23:55 INFO storage.MemoryStore: Block rdd_1_17 stored as values to memory (estimated size 69.3 MB, free 70.9 MB)
13/07/27 23:23:55 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_17 in memory on tachyon-ec2-0:33253 (size: 69.3 MB, free: 71.0 MB)
13/07/27 23:23:55 INFO storage.BlockManagerMaster: Updated info of block rdd_1_17
13/07/27 23:23:55 INFO local.LocalScheduler: Finished 17
13/07/27 23:23:55 INFO scheduler.DAGScheduler: Completed ResultTask(0, 17)
13/07/27 23:23:55 INFO local.LocalTaskSetManager: Size of task 18 is 1491 bytes
13/07/27 23:23:55 INFO local.LocalScheduler: Running 18
13/07/27 23:23:55 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:23:55 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a3
13/07/27 23:23:55 INFO storage.MemoryStore: ensureFreeSpace(30062713) called with curMem=1283906736, maxMem=1358297825
13/07/27 23:23:55 INFO storage.MemoryStore: Block rdd_1_18 stored as values to memory (estimated size 28.7 MB, free 42.3 MB)
13/07/27 23:23:55 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_18 in memory on tachyon-ec2-0:33253 (size: 28.7 MB, free: 42.3 MB)
13/07/27 23:23:55 INFO storage.BlockManagerMaster: Updated info of block rdd_1_18
13/07/27 23:23:55 INFO local.LocalScheduler: Finished 18
13/07/27 23:23:55 INFO scheduler.DAGScheduler: Completed ResultTask(0, 18)
13/07/27 23:23:55 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:23:55 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 6.708 s
13/07/27 23:23:55 INFO spark.SparkContext: Job finished: count at <console>:15, took 6.758860032 s
res0: Long = 500094

scala> 13/07/27 23:23:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:23:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:23:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:23:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:23:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:23:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:23:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:23:55 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
run11:

spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1 as mode POSIX_FADV_DONTNEED
offset: 0
length: 525
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:23:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:23:58 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:44893
Creating SparkContext...
13/07/27 23:24:07 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:24:07 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:24:07 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:24:07 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232407-fa6c
13/07/27 23:24:07 INFO network.ConnectionManager: Bound socket to port 47825 with id = ConnectionManagerId(tachyon-ec2-0,47825)
13/07/27 23:24:07 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:24:07 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:47825 with 1295.4 MB RAM
13/07/27 23:24:07 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:24:07 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:24:07 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:49587
13/07/27 23:24:07 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:49587
13/07/27 23:24:07 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:24:07 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-4902b174-0c56-41df-bd78-224df21f7f17
13/07/27 23:24:07 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:24:07 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:42610
13/07/27 23:24:07 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:24:07 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:24:07 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:24:07 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:24:07 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:24:07 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:24:07 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:24:07 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:24:07 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:24:07 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:24:07 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1").cache()
13/07/27 23:24:09 INFO storage.MemoryStore: ensureFreeSpace(58391) called with curMem=0, maxMem=1358297825
13/07/27 23:24:09 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:24:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:24:09 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:24:09 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:24:09 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:09 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:09 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:24:09 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:09 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:09 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:09 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:09 INFO local.LocalTaskSetManager: Size of task 0 is 1486 bytes
13/07/27 23:24:09 INFO local.LocalScheduler: Running 0
13/07/27 23:24:09 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:09 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:24:09 INFO storage.MemoryStore: ensureFreeSpace(1192) called with curMem=58391, maxMem=1358297825
13/07/27 23:24:09 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1192.0 B, free 1295.3 MB)
13/07/27 23:24:09 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:47825 (size: 1192.0 B, free: 1295.4 MB)
13/07/27 23:24:09 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:24:09 INFO local.LocalScheduler: Finished 0
13/07/27 23:24:09 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:24:09 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:24:09 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.213 s
13/07/27 23:24:09 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.257526873 s
res0: Long = 1

scala> s.count()
13/07/27 23:24:10 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Final stage: Stage 1 (count at <console>:15)
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:10 INFO local.LocalTaskSetManager: Size of task 1 is 1487 bytes
13/07/27 23:24:10 INFO local.LocalScheduler: Running 1
13/07/27 23:24:10 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:10 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:10 INFO local.LocalScheduler: Finished 1
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Completed ResultTask(1, 0)
13/07/27 23:24:10 INFO local.LocalScheduler: Remove TaskSet 1.0 from pool 
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Stage 1 (count at <console>:15) finished in 0.059 s
13/07/27 23:24:10 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.061205722 s
res1: Long = 1

scala> s.count()
13/07/27 23:24:10 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Final stage: Stage 2 (count at <console>:15)
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:10 INFO local.LocalTaskSetManager: Size of task 2 is 1487 bytes
13/07/27 23:24:10 INFO local.LocalScheduler: Running 2
13/07/27 23:24:10 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:10 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:10 INFO local.LocalScheduler: Finished 2
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Completed ResultTask(2, 0)
13/07/27 23:24:10 INFO local.LocalScheduler: Remove TaskSet 2.0 from pool 
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Stage 2 (count at <console>:15) finished in 0.037 s
13/07/27 23:24:10 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.039779188 s
res2: Long = 1

scala> s.count()
13/07/27 23:24:10 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Final stage: Stage 3 (count at <console>:15)
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:10 INFO local.LocalTaskSetManager: Size of task 3 is 1487 bytes
13/07/27 23:24:10 INFO local.LocalScheduler: Running 3
13/07/27 23:24:10 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:10 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:10 INFO local.LocalScheduler: Finished 3
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Completed ResultTask(3, 0)
13/07/27 23:24:10 INFO local.LocalScheduler: Remove TaskSet 3.0 from pool 
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Stage 3 (count at <console>:15) finished in 0.032 s
13/07/27 23:24:10 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.034922134 s
res3: Long = 1

scala> s.count()
13/07/27 23:24:10 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Final stage: Stage 4 (count at <console>:15)
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:10 INFO local.LocalTaskSetManager: Size of task 4 is 1487 bytes
13/07/27 23:24:10 INFO local.LocalScheduler: Running 4
13/07/27 23:24:10 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:10 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:10 INFO local.LocalScheduler: Finished 4
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Completed ResultTask(4, 0)
13/07/27 23:24:10 INFO local.LocalScheduler: Remove TaskSet 4.0 from pool 
13/07/27 23:24:10 INFO scheduler.DAGScheduler: Stage 4 (count at <console>:15) finished in 0.031 s
13/07/27 23:24:10 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.033449326 s
res4: Long = 1

scala> s.count()
13/07/27 23:24:11 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Got job 5 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Final stage: Stage 5 (count at <console>:15)
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Submitting Stage 5 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 5 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:11 INFO local.LocalTaskSetManager: Size of task 5 is 1487 bytes
13/07/27 23:24:11 INFO local.LocalScheduler: Running 5
13/07/27 23:24:11 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:11 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:11 INFO local.LocalScheduler: Finished 5
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Completed ResultTask(5, 0)
13/07/27 23:24:11 INFO local.LocalScheduler: Remove TaskSet 5.0 from pool 
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Stage 5 (count at <console>:15) finished in 0.031 s
13/07/27 23:24:11 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.033384933 s
res5: Long = 1

scala> s.count()
13/07/27 23:24:11 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Got job 6 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Final stage: Stage 6 (count at <console>:15)
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Submitting Stage 6 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 6 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:11 INFO local.LocalTaskSetManager: Size of task 6 is 1487 bytes
13/07/27 23:24:11 INFO local.LocalScheduler: Running 6
13/07/27 23:24:11 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:11 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:11 INFO local.LocalScheduler: Finished 6
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Completed ResultTask(6, 0)
13/07/27 23:24:11 INFO local.LocalScheduler: Remove TaskSet 6.0 from pool 
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Stage 6 (count at <console>:15) finished in 0.030 s
13/07/27 23:24:11 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.032747991 s
res6: Long = 1

scala> s.count()
13/07/27 23:24:11 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Got job 7 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Final stage: Stage 7 (count at <console>:15)
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Submitting Stage 7 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 7 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:11 INFO local.LocalTaskSetManager: Size of task 7 is 1487 bytes
13/07/27 23:24:11 INFO local.LocalScheduler: Running 7
13/07/27 23:24:11 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:11 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:11 INFO local.LocalScheduler: Finished 7
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Completed ResultTask(7, 0)
13/07/27 23:24:11 INFO local.LocalScheduler: Remove TaskSet 7.0 from pool 
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Stage 7 (count at <console>:15) finished in 0.033 s
13/07/27 23:24:11 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.035642812 s
res7: Long = 1

scala> s.count()
13/07/27 23:24:11 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Got job 8 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Final stage: Stage 8 (count at <console>:15)
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Submitting Stage 8 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 8 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:11 INFO local.LocalTaskSetManager: Size of task 8 is 1487 bytes
13/07/27 23:24:11 INFO local.LocalScheduler: Running 8
13/07/27 23:24:11 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:11 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:11 INFO local.LocalScheduler: Finished 8
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Completed ResultTask(8, 0)
13/07/27 23:24:11 INFO local.LocalScheduler: Remove TaskSet 8.0 from pool 
13/07/27 23:24:11 INFO scheduler.DAGScheduler: Stage 8 (count at <console>:15) finished in 0.030 s
13/07/27 23:24:11 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.033413593 s
res8: Long = 1

scala> s.count()
13/07/27 23:24:12 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:12 INFO scheduler.DAGScheduler: Got job 9 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:12 INFO scheduler.DAGScheduler: Final stage: Stage 9 (count at <console>:15)
13/07/27 23:24:12 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:12 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:12 INFO scheduler.DAGScheduler: Submitting Stage 9 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:12 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 9 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:12 INFO local.LocalTaskSetManager: Size of task 9 is 1487 bytes
13/07/27 23:24:12 INFO local.LocalScheduler: Running 9
13/07/27 23:24:12 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:12 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:12 INFO local.LocalScheduler: Finished 9
13/07/27 23:24:12 INFO scheduler.DAGScheduler: Completed ResultTask(9, 0)
13/07/27 23:24:12 INFO local.LocalScheduler: Remove TaskSet 9.0 from pool 
13/07/27 23:24:12 INFO scheduler.DAGScheduler: Stage 9 (count at <console>:15) finished in 0.030 s
13/07/27 23:24:12 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.032796555 s
res9: Long = 1

scala> s.count()
13/07/27 23:24:12 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:12 INFO scheduler.DAGScheduler: Got job 10 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:12 INFO scheduler.DAGScheduler: Final stage: Stage 10 (count at <console>:15)
13/07/27 23:24:12 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:12 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:12 INFO scheduler.DAGScheduler: Submitting Stage 10 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:12 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 10 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:12 INFO local.LocalTaskSetManager: Size of task 10 is 1487 bytes
13/07/27 23:24:12 INFO local.LocalScheduler: Running 10
13/07/27 23:24:12 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:12 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:12 INFO local.LocalScheduler: Finished 10
13/07/27 23:24:12 INFO scheduler.DAGScheduler: Completed ResultTask(10, 0)
13/07/27 23:24:12 INFO local.LocalScheduler: Remove TaskSet 10.0 from pool 
13/07/27 23:24:12 INFO scheduler.DAGScheduler: Stage 10 (count at <console>:15) finished in 0.022 s
13/07/27 23:24:12 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.025561161 s
res10: Long = 1

scala> 13/07/27 23:24:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:24:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:24:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:24:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:24:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:24:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:24:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:24:12 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100 as mode POSIX_FADV_DONTNEED
offset: 0
length: 55735
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:24:14 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:24:14 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:57901
Creating SparkContext...
13/07/27 23:24:24 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:24:24 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:24:24 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:24:24 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232424-c069
13/07/27 23:24:24 INFO network.ConnectionManager: Bound socket to port 49495 with id = ConnectionManagerId(tachyon-ec2-0,49495)
13/07/27 23:24:24 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:24:24 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:49495 with 1295.4 MB RAM
13/07/27 23:24:24 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:24:24 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:24:24 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:43541
13/07/27 23:24:24 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:43541
13/07/27 23:24:24 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:24:24 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-af71f3f2-d426-4c45-a62a-5d38ff6353c6
13/07/27 23:24:24 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:24:24 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:54492
13/07/27 23:24:24 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:24:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:24:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:24:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:24:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:24:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:24:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:24:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:24:24 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:24:24 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:24:24 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100").cache()
13/07/27 23:24:25 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:24:25 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:24:26 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:24:26 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:24:26 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:24:26 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:26 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:26 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:24:26 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:26 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:26 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:26 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:26 INFO local.LocalTaskSetManager: Size of task 0 is 1488 bytes
13/07/27 23:24:26 INFO local.LocalScheduler: Running 0
13/07/27 23:24:26 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:26 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:24:26 INFO storage.MemoryStore: ensureFreeSpace(116080) called with curMem=58399, maxMem=1358297825
13/07/27 23:24:26 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 113.4 KB, free 1295.2 MB)
13/07/27 23:24:26 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:49495 (size: 113.4 KB, free: 1295.3 MB)
13/07/27 23:24:26 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:24:26 INFO local.LocalScheduler: Finished 0
13/07/27 23:24:26 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:24:26 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:24:26 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.223 s
13/07/27 23:24:26 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.268200591 s
res0: Long = 100

scala> s.count()
13/07/27 23:24:26 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:26 INFO scheduler.DAGScheduler: Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:26 INFO scheduler.DAGScheduler: Final stage: Stage 1 (count at <console>:15)
13/07/27 23:24:26 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:26 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:26 INFO scheduler.DAGScheduler: Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:26 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:26 INFO local.LocalTaskSetManager: Size of task 1 is 1489 bytes
13/07/27 23:24:26 INFO local.LocalScheduler: Running 1
13/07/27 23:24:26 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:26 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:26 INFO local.LocalScheduler: Finished 1
13/07/27 23:24:26 INFO scheduler.DAGScheduler: Completed ResultTask(1, 0)
13/07/27 23:24:26 INFO local.LocalScheduler: Remove TaskSet 1.0 from pool 
13/07/27 23:24:26 INFO scheduler.DAGScheduler: Stage 1 (count at <console>:15) finished in 0.043 s
13/07/27 23:24:26 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.045214658 s
res1: Long = 100

scala> s.count()
13/07/27 23:24:27 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Final stage: Stage 2 (count at <console>:15)
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:27 INFO local.LocalTaskSetManager: Size of task 2 is 1489 bytes
13/07/27 23:24:27 INFO local.LocalScheduler: Running 2
13/07/27 23:24:27 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:27 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:27 INFO local.LocalScheduler: Finished 2
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Completed ResultTask(2, 0)
13/07/27 23:24:27 INFO local.LocalScheduler: Remove TaskSet 2.0 from pool 
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Stage 2 (count at <console>:15) finished in 0.039 s
13/07/27 23:24:27 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.041989687 s
res2: Long = 100

scala> s.count()
13/07/27 23:24:27 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Final stage: Stage 3 (count at <console>:15)
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:27 INFO local.LocalTaskSetManager: Size of task 3 is 1489 bytes
13/07/27 23:24:27 INFO local.LocalScheduler: Running 3
13/07/27 23:24:27 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:27 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:27 INFO local.LocalScheduler: Finished 3
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Completed ResultTask(3, 0)
13/07/27 23:24:27 INFO local.LocalScheduler: Remove TaskSet 3.0 from pool 
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Stage 3 (count at <console>:15) finished in 0.034 s
13/07/27 23:24:27 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.037395246 s
res3: Long = 100

scala> s.count()
13/07/27 23:24:27 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Final stage: Stage 4 (count at <console>:15)
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:27 INFO local.LocalTaskSetManager: Size of task 4 is 1489 bytes
13/07/27 23:24:27 INFO local.LocalScheduler: Running 4
13/07/27 23:24:27 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:27 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:27 INFO local.LocalScheduler: Finished 4
13/07/27 23:24:27 INFO local.LocalScheduler: Remove TaskSet 4.0 from pool 
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Completed ResultTask(4, 0)
13/07/27 23:24:27 INFO scheduler.DAGScheduler: Stage 4 (count at <console>:15) finished in 0.031 s
13/07/27 23:24:27 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.033722762 s
res4: Long = 100

scala> s.count()
13/07/27 23:24:28 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Got job 5 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Final stage: Stage 5 (count at <console>:15)
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Submitting Stage 5 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 5 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:28 INFO local.LocalTaskSetManager: Size of task 5 is 1489 bytes
13/07/27 23:24:28 INFO local.LocalScheduler: Running 5
13/07/27 23:24:28 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:28 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:28 INFO local.LocalScheduler: Finished 5
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Completed ResultTask(5, 0)
13/07/27 23:24:28 INFO local.LocalScheduler: Remove TaskSet 5.0 from pool 
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Stage 5 (count at <console>:15) finished in 0.031 s
13/07/27 23:24:28 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.033817935 s
res5: Long = 100

scala> s.count()
13/07/27 23:24:28 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Got job 6 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Final stage: Stage 6 (count at <console>:15)
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Submitting Stage 6 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 6 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:28 INFO local.LocalTaskSetManager: Size of task 6 is 1489 bytes
13/07/27 23:24:28 INFO local.LocalScheduler: Running 6
13/07/27 23:24:28 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:28 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:28 INFO local.LocalScheduler: Finished 6
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Completed ResultTask(6, 0)
13/07/27 23:24:28 INFO local.LocalScheduler: Remove TaskSet 6.0 from pool 
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Stage 6 (count at <console>:15) finished in 0.031 s
13/07/27 23:24:28 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.032803908 s
res6: Long = 100

scala> s.count()
13/07/27 23:24:28 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Got job 7 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Final stage: Stage 7 (count at <console>:15)
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Submitting Stage 7 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 7 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:28 INFO local.LocalTaskSetManager: Size of task 7 is 1489 bytes
13/07/27 23:24:28 INFO local.LocalScheduler: Running 7
13/07/27 23:24:28 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:28 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:28 INFO local.LocalScheduler: Finished 7
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Completed ResultTask(7, 0)
13/07/27 23:24:28 INFO local.LocalScheduler: Remove TaskSet 7.0 from pool 
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Stage 7 (count at <console>:15) finished in 0.032 s
13/07/27 23:24:28 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.035356065 s
res7: Long = 100

scala> s.count()
13/07/27 23:24:28 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Got job 8 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Final stage: Stage 8 (count at <console>:15)
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Submitting Stage 8 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 8 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:28 INFO local.LocalTaskSetManager: Size of task 8 is 1489 bytes
13/07/27 23:24:28 INFO local.LocalScheduler: Running 8
13/07/27 23:24:28 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:28 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:28 INFO local.LocalScheduler: Finished 8
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Completed ResultTask(8, 0)
13/07/27 23:24:28 INFO local.LocalScheduler: Remove TaskSet 8.0 from pool 
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Stage 8 (count at <console>:15) finished in 0.030 s
13/07/27 23:24:28 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.032625241 s
res8: Long = 100

scala> s.count()
13/07/27 23:24:28 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Got job 9 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Final stage: Stage 9 (count at <console>:15)
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Submitting Stage 9 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:28 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 9 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:28 INFO local.LocalTaskSetManager: Size of task 9 is 1489 bytes
13/07/27 23:24:28 INFO local.LocalScheduler: Running 9
13/07/27 23:24:29 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:29 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:29 INFO local.LocalScheduler: Finished 9
13/07/27 23:24:29 INFO scheduler.DAGScheduler: Completed ResultTask(9, 0)
13/07/27 23:24:29 INFO local.LocalScheduler: Remove TaskSet 9.0 from pool 
13/07/27 23:24:29 INFO scheduler.DAGScheduler: Stage 9 (count at <console>:15) finished in 0.030 s
13/07/27 23:24:29 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.032134865 s
res9: Long = 100

scala> s.count()
13/07/27 23:24:29 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:29 INFO scheduler.DAGScheduler: Got job 10 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:29 INFO scheduler.DAGScheduler: Final stage: Stage 10 (count at <console>:15)
13/07/27 23:24:29 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:29 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:29 INFO scheduler.DAGScheduler: Submitting Stage 10 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:29 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 10 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:29 INFO local.LocalTaskSetManager: Size of task 10 is 1489 bytes
13/07/27 23:24:29 INFO local.LocalScheduler: Running 10
13/07/27 23:24:29 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:29 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:29 INFO local.LocalScheduler: Finished 10
13/07/27 23:24:29 INFO scheduler.DAGScheduler: Completed ResultTask(10, 0)
13/07/27 23:24:29 INFO local.LocalScheduler: Remove TaskSet 10.0 from pool 
13/07/27 23:24:29 INFO scheduler.DAGScheduler: Stage 10 (count at <console>:15) finished in 0.021 s
13/07/27 23:24:29 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.023785935 s
res10: Long = 100

scala> 13/07/27 23:24:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:24:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:24:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:24:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:24:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:24:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:24:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:24:29 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.1000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 776400
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:24:31 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:24:31 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:59964
Creating SparkContext...
13/07/27 23:24:40 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:24:41 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:24:41 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:24:41 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232441-5795
13/07/27 23:24:41 INFO network.ConnectionManager: Bound socket to port 60210 with id = ConnectionManagerId(tachyon-ec2-0,60210)
13/07/27 23:24:41 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:24:41 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:60210 with 1295.4 MB RAM
13/07/27 23:24:41 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:24:41 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:24:41 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:44444
13/07/27 23:24:41 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:44444
13/07/27 23:24:41 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:24:41 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-45a70e27-1a86-432d-be70-76e393b88d7e
13/07/27 23:24:41 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:24:41 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:53817
13/07/27 23:24:41 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:24:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:24:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:24:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:24:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:24:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:24:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:24:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:24:41 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:24:41 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:24:41 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.1000").cache()
13/07/27 23:24:42 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:24:42 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:24:42 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:24:42 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:24:43 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:24:43 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:43 INFO local.LocalTaskSetManager: Size of task 0 is 1489 bytes
13/07/27 23:24:43 INFO local.LocalScheduler: Running 0
13/07/27 23:24:43 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:43 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:24:43 INFO storage.MemoryStore: ensureFreeSpace(1618123) called with curMem=58399, maxMem=1358297825
13/07/27 23:24:43 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 1580.2 KB, free 1293.8 MB)
13/07/27 23:24:43 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:60210 (size: 1580.2 KB, free: 1293.8 MB)
13/07/27 23:24:43 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:24:43 INFO local.LocalScheduler: Finished 0
13/07/27 23:24:43 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.244 s
13/07/27 23:24:43 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.287679881 s
res0: Long = 1000

scala> s.count()
13/07/27 23:24:43 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Final stage: Stage 1 (count at <console>:15)
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:43 INFO local.LocalTaskSetManager: Size of task 1 is 1490 bytes
13/07/27 23:24:43 INFO local.LocalScheduler: Running 1
13/07/27 23:24:43 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:43 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:43 INFO local.LocalScheduler: Finished 1
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Completed ResultTask(1, 0)
13/07/27 23:24:43 INFO local.LocalScheduler: Remove TaskSet 1.0 from pool 
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Stage 1 (count at <console>:15) finished in 0.042 s
13/07/27 23:24:43 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.044983342 s
res1: Long = 1000

scala> s.count()
13/07/27 23:24:43 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Final stage: Stage 2 (count at <console>:15)
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:43 INFO local.LocalTaskSetManager: Size of task 2 is 1490 bytes
13/07/27 23:24:43 INFO local.LocalScheduler: Running 2
13/07/27 23:24:43 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:43 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:43 INFO local.LocalScheduler: Finished 2
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Completed ResultTask(2, 0)
13/07/27 23:24:43 INFO local.LocalScheduler: Remove TaskSet 2.0 from pool 
13/07/27 23:24:43 INFO scheduler.DAGScheduler: Stage 2 (count at <console>:15) finished in 0.038 s
13/07/27 23:24:43 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.040908621 s
res2: Long = 1000

scala> s.count()
13/07/27 23:24:44 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Final stage: Stage 3 (count at <console>:15)
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:44 INFO local.LocalTaskSetManager: Size of task 3 is 1490 bytes
13/07/27 23:24:44 INFO local.LocalScheduler: Running 3
13/07/27 23:24:44 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:44 INFO local.LocalScheduler: Finished 3
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Completed ResultTask(3, 0)
13/07/27 23:24:44 INFO local.LocalScheduler: Remove TaskSet 3.0 from pool 
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Stage 3 (count at <console>:15) finished in 0.033 s
13/07/27 23:24:44 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.035383355 s
res3: Long = 1000

scala> s.count()
13/07/27 23:24:44 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Final stage: Stage 4 (count at <console>:15)
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:44 INFO local.LocalTaskSetManager: Size of task 4 is 1490 bytes
13/07/27 23:24:44 INFO local.LocalScheduler: Running 4
13/07/27 23:24:44 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:44 INFO local.LocalScheduler: Finished 4
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Completed ResultTask(4, 0)
13/07/27 23:24:44 INFO local.LocalScheduler: Remove TaskSet 4.0 from pool 
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Stage 4 (count at <console>:15) finished in 0.031 s
13/07/27 23:24:44 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.034222162 s
res4: Long = 1000

scala> s.count()
13/07/27 23:24:44 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Got job 5 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Final stage: Stage 5 (count at <console>:15)
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Submitting Stage 5 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 5 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:44 INFO local.LocalTaskSetManager: Size of task 5 is 1490 bytes
13/07/27 23:24:44 INFO local.LocalScheduler: Running 5
13/07/27 23:24:44 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:44 INFO local.LocalScheduler: Finished 5
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Completed ResultTask(5, 0)
13/07/27 23:24:44 INFO local.LocalScheduler: Remove TaskSet 5.0 from pool 
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Stage 5 (count at <console>:15) finished in 0.031 s
13/07/27 23:24:44 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.034271812 s
res5: Long = 1000

scala> s.count()
13/07/27 23:24:44 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Got job 6 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Final stage: Stage 6 (count at <console>:15)
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Submitting Stage 6 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 6 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:44 INFO local.LocalTaskSetManager: Size of task 6 is 1490 bytes
13/07/27 23:24:44 INFO local.LocalScheduler: Running 6
13/07/27 23:24:45 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:45 INFO local.LocalScheduler: Finished 6
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Completed ResultTask(6, 0)
13/07/27 23:24:45 INFO local.LocalScheduler: Remove TaskSet 6.0 from pool 
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Stage 6 (count at <console>:15) finished in 0.030 s
13/07/27 23:24:45 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.033134866 s
res6: Long = 1000

scala> s.count()
13/07/27 23:24:45 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Got job 7 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Final stage: Stage 7 (count at <console>:15)
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Submitting Stage 7 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 7 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:45 INFO local.LocalTaskSetManager: Size of task 7 is 1490 bytes
13/07/27 23:24:45 INFO local.LocalScheduler: Running 7
13/07/27 23:24:45 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:45 INFO local.LocalScheduler: Finished 7
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Completed ResultTask(7, 0)
13/07/27 23:24:45 INFO local.LocalScheduler: Remove TaskSet 7.0 from pool 
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Stage 7 (count at <console>:15) finished in 0.033 s
13/07/27 23:24:45 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.035644403 s
res7: Long = 1000

scala> s.count()
13/07/27 23:24:45 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Got job 8 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Final stage: Stage 8 (count at <console>:15)
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Submitting Stage 8 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 8 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:45 INFO local.LocalTaskSetManager: Size of task 8 is 1490 bytes
13/07/27 23:24:45 INFO local.LocalScheduler: Running 8
13/07/27 23:24:45 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:45 INFO local.LocalScheduler: Finished 8
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Completed ResultTask(8, 0)
13/07/27 23:24:45 INFO local.LocalScheduler: Remove TaskSet 8.0 from pool 
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Stage 8 (count at <console>:15) finished in 0.030 s
13/07/27 23:24:45 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.03288763 s
res8: Long = 1000

scala> s.count()
13/07/27 23:24:45 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Got job 9 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Final stage: Stage 9 (count at <console>:15)
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Submitting Stage 9 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 9 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:45 INFO local.LocalTaskSetManager: Size of task 9 is 1490 bytes
13/07/27 23:24:45 INFO local.LocalScheduler: Running 9
13/07/27 23:24:45 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:45 INFO local.LocalScheduler: Finished 9
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Completed ResultTask(9, 0)
13/07/27 23:24:45 INFO local.LocalScheduler: Remove TaskSet 9.0 from pool 
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Stage 9 (count at <console>:15) finished in 0.030 s
13/07/27 23:24:45 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.03289034 s
res9: Long = 1000

scala> s.count()
13/07/27 23:24:45 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Got job 10 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Final stage: Stage 10 (count at <console>:15)
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Submitting Stage 10 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 10 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:45 INFO local.LocalTaskSetManager: Size of task 10 is 1490 bytes
13/07/27 23:24:45 INFO local.LocalScheduler: Running 10
13/07/27 23:24:45 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:24:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:24:45 INFO local.LocalScheduler: Finished 10
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Completed ResultTask(10, 0)
13/07/27 23:24:45 INFO local.LocalScheduler: Remove TaskSet 10.0 from pool 
13/07/27 23:24:45 INFO scheduler.DAGScheduler: Stage 10 (count at <console>:15) finished in 0.024 s
13/07/27 23:24:45 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.026921521 s
res10: Long = 1000

scala> 13/07/27 23:24:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:24:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:24:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:24:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:24:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:24:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:24:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:24:46 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.10000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 12330369
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:24:48 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:24:48 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:41010
Creating SparkContext...
13/07/27 23:24:57 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:24:58 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:24:58 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:24:58 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232458-d38b
13/07/27 23:24:58 INFO network.ConnectionManager: Bound socket to port 35676 with id = ConnectionManagerId(tachyon-ec2-0,35676)
13/07/27 23:24:58 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:24:58 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:35676 with 1295.4 MB RAM
13/07/27 23:24:58 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:24:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:24:58 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:48903
13/07/27 23:24:58 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:48903
13/07/27 23:24:58 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:24:58 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-8b32989a-3b06-4abe-92a2-b54a048154df
13/07/27 23:24:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:24:58 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:33395
13/07/27 23:24:58 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:24:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:24:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:24:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:24:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:24:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:24:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:24:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:24:58 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:24:58 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:24:58 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.10000").cache()
13/07/27 23:24:59 INFO storage.MemoryStore: ensureFreeSpace(58399) called with curMem=0, maxMem=1358297825
13/07/27 23:24:59 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:24:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:24:59 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:24:59 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:24:59 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:24:59 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:24:59 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:24:59 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:24:59 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:24:59 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:24:59 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:24:59 INFO local.LocalTaskSetManager: Size of task 0 is 1490 bytes
13/07/27 23:24:59 INFO local.LocalScheduler: Running 0
13/07/27 23:25:00 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:00 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:25:00 INFO storage.MemoryStore: ensureFreeSpace(26215750) called with curMem=58399, maxMem=1358297825
13/07/27 23:25:00 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 25.0 MB, free 1270.3 MB)
13/07/27 23:25:00 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:35676 (size: 25.0 MB, free: 1270.4 MB)
13/07/27 23:25:00 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:25:00 INFO local.LocalScheduler: Finished 0
13/07/27 23:25:00 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 0.410 s
13/07/27 23:25:00 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.453219162 s
res0: Long = 10000

scala> s.count()
13/07/27 23:25:00 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Got job 1 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Final stage: Stage 1 (count at <console>:15)
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:00 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:25:00 INFO local.LocalScheduler: Running 1
13/07/27 23:25:00 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:00 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:00 INFO local.LocalScheduler: Finished 1
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Completed ResultTask(1, 0)
13/07/27 23:25:00 INFO local.LocalScheduler: Remove TaskSet 1.0 from pool 
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Stage 1 (count at <console>:15) finished in 0.044 s
13/07/27 23:25:00 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.046531456 s
res1: Long = 10000

scala> s.count()
13/07/27 23:25:00 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Got job 2 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Final stage: Stage 2 (count at <console>:15)
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:00 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:25:00 INFO local.LocalScheduler: Running 2
13/07/27 23:25:00 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:00 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:00 INFO local.LocalScheduler: Finished 2
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Completed ResultTask(2, 0)
13/07/27 23:25:00 INFO local.LocalScheduler: Remove TaskSet 2.0 from pool 
13/07/27 23:25:00 INFO scheduler.DAGScheduler: Stage 2 (count at <console>:15) finished in 0.037 s
13/07/27 23:25:00 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.039847986 s
res2: Long = 10000

scala> s.count()
13/07/27 23:25:01 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Got job 3 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Final stage: Stage 3 (count at <console>:15)
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:01 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:25:01 INFO local.LocalScheduler: Running 3
13/07/27 23:25:01 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:01 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:01 INFO local.LocalScheduler: Finished 3
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Completed ResultTask(3, 0)
13/07/27 23:25:01 INFO local.LocalScheduler: Remove TaskSet 3.0 from pool 
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Stage 3 (count at <console>:15) finished in 0.033 s
13/07/27 23:25:01 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.036284906 s
res3: Long = 10000

scala> s.count()
13/07/27 23:25:01 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Got job 4 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Final stage: Stage 4 (count at <console>:15)
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:01 INFO local.LocalTaskSetManager: Size of task 4 is 1491 bytes
13/07/27 23:25:01 INFO local.LocalScheduler: Running 4
13/07/27 23:25:01 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:01 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:01 INFO local.LocalScheduler: Finished 4
13/07/27 23:25:01 INFO local.LocalScheduler: Remove TaskSet 4.0 from pool 
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Completed ResultTask(4, 0)
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Stage 4 (count at <console>:15) finished in 0.031 s
13/07/27 23:25:01 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.034443106 s
res4: Long = 10000

scala> s.count()
13/07/27 23:25:01 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Got job 5 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Final stage: Stage 5 (count at <console>:15)
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Submitting Stage 5 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 5 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:01 INFO local.LocalTaskSetManager: Size of task 5 is 1491 bytes
13/07/27 23:25:01 INFO local.LocalScheduler: Running 5
13/07/27 23:25:01 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:01 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:01 INFO local.LocalScheduler: Finished 5
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Completed ResultTask(5, 0)
13/07/27 23:25:01 INFO local.LocalScheduler: Remove TaskSet 5.0 from pool 
13/07/27 23:25:01 INFO scheduler.DAGScheduler: Stage 5 (count at <console>:15) finished in 0.031 s
13/07/27 23:25:01 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.033887125 s
res5: Long = 10000

scala> s.count()
13/07/27 23:25:02 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Got job 6 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Final stage: Stage 6 (count at <console>:15)
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Submitting Stage 6 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 6 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:02 INFO local.LocalTaskSetManager: Size of task 6 is 1491 bytes
13/07/27 23:25:02 INFO local.LocalScheduler: Running 6
13/07/27 23:25:02 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:02 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:02 INFO local.LocalScheduler: Finished 6
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Completed ResultTask(6, 0)
13/07/27 23:25:02 INFO local.LocalScheduler: Remove TaskSet 6.0 from pool 
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Stage 6 (count at <console>:15) finished in 0.030 s
13/07/27 23:25:02 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.033220035 s
res6: Long = 10000

scala> s.count()
13/07/27 23:25:02 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Got job 7 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Final stage: Stage 7 (count at <console>:15)
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Submitting Stage 7 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 7 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:02 INFO local.LocalTaskSetManager: Size of task 7 is 1491 bytes
13/07/27 23:25:02 INFO local.LocalScheduler: Running 7
13/07/27 23:25:02 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:02 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:02 INFO local.LocalScheduler: Finished 7
13/07/27 23:25:02 INFO local.LocalScheduler: Remove TaskSet 7.0 from pool 
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Completed ResultTask(7, 0)
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Stage 7 (count at <console>:15) finished in 0.033 s
13/07/27 23:25:02 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.035634776 s
res7: Long = 10000

scala> s.count()
13/07/27 23:25:02 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Got job 8 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Final stage: Stage 8 (count at <console>:15)
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Submitting Stage 8 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 8 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:02 INFO local.LocalTaskSetManager: Size of task 8 is 1491 bytes
13/07/27 23:25:02 INFO local.LocalScheduler: Running 8
13/07/27 23:25:02 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:02 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:02 INFO local.LocalScheduler: Finished 8
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Completed ResultTask(8, 0)
13/07/27 23:25:02 INFO local.LocalScheduler: Remove TaskSet 8.0 from pool 
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Stage 8 (count at <console>:15) finished in 0.029 s
13/07/27 23:25:02 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.032379678 s
res8: Long = 10000

scala> s.count()
13/07/27 23:25:02 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Got job 9 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Final stage: Stage 9 (count at <console>:15)
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Submitting Stage 9 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 9 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:02 INFO local.LocalTaskSetManager: Size of task 9 is 1491 bytes
13/07/27 23:25:02 INFO local.LocalScheduler: Running 9
13/07/27 23:25:02 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:02 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:02 INFO local.LocalScheduler: Finished 9
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Completed ResultTask(9, 0)
13/07/27 23:25:02 INFO local.LocalScheduler: Remove TaskSet 9.0 from pool 
13/07/27 23:25:02 INFO scheduler.DAGScheduler: Stage 9 (count at <console>:15) finished in 0.040 s
13/07/27 23:25:02 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.042983642 s
res9: Long = 10000

scala> s.count()
13/07/27 23:25:03 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:03 INFO scheduler.DAGScheduler: Got job 10 (count at <console>:15) with 1 output partitions (allowLocal=false)
13/07/27 23:25:03 INFO scheduler.DAGScheduler: Final stage: Stage 10 (count at <console>:15)
13/07/27 23:25:03 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:03 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:03 INFO scheduler.DAGScheduler: Submitting Stage 10 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:03 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 10 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:03 INFO local.LocalTaskSetManager: Size of task 10 is 1491 bytes
13/07/27 23:25:03 INFO local.LocalScheduler: Running 10
13/07/27 23:25:03 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:03 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:03 INFO local.LocalScheduler: Finished 10
13/07/27 23:25:03 INFO scheduler.DAGScheduler: Completed ResultTask(10, 0)
13/07/27 23:25:03 INFO local.LocalScheduler: Remove TaskSet 10.0 from pool 
13/07/27 23:25:03 INFO scheduler.DAGScheduler: Stage 10 (count at <console>:15) finished in 0.021 s
13/07/27 23:25:03 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.024225919 s
res10: Long = 10000

scala> 13/07/27 23:25:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:25:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:25:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:25:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:25:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:25:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:25:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:25:03 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.100000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 125141299
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:25:05 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:25:05 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:38479
Creating SparkContext...
13/07/27 23:25:14 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:25:15 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:25:15 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:25:15 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232515-bd5a
13/07/27 23:25:15 INFO network.ConnectionManager: Bound socket to port 50243 with id = ConnectionManagerId(tachyon-ec2-0,50243)
13/07/27 23:25:15 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:25:15 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:50243 with 1295.4 MB RAM
13/07/27 23:25:15 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:25:15 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:25:15 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:52495
13/07/27 23:25:15 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:52495
13/07/27 23:25:15 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:25:15 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-3168fa72-80c1-4179-8943-f6047496699b
13/07/27 23:25:15 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:25:15 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:44882
13/07/27 23:25:15 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:25:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:25:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:25:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:25:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:25:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:25:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:25:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:25:15 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:25:15 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:25:15 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.100000").cache()
13/07/27 23:25:16 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:25:16 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:25:16 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:25:16 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:25:16 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:25:16 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:16 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:25:16 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:25:16 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:16 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:16 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:16 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:17 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:25:17 INFO local.LocalScheduler: Running 0
13/07/27 23:25:17 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:17 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:25:17 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:25:17 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:25:17 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:50243 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:25:17 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:25:17 INFO local.LocalScheduler: Finished 0
13/07/27 23:25:17 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:25:17 INFO local.LocalScheduler: Running 1
13/07/27 23:25:17 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:25:17 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:17 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:25:17 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:25:17 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:25:17 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:50243 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:25:17 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:25:17 INFO local.LocalScheduler: Finished 1
13/07/27 23:25:17 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:25:17 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:25:17 INFO local.LocalScheduler: Running 2
13/07/27 23:25:17 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:17 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:25:18 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:25:18 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:25:18 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:50243 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:25:18 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:25:18 INFO local.LocalScheduler: Finished 2
13/07/27 23:25:18 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:25:18 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:25:18 INFO local.LocalScheduler: Running 3
13/07/27 23:25:18 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:18 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:25:18 INFO storage.MemoryStore: ensureFreeSpace(52232232) called with curMem=211087067, maxMem=1358297825
13/07/27 23:25:18 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 49.8 MB, free 1044.3 MB)
13/07/27 23:25:18 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:50243 (size: 49.8 MB, free: 1044.3 MB)
13/07/27 23:25:18 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:25:18 INFO local.LocalScheduler: Finished 3
13/07/27 23:25:18 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:25:18 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:25:18 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 1.626 s
13/07/27 23:25:18 INFO spark.SparkContext: Job finished: count at <console>:15, took 1.672633237 s
res0: Long = 100002

scala> s.count()
13/07/27 23:25:18 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:18 INFO scheduler.DAGScheduler: Got job 1 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:25:18 INFO scheduler.DAGScheduler: Final stage: Stage 1 (count at <console>:15)
13/07/27 23:25:18 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:18 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:18 INFO scheduler.DAGScheduler: Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:18 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:18 INFO local.LocalTaskSetManager: Size of task 4 is 1492 bytes
13/07/27 23:25:18 INFO local.LocalScheduler: Running 4
13/07/27 23:25:18 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:18 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:18 INFO local.LocalScheduler: Finished 4
13/07/27 23:25:18 INFO scheduler.DAGScheduler: Completed ResultTask(1, 0)
13/07/27 23:25:18 INFO local.LocalTaskSetManager: Size of task 5 is 1492 bytes
13/07/27 23:25:18 INFO local.LocalScheduler: Running 5
13/07/27 23:25:18 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:18 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:18 INFO local.LocalScheduler: Finished 5
13/07/27 23:25:18 INFO scheduler.DAGScheduler: Completed ResultTask(1, 1)
13/07/27 23:25:18 INFO local.LocalTaskSetManager: Size of task 6 is 1492 bytes
13/07/27 23:25:18 INFO local.LocalScheduler: Running 6
13/07/27 23:25:18 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:18 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:18 INFO local.LocalScheduler: Finished 6
13/07/27 23:25:18 INFO scheduler.DAGScheduler: Completed ResultTask(1, 2)
13/07/27 23:25:18 INFO local.LocalTaskSetManager: Size of task 7 is 1492 bytes
13/07/27 23:25:18 INFO local.LocalScheduler: Running 7
13/07/27 23:25:19 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:19 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:19 INFO local.LocalScheduler: Finished 7
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Completed ResultTask(1, 3)
13/07/27 23:25:19 INFO local.LocalScheduler: Remove TaskSet 1.0 from pool 
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Stage 1 (count at <console>:15) finished in 0.118 s
13/07/27 23:25:19 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.122392717 s
res1: Long = 100002

scala> s.count()
13/07/27 23:25:19 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Got job 2 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Final stage: Stage 2 (count at <console>:15)
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:19 INFO local.LocalTaskSetManager: Size of task 8 is 1492 bytes
13/07/27 23:25:19 INFO local.LocalScheduler: Running 8
13/07/27 23:25:19 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:19 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:19 INFO local.LocalScheduler: Finished 8
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Completed ResultTask(2, 0)
13/07/27 23:25:19 INFO local.LocalTaskSetManager: Size of task 9 is 1492 bytes
13/07/27 23:25:19 INFO local.LocalScheduler: Running 9
13/07/27 23:25:19 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:19 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:19 INFO local.LocalScheduler: Finished 9
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Completed ResultTask(2, 1)
13/07/27 23:25:19 INFO local.LocalTaskSetManager: Size of task 10 is 1492 bytes
13/07/27 23:25:19 INFO local.LocalScheduler: Running 10
13/07/27 23:25:19 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:19 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:19 INFO local.LocalScheduler: Finished 10
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Completed ResultTask(2, 2)
13/07/27 23:25:19 INFO local.LocalTaskSetManager: Size of task 11 is 1492 bytes
13/07/27 23:25:19 INFO local.LocalScheduler: Running 11
13/07/27 23:25:19 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:19 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:19 INFO local.LocalScheduler: Finished 11
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Completed ResultTask(2, 3)
13/07/27 23:25:19 INFO local.LocalScheduler: Remove TaskSet 2.0 from pool 
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Stage 2 (count at <console>:15) finished in 0.113 s
13/07/27 23:25:19 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.116204393 s
res2: Long = 100002

scala> s.count()
13/07/27 23:25:19 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Got job 3 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Final stage: Stage 3 (count at <console>:15)
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:19 INFO local.LocalTaskSetManager: Size of task 12 is 1492 bytes
13/07/27 23:25:19 INFO local.LocalScheduler: Running 12
13/07/27 23:25:19 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:19 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:19 INFO local.LocalScheduler: Finished 12
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Completed ResultTask(3, 0)
13/07/27 23:25:19 INFO local.LocalTaskSetManager: Size of task 13 is 1492 bytes
13/07/27 23:25:19 INFO local.LocalScheduler: Running 13
13/07/27 23:25:19 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:19 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:19 INFO local.LocalScheduler: Finished 13
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Completed ResultTask(3, 1)
13/07/27 23:25:19 INFO local.LocalTaskSetManager: Size of task 14 is 1492 bytes
13/07/27 23:25:19 INFO local.LocalScheduler: Running 14
13/07/27 23:25:19 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:19 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:19 INFO local.LocalScheduler: Finished 14
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Completed ResultTask(3, 2)
13/07/27 23:25:19 INFO local.LocalTaskSetManager: Size of task 15 is 1492 bytes
13/07/27 23:25:19 INFO local.LocalScheduler: Running 15
13/07/27 23:25:19 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:19 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:19 INFO local.LocalScheduler: Finished 15
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Completed ResultTask(3, 3)
13/07/27 23:25:19 INFO local.LocalScheduler: Remove TaskSet 3.0 from pool 
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Stage 3 (count at <console>:15) finished in 0.081 s
13/07/27 23:25:19 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.084610937 s
res3: Long = 100002

scala> s.count()
13/07/27 23:25:19 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Got job 4 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Final stage: Stage 4 (count at <console>:15)
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:19 INFO local.LocalTaskSetManager: Size of task 16 is 1492 bytes
13/07/27 23:25:19 INFO local.LocalScheduler: Running 16
13/07/27 23:25:19 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:19 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:19 INFO local.LocalScheduler: Finished 16
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Completed ResultTask(4, 0)
13/07/27 23:25:19 INFO local.LocalTaskSetManager: Size of task 17 is 1492 bytes
13/07/27 23:25:19 INFO local.LocalScheduler: Running 17
13/07/27 23:25:19 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:19 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:19 INFO local.LocalScheduler: Finished 17
13/07/27 23:25:19 INFO scheduler.DAGScheduler: Completed ResultTask(4, 1)
13/07/27 23:25:19 INFO local.LocalTaskSetManager: Size of task 18 is 1492 bytes
13/07/27 23:25:19 INFO local.LocalScheduler: Running 18
13/07/27 23:25:20 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:20 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:20 INFO local.LocalScheduler: Finished 18
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Completed ResultTask(4, 2)
13/07/27 23:25:20 INFO local.LocalTaskSetManager: Size of task 19 is 1492 bytes
13/07/27 23:25:20 INFO local.LocalScheduler: Running 19
13/07/27 23:25:20 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:20 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:20 INFO local.LocalScheduler: Finished 19
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Completed ResultTask(4, 3)
13/07/27 23:25:20 INFO local.LocalScheduler: Remove TaskSet 4.0 from pool 
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Stage 4 (count at <console>:15) finished in 0.073 s
13/07/27 23:25:20 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.076830131 s
res4: Long = 100002

scala> s.count()
13/07/27 23:25:20 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Got job 5 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Final stage: Stage 5 (count at <console>:15)
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Submitting Stage 5 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 5 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:20 INFO local.LocalTaskSetManager: Size of task 20 is 1492 bytes
13/07/27 23:25:20 INFO local.LocalScheduler: Running 20
13/07/27 23:25:20 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:20 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:20 INFO local.LocalScheduler: Finished 20
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Completed ResultTask(5, 0)
13/07/27 23:25:20 INFO local.LocalTaskSetManager: Size of task 21 is 1492 bytes
13/07/27 23:25:20 INFO local.LocalScheduler: Running 21
13/07/27 23:25:20 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:20 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:20 INFO local.LocalScheduler: Finished 21
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Completed ResultTask(5, 1)
13/07/27 23:25:20 INFO local.LocalTaskSetManager: Size of task 22 is 1492 bytes
13/07/27 23:25:20 INFO local.LocalScheduler: Running 22
13/07/27 23:25:20 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:20 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:20 INFO local.LocalScheduler: Finished 22
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Completed ResultTask(5, 2)
13/07/27 23:25:20 INFO local.LocalTaskSetManager: Size of task 23 is 1492 bytes
13/07/27 23:25:20 INFO local.LocalScheduler: Running 23
13/07/27 23:25:20 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:20 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:20 INFO local.LocalScheduler: Finished 23
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Completed ResultTask(5, 3)
13/07/27 23:25:20 INFO local.LocalScheduler: Remove TaskSet 5.0 from pool 
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Stage 5 (count at <console>:15) finished in 0.075 s
13/07/27 23:25:20 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.078260793 s
res5: Long = 100002

scala> s.count()
13/07/27 23:25:20 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Got job 6 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Final stage: Stage 6 (count at <console>:15)
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Submitting Stage 6 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 6 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:20 INFO local.LocalTaskSetManager: Size of task 24 is 1492 bytes
13/07/27 23:25:20 INFO local.LocalScheduler: Running 24
13/07/27 23:25:20 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:20 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:20 INFO local.LocalScheduler: Finished 24
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Completed ResultTask(6, 0)
13/07/27 23:25:20 INFO local.LocalTaskSetManager: Size of task 25 is 1492 bytes
13/07/27 23:25:20 INFO local.LocalScheduler: Running 25
13/07/27 23:25:20 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:20 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:20 INFO local.LocalScheduler: Finished 25
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Completed ResultTask(6, 1)
13/07/27 23:25:20 INFO local.LocalTaskSetManager: Size of task 26 is 1492 bytes
13/07/27 23:25:20 INFO local.LocalScheduler: Running 26
13/07/27 23:25:20 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:20 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:20 INFO local.LocalScheduler: Finished 26
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Completed ResultTask(6, 2)
13/07/27 23:25:20 INFO local.LocalTaskSetManager: Size of task 27 is 1492 bytes
13/07/27 23:25:20 INFO local.LocalScheduler: Running 27
13/07/27 23:25:20 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:20 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:20 INFO local.LocalScheduler: Finished 27
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Completed ResultTask(6, 3)
13/07/27 23:25:20 INFO local.LocalScheduler: Remove TaskSet 6.0 from pool 
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Stage 6 (count at <console>:15) finished in 0.069 s
13/07/27 23:25:20 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.071961123 s
res6: Long = 100002

scala> s.count()
13/07/27 23:25:20 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Got job 7 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Final stage: Stage 7 (count at <console>:15)
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Submitting Stage 7 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 7 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:20 INFO local.LocalTaskSetManager: Size of task 28 is 1492 bytes
13/07/27 23:25:20 INFO local.LocalScheduler: Running 28
13/07/27 23:25:20 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:20 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:20 INFO local.LocalScheduler: Finished 28
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Completed ResultTask(7, 0)
13/07/27 23:25:20 INFO local.LocalTaskSetManager: Size of task 29 is 1492 bytes
13/07/27 23:25:20 INFO local.LocalScheduler: Running 29
13/07/27 23:25:20 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:20 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:20 INFO local.LocalScheduler: Finished 29
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Completed ResultTask(7, 1)
13/07/27 23:25:20 INFO local.LocalTaskSetManager: Size of task 30 is 1492 bytes
13/07/27 23:25:20 INFO local.LocalScheduler: Running 30
13/07/27 23:25:20 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:20 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:20 INFO local.LocalScheduler: Finished 30
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Completed ResultTask(7, 2)
13/07/27 23:25:20 INFO local.LocalTaskSetManager: Size of task 31 is 1492 bytes
13/07/27 23:25:20 INFO local.LocalScheduler: Running 31
13/07/27 23:25:20 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:20 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:20 INFO local.LocalScheduler: Finished 31
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Completed ResultTask(7, 3)
13/07/27 23:25:20 INFO local.LocalScheduler: Remove TaskSet 7.0 from pool 
13/07/27 23:25:20 INFO scheduler.DAGScheduler: Stage 7 (count at <console>:15) finished in 0.066 s
13/07/27 23:25:20 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.069465329 s
res7: Long = 100002

scala> s.count()
13/07/27 23:25:21 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Got job 8 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Final stage: Stage 8 (count at <console>:15)
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Submitting Stage 8 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 8 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:21 INFO local.LocalTaskSetManager: Size of task 32 is 1492 bytes
13/07/27 23:25:21 INFO local.LocalScheduler: Running 32
13/07/27 23:25:21 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:21 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:21 INFO local.LocalScheduler: Finished 32
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Completed ResultTask(8, 0)
13/07/27 23:25:21 INFO local.LocalTaskSetManager: Size of task 33 is 1492 bytes
13/07/27 23:25:21 INFO local.LocalScheduler: Running 33
13/07/27 23:25:21 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:21 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:21 INFO local.LocalScheduler: Finished 33
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Completed ResultTask(8, 1)
13/07/27 23:25:21 INFO local.LocalTaskSetManager: Size of task 34 is 1492 bytes
13/07/27 23:25:21 INFO local.LocalScheduler: Running 34
13/07/27 23:25:21 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:21 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:21 INFO local.LocalScheduler: Finished 34
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Completed ResultTask(8, 2)
13/07/27 23:25:21 INFO local.LocalTaskSetManager: Size of task 35 is 1492 bytes
13/07/27 23:25:21 INFO local.LocalScheduler: Running 35
13/07/27 23:25:21 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:21 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:21 INFO local.LocalScheduler: Finished 35
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Completed ResultTask(8, 3)
13/07/27 23:25:21 INFO local.LocalScheduler: Remove TaskSet 8.0 from pool 
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Stage 8 (count at <console>:15) finished in 0.065 s
13/07/27 23:25:21 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.067854416 s
res8: Long = 100002

scala> s.count()
13/07/27 23:25:21 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Got job 9 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Final stage: Stage 9 (count at <console>:15)
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Submitting Stage 9 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 9 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:21 INFO local.LocalTaskSetManager: Size of task 36 is 1492 bytes
13/07/27 23:25:21 INFO local.LocalScheduler: Running 36
13/07/27 23:25:21 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:21 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:21 INFO local.LocalScheduler: Finished 36
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Completed ResultTask(9, 0)
13/07/27 23:25:21 INFO local.LocalTaskSetManager: Size of task 37 is 1492 bytes
13/07/27 23:25:21 INFO local.LocalScheduler: Running 37
13/07/27 23:25:21 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:21 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:21 INFO local.LocalScheduler: Finished 37
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Completed ResultTask(9, 1)
13/07/27 23:25:21 INFO local.LocalTaskSetManager: Size of task 38 is 1492 bytes
13/07/27 23:25:21 INFO local.LocalScheduler: Running 38
13/07/27 23:25:21 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:21 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:21 INFO local.LocalScheduler: Finished 38
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Completed ResultTask(9, 2)
13/07/27 23:25:21 INFO local.LocalTaskSetManager: Size of task 39 is 1492 bytes
13/07/27 23:25:21 INFO local.LocalScheduler: Running 39
13/07/27 23:25:21 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:21 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:21 INFO local.LocalScheduler: Finished 39
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Completed ResultTask(9, 3)
13/07/27 23:25:21 INFO local.LocalScheduler: Remove TaskSet 9.0 from pool 
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Stage 9 (count at <console>:15) finished in 0.064 s
13/07/27 23:25:21 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.066681218 s
res9: Long = 100002

scala> s.count()
13/07/27 23:25:21 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Got job 10 (count at <console>:15) with 4 output partitions (allowLocal=false)
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Final stage: Stage 10 (count at <console>:15)
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Submitting Stage 10 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from Stage 10 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:21 INFO local.LocalTaskSetManager: Size of task 40 is 1492 bytes
13/07/27 23:25:21 INFO local.LocalScheduler: Running 40
13/07/27 23:25:21 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:21 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:21 INFO local.LocalScheduler: Finished 40
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Completed ResultTask(10, 0)
13/07/27 23:25:21 INFO local.LocalTaskSetManager: Size of task 41 is 1492 bytes
13/07/27 23:25:21 INFO local.LocalScheduler: Running 41
13/07/27 23:25:21 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:21 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:21 INFO local.LocalScheduler: Finished 41
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Completed ResultTask(10, 1)
13/07/27 23:25:21 INFO local.LocalTaskSetManager: Size of task 42 is 1492 bytes
13/07/27 23:25:21 INFO local.LocalScheduler: Running 42
13/07/27 23:25:21 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:21 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:21 INFO local.LocalScheduler: Finished 42
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Completed ResultTask(10, 2)
13/07/27 23:25:21 INFO local.LocalTaskSetManager: Size of task 43 is 1492 bytes
13/07/27 23:25:21 INFO local.LocalScheduler: Running 43
13/07/27 23:25:21 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:21 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:21 INFO local.LocalScheduler: Finished 43
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Completed ResultTask(10, 3)
13/07/27 23:25:21 INFO local.LocalScheduler: Remove TaskSet 10.0 from pool 
13/07/27 23:25:21 INFO scheduler.DAGScheduler: Stage 10 (count at <console>:15) finished in 0.062 s
13/07/27 23:25:21 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.064050995 s
res10: Long = 100002

scala> 13/07/27 23:25:21 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:25:21 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:25:21 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:25:21 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:25:21 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:25:21 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:25:21 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:25:21 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
spark-shell count

Going to fadvise /mnt/tachyon/hit_data.tsv.500000 as mode POSIX_FADV_DONTNEED
offset: 0
length: 618418417
mode: POSIX_FADV_DONTNEED
WIN
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/work/tachyon/target/tachyon-0.3.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/work/spark/lib_managed/jars/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Welcome to
      ____              __  
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 0.8.0
      /_/                  

Using Scala version 2.9.3 (OpenJDK 64-Bit Server VM, Java 1.7.0_25)
Initializing interpreter...
13/07/27 23:25:24 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:25:24 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:37438
Creating SparkContext...
13/07/27 23:25:33 INFO slf4j.Slf4jEventHandler: Slf4jEventHandler started
13/07/27 23:25:33 INFO spark.SparkEnv: Registering BlockManagerMaster
13/07/27 23:25:33 INFO storage.MemoryStore: MemoryStore started with capacity 1295.4 MB.
13/07/27 23:25:33 INFO storage.DiskStore: Created local directory at /tmp/spark-local-20130727232533-26bf
13/07/27 23:25:33 INFO network.ConnectionManager: Bound socket to port 38215 with id = ConnectionManagerId(tachyon-ec2-0,38215)
13/07/27 23:25:33 INFO storage.BlockManagerMaster: Trying to register BlockManager
13/07/27 23:25:33 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Registering block manager tachyon-ec2-0:38215 with 1295.4 MB RAM
13/07/27 23:25:33 INFO storage.BlockManagerMaster: Registered BlockManager
13/07/27 23:25:33 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:25:33 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:40378
13/07/27 23:25:33 INFO broadcast.HttpBroadcast: Broadcast server started at http://10.151.80.188:40378
13/07/27 23:25:33 INFO spark.SparkEnv: Registering MapOutputTracker
13/07/27 23:25:33 INFO spark.HttpFileServer: HTTP File server directory is /tmp/spark-83dd8b45-774c-4a82-b4ba-987948cbc852
13/07/27 23:25:33 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:25:33 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:42104
13/07/27 23:25:33 INFO server.Server: jetty-7.x.y-SNAPSHOT
13/07/27 23:25:33 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage/rdd,null}
13/07/27 23:25:33 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:25:33 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:25:33 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:25:33 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:25:33 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:25:33 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:25:33 INFO handler.ContextHandler: started o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:25:33 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:33000
13/07/27 23:25:34 INFO ui.SparkUI: Started Spark Web UI at http://tachyon-ec2-0:33000
Spark context available as sc.
Type in expressions to have them evaluated.
Type :help for more information.

scala> val s = sc.textFile("/mnt/tachyon/hit_data.tsv.500000").cache()
13/07/27 23:25:35 INFO storage.MemoryStore: ensureFreeSpace(58407) called with curMem=0, maxMem=1358297825
13/07/27 23:25:35 INFO storage.MemoryStore: Block broadcast_0 stored as values to memory (estimated size 57.0 KB, free 1295.3 MB)
s: spark.RDD[String] = MappedRDD[1] at textFile at <console>:12

scala> s.count()
13/07/27 23:25:35 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/07/27 23:25:35 WARN snappy.LoadSnappy: Snappy native library not loaded
13/07/27 23:25:35 INFO mapred.FileInputFormat: Total input paths to process : 1
13/07/27 23:25:35 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:35 INFO scheduler.DAGScheduler: Got job 0 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:25:35 INFO scheduler.DAGScheduler: Final stage: Stage 0 (count at <console>:15)
13/07/27 23:25:35 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:35 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:35 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:35 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 0 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:35 INFO local.LocalTaskSetManager: Size of task 0 is 1491 bytes
13/07/27 23:25:35 INFO local.LocalScheduler: Running 0
13/07/27 23:25:35 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:35 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@691
13/07/27 23:25:36 INFO storage.MemoryStore: ensureFreeSpace(71775067) called with curMem=58407, maxMem=1358297825
13/07/27 23:25:36 INFO storage.MemoryStore: Block rdd_1_0 stored as values to memory (estimated size 68.5 MB, free 1226.9 MB)
13/07/27 23:25:36 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_0 in memory on tachyon-ec2-0:38215 (size: 68.5 MB, free: 1226.9 MB)
13/07/27 23:25:36 INFO storage.BlockManagerMaster: Updated info of block rdd_1_0
13/07/27 23:25:36 INFO local.LocalScheduler: Finished 0
13/07/27 23:25:36 INFO local.LocalTaskSetManager: Size of task 1 is 1491 bytes
13/07/27 23:25:36 INFO local.LocalScheduler: Running 1
13/07/27 23:25:36 INFO scheduler.DAGScheduler: Completed ResultTask(0, 0)
13/07/27 23:25:36 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:36 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@692
13/07/27 23:25:36 INFO storage.MemoryStore: ensureFreeSpace(69746072) called with curMem=71833474, maxMem=1358297825
13/07/27 23:25:36 INFO storage.MemoryStore: Block rdd_1_1 stored as values to memory (estimated size 66.5 MB, free 1160.4 MB)
13/07/27 23:25:36 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_1 in memory on tachyon-ec2-0:38215 (size: 66.5 MB, free: 1160.4 MB)
13/07/27 23:25:36 INFO storage.BlockManagerMaster: Updated info of block rdd_1_1
13/07/27 23:25:36 INFO local.LocalScheduler: Finished 1
13/07/27 23:25:36 INFO scheduler.DAGScheduler: Completed ResultTask(0, 1)
13/07/27 23:25:36 INFO local.LocalTaskSetManager: Size of task 2 is 1491 bytes
13/07/27 23:25:36 INFO local.LocalScheduler: Running 2
13/07/27 23:25:36 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:36 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@693
13/07/27 23:25:37 INFO storage.MemoryStore: ensureFreeSpace(69507521) called with curMem=141579546, maxMem=1358297825
13/07/27 23:25:37 INFO storage.MemoryStore: Block rdd_1_2 stored as values to memory (estimated size 66.3 MB, free 1094.1 MB)
13/07/27 23:25:37 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_2 in memory on tachyon-ec2-0:38215 (size: 66.3 MB, free: 1094.1 MB)
13/07/27 23:25:37 INFO storage.BlockManagerMaster: Updated info of block rdd_1_2
13/07/27 23:25:37 INFO local.LocalScheduler: Finished 2
13/07/27 23:25:37 INFO scheduler.DAGScheduler: Completed ResultTask(0, 2)
13/07/27 23:25:37 INFO local.LocalTaskSetManager: Size of task 3 is 1491 bytes
13/07/27 23:25:37 INFO local.LocalScheduler: Running 3
13/07/27 23:25:37 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:37 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@694
13/07/27 23:25:37 INFO storage.MemoryStore: ensureFreeSpace(73224723) called with curMem=211087067, maxMem=1358297825
13/07/27 23:25:37 INFO storage.MemoryStore: Block rdd_1_3 stored as values to memory (estimated size 69.8 MB, free 1024.2 MB)
13/07/27 23:25:37 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_3 in memory on tachyon-ec2-0:38215 (size: 69.8 MB, free: 1024.3 MB)
13/07/27 23:25:37 INFO storage.BlockManagerMaster: Updated info of block rdd_1_3
13/07/27 23:25:37 INFO local.LocalScheduler: Finished 3
13/07/27 23:25:37 INFO scheduler.DAGScheduler: Completed ResultTask(0, 3)
13/07/27 23:25:37 INFO local.LocalTaskSetManager: Size of task 4 is 1491 bytes
13/07/27 23:25:37 INFO local.LocalScheduler: Running 4
13/07/27 23:25:37 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:25:37 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@695
13/07/27 23:25:37 INFO storage.MemoryStore: ensureFreeSpace(72058182) called with curMem=284311790, maxMem=1358297825
13/07/27 23:25:37 INFO storage.MemoryStore: Block rdd_1_4 stored as values to memory (estimated size 68.7 MB, free 955.5 MB)
13/07/27 23:25:37 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_4 in memory on tachyon-ec2-0:38215 (size: 68.7 MB, free: 955.6 MB)
13/07/27 23:25:37 INFO storage.BlockManagerMaster: Updated info of block rdd_1_4
13/07/27 23:25:37 INFO local.LocalScheduler: Finished 4
13/07/27 23:25:37 INFO scheduler.DAGScheduler: Completed ResultTask(0, 4)
13/07/27 23:25:37 INFO local.LocalTaskSetManager: Size of task 5 is 1491 bytes
13/07/27 23:25:37 INFO local.LocalScheduler: Running 5
13/07/27 23:25:37 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:25:37 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@696
13/07/27 23:25:38 INFO storage.MemoryStore: ensureFreeSpace(69756558) called with curMem=356369972, maxMem=1358297825
13/07/27 23:25:38 INFO storage.MemoryStore: Block rdd_1_5 stored as values to memory (estimated size 66.5 MB, free 889.0 MB)
13/07/27 23:25:38 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_5 in memory on tachyon-ec2-0:38215 (size: 66.5 MB, free: 889.0 MB)
13/07/27 23:25:38 INFO storage.BlockManagerMaster: Updated info of block rdd_1_5
13/07/27 23:25:38 INFO local.LocalScheduler: Finished 5
13/07/27 23:25:38 INFO scheduler.DAGScheduler: Completed ResultTask(0, 5)
13/07/27 23:25:38 INFO local.LocalTaskSetManager: Size of task 6 is 1491 bytes
13/07/27 23:25:38 INFO local.LocalScheduler: Running 6
13/07/27 23:25:38 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:25:38 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@697
13/07/27 23:25:39 INFO storage.MemoryStore: ensureFreeSpace(71337286) called with curMem=426126530, maxMem=1358297825
13/07/27 23:25:39 INFO storage.MemoryStore: Block rdd_1_6 stored as values to memory (estimated size 68.0 MB, free 821.0 MB)
13/07/27 23:25:39 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_6 in memory on tachyon-ec2-0:38215 (size: 68.0 MB, free: 821.0 MB)
13/07/27 23:25:39 INFO storage.BlockManagerMaster: Updated info of block rdd_1_6
13/07/27 23:25:39 INFO local.LocalScheduler: Finished 6
13/07/27 23:25:39 INFO scheduler.DAGScheduler: Completed ResultTask(0, 6)
13/07/27 23:25:39 INFO local.LocalTaskSetManager: Size of task 7 is 1491 bytes
13/07/27 23:25:39 INFO local.LocalScheduler: Running 7
13/07/27 23:25:39 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:25:39 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@698
13/07/27 23:25:39 INFO storage.MemoryStore: ensureFreeSpace(71927110) called with curMem=497463816, maxMem=1358297825
13/07/27 23:25:39 INFO storage.MemoryStore: Block rdd_1_7 stored as values to memory (estimated size 68.6 MB, free 752.4 MB)
13/07/27 23:25:39 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_7 in memory on tachyon-ec2-0:38215 (size: 68.6 MB, free: 752.4 MB)
13/07/27 23:25:39 INFO storage.BlockManagerMaster: Updated info of block rdd_1_7
13/07/27 23:25:39 INFO local.LocalScheduler: Finished 7
13/07/27 23:25:39 INFO scheduler.DAGScheduler: Completed ResultTask(0, 7)
13/07/27 23:25:39 INFO local.LocalTaskSetManager: Size of task 8 is 1491 bytes
13/07/27 23:25:39 INFO local.LocalScheduler: Running 8
13/07/27 23:25:39 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:25:39 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@699
13/07/27 23:25:39 INFO storage.MemoryStore: ensureFreeSpace(68354088) called with curMem=569390926, maxMem=1358297825
13/07/27 23:25:39 INFO storage.MemoryStore: Block rdd_1_8 stored as values to memory (estimated size 65.2 MB, free 687.2 MB)
13/07/27 23:25:39 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_8 in memory on tachyon-ec2-0:38215 (size: 65.2 MB, free: 687.2 MB)
13/07/27 23:25:39 INFO storage.BlockManagerMaster: Updated info of block rdd_1_8
13/07/27 23:25:39 INFO local.LocalScheduler: Finished 8
13/07/27 23:25:39 INFO scheduler.DAGScheduler: Completed ResultTask(0, 8)
13/07/27 23:25:39 INFO local.LocalTaskSetManager: Size of task 9 is 1491 bytes
13/07/27 23:25:39 INFO local.LocalScheduler: Running 9
13/07/27 23:25:40 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:25:40 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69a
13/07/27 23:25:40 INFO storage.MemoryStore: ensureFreeSpace(72189254) called with curMem=637745014, maxMem=1358297825
13/07/27 23:25:40 INFO storage.MemoryStore: Block rdd_1_9 stored as values to memory (estimated size 68.8 MB, free 618.3 MB)
13/07/27 23:25:40 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_9 in memory on tachyon-ec2-0:38215 (size: 68.8 MB, free: 618.4 MB)
13/07/27 23:25:40 INFO storage.BlockManagerMaster: Updated info of block rdd_1_9
13/07/27 23:25:40 INFO local.LocalScheduler: Finished 9
13/07/27 23:25:40 INFO scheduler.DAGScheduler: Completed ResultTask(0, 9)
13/07/27 23:25:40 INFO local.LocalTaskSetManager: Size of task 10 is 1491 bytes
13/07/27 23:25:40 INFO local.LocalScheduler: Running 10
13/07/27 23:25:40 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:25:40 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69b
13/07/27 23:25:41 INFO storage.MemoryStore: ensureFreeSpace(69900737) called with curMem=709934268, maxMem=1358297825
13/07/27 23:25:41 INFO storage.MemoryStore: Block rdd_1_10 stored as values to memory (estimated size 66.7 MB, free 551.7 MB)
13/07/27 23:25:41 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_10 in memory on tachyon-ec2-0:38215 (size: 66.7 MB, free: 551.7 MB)
13/07/27 23:25:41 INFO storage.BlockManagerMaster: Updated info of block rdd_1_10
13/07/27 23:25:41 INFO local.LocalScheduler: Finished 10
13/07/27 23:25:41 INFO scheduler.DAGScheduler: Completed ResultTask(0, 10)
13/07/27 23:25:41 INFO local.LocalTaskSetManager: Size of task 11 is 1491 bytes
13/07/27 23:25:41 INFO local.LocalScheduler: Running 11
13/07/27 23:25:41 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:25:41 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69c
13/07/27 23:25:41 INFO storage.MemoryStore: ensureFreeSpace(71945460) called with curMem=779835005, maxMem=1358297825
13/07/27 23:25:41 INFO storage.MemoryStore: Block rdd_1_11 stored as values to memory (estimated size 68.6 MB, free 483.1 MB)
13/07/27 23:25:41 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_11 in memory on tachyon-ec2-0:38215 (size: 68.6 MB, free: 483.1 MB)
13/07/27 23:25:41 INFO storage.BlockManagerMaster: Updated info of block rdd_1_11
13/07/27 23:25:41 INFO local.LocalScheduler: Finished 11
13/07/27 23:25:41 INFO scheduler.DAGScheduler: Completed ResultTask(0, 11)
13/07/27 23:25:41 INFO local.LocalTaskSetManager: Size of task 12 is 1491 bytes
13/07/27 23:25:41 INFO local.LocalScheduler: Running 12
13/07/27 23:25:41 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:25:41 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69d
13/07/27 23:25:41 INFO storage.MemoryStore: ensureFreeSpace(71937596) called with curMem=851780465, maxMem=1358297825
13/07/27 23:25:41 INFO storage.MemoryStore: Block rdd_1_12 stored as values to memory (estimated size 68.6 MB, free 414.4 MB)
13/07/27 23:25:41 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_12 in memory on tachyon-ec2-0:38215 (size: 68.6 MB, free: 414.5 MB)
13/07/27 23:25:41 INFO storage.BlockManagerMaster: Updated info of block rdd_1_12
13/07/27 23:25:41 INFO local.LocalScheduler: Finished 12
13/07/27 23:25:41 INFO scheduler.DAGScheduler: Completed ResultTask(0, 12)
13/07/27 23:25:41 INFO local.LocalTaskSetManager: Size of task 13 is 1491 bytes
13/07/27 23:25:41 INFO local.LocalScheduler: Running 13
13/07/27 23:25:41 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:25:41 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69e
13/07/27 23:25:42 INFO storage.MemoryStore: ensureFreeSpace(72915393) called with curMem=923718061, maxMem=1358297825
13/07/27 23:25:42 INFO storage.MemoryStore: Block rdd_1_13 stored as values to memory (estimated size 69.5 MB, free 344.9 MB)
13/07/27 23:25:42 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_13 in memory on tachyon-ec2-0:38215 (size: 69.5 MB, free: 345.0 MB)
13/07/27 23:25:42 INFO storage.BlockManagerMaster: Updated info of block rdd_1_13
13/07/27 23:25:42 INFO local.LocalScheduler: Finished 13
13/07/27 23:25:42 INFO scheduler.DAGScheduler: Completed ResultTask(0, 13)
13/07/27 23:25:42 INFO local.LocalTaskSetManager: Size of task 14 is 1491 bytes
13/07/27 23:25:42 INFO local.LocalScheduler: Running 14
13/07/27 23:25:42 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:25:42 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@69f
13/07/27 23:25:43 INFO storage.MemoryStore: ensureFreeSpace(71974296) called with curMem=996633454, maxMem=1358297825
13/07/27 23:25:43 INFO storage.MemoryStore: Block rdd_1_14 stored as values to memory (estimated size 68.6 MB, free 276.3 MB)
13/07/27 23:25:43 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_14 in memory on tachyon-ec2-0:38215 (size: 68.6 MB, free: 276.3 MB)
13/07/27 23:25:43 INFO storage.BlockManagerMaster: Updated info of block rdd_1_14
13/07/27 23:25:43 INFO local.LocalScheduler: Finished 14
13/07/27 23:25:43 INFO scheduler.DAGScheduler: Completed ResultTask(0, 14)
13/07/27 23:25:43 INFO local.LocalTaskSetManager: Size of task 15 is 1491 bytes
13/07/27 23:25:43 INFO local.LocalScheduler: Running 15
13/07/27 23:25:43 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:25:43 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a0
13/07/27 23:25:43 INFO storage.MemoryStore: ensureFreeSpace(71051549) called with curMem=1068607750, maxMem=1358297825
13/07/27 23:25:43 INFO storage.MemoryStore: Block rdd_1_15 stored as values to memory (estimated size 67.8 MB, free 208.5 MB)
13/07/27 23:25:43 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_15 in memory on tachyon-ec2-0:38215 (size: 67.8 MB, free: 208.6 MB)
13/07/27 23:25:43 INFO storage.BlockManagerMaster: Updated info of block rdd_1_15
13/07/27 23:25:43 INFO local.LocalScheduler: Finished 15
13/07/27 23:25:43 INFO scheduler.DAGScheduler: Completed ResultTask(0, 15)
13/07/27 23:25:43 INFO local.LocalTaskSetManager: Size of task 16 is 1491 bytes
13/07/27 23:25:43 INFO local.LocalScheduler: Running 16
13/07/27 23:25:43 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:25:43 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a1
13/07/27 23:25:43 INFO storage.MemoryStore: ensureFreeSpace(71565352) called with curMem=1139659299, maxMem=1358297825
13/07/27 23:25:43 INFO storage.MemoryStore: Block rdd_1_16 stored as values to memory (estimated size 68.3 MB, free 140.3 MB)
13/07/27 23:25:43 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_16 in memory on tachyon-ec2-0:38215 (size: 68.3 MB, free: 140.3 MB)
13/07/27 23:25:43 INFO storage.BlockManagerMaster: Updated info of block rdd_1_16
13/07/27 23:25:43 INFO local.LocalScheduler: Finished 16
13/07/27 23:25:43 INFO scheduler.DAGScheduler: Completed ResultTask(0, 16)
13/07/27 23:25:43 INFO local.LocalTaskSetManager: Size of task 17 is 1491 bytes
13/07/27 23:25:43 INFO local.LocalScheduler: Running 17
13/07/27 23:25:43 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:25:43 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a2
13/07/27 23:25:44 INFO storage.MemoryStore: ensureFreeSpace(72682085) called with curMem=1211224651, maxMem=1358297825
13/07/27 23:25:44 INFO storage.MemoryStore: Block rdd_1_17 stored as values to memory (estimated size 69.3 MB, free 70.9 MB)
13/07/27 23:25:44 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_17 in memory on tachyon-ec2-0:38215 (size: 69.3 MB, free: 71.0 MB)
13/07/27 23:25:44 INFO storage.BlockManagerMaster: Updated info of block rdd_1_17
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 17
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(0, 17)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 18 is 1491 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 18
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:25:44 INFO spark.CacheManager: Computing partition spark.rdd.HadoopPartition@6a3
13/07/27 23:25:44 INFO storage.MemoryStore: ensureFreeSpace(30062713) called with curMem=1283906736, maxMem=1358297825
13/07/27 23:25:44 INFO storage.MemoryStore: Block rdd_1_18 stored as values to memory (estimated size 28.7 MB, free 42.3 MB)
13/07/27 23:25:44 INFO storage.BlockManagerMasterActor$BlockManagerInfo: Added rdd_1_18 in memory on tachyon-ec2-0:38215 (size: 28.7 MB, free: 42.3 MB)
13/07/27 23:25:44 INFO storage.BlockManagerMaster: Updated info of block rdd_1_18
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 18
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(0, 18)
13/07/27 23:25:44 INFO local.LocalScheduler: Remove TaskSet 0.0 from pool 
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Stage 0 (count at <console>:15) finished in 8.622 s
13/07/27 23:25:44 INFO spark.SparkContext: Job finished: count at <console>:15, took 8.672405434 s
res0: Long = 500094

scala> s.count()
13/07/27 23:25:44 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Got job 1 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Final stage: Stage 1 (count at <console>:15)
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Submitting Stage 1 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 1 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 19 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 19
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 19
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 0)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 20 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 20
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 20
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 1)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 21 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 21
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 21
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 2)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 22 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 22
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 22
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 3)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 23 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 23
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 23
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 4)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 24 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 24
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 24
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 5)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 25 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 25
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 25
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 6)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 26 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 26
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 26
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 7)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 27 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 27
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 27
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 8)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 28 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 28
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 28
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 9)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 29 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 29
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 29
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 10)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 30 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 30
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 30
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 11)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 31 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 31
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 31
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 12)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 32 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 32
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 32
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 13)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 33 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 33
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 33
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 14)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 34 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 34
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 34
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 15)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 35 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 35
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 35
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 16)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 36 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 36
13/07/27 23:25:44 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:25:44 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:44 INFO local.LocalScheduler: Finished 36
13/07/27 23:25:44 INFO scheduler.DAGScheduler: Completed ResultTask(1, 17)
13/07/27 23:25:44 INFO local.LocalTaskSetManager: Size of task 37 is 1492 bytes
13/07/27 23:25:44 INFO local.LocalScheduler: Running 37
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 37
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(1, 18)
13/07/27 23:25:45 INFO local.LocalScheduler: Remove TaskSet 1.0 from pool 
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Stage 1 (count at <console>:15) finished in 0.318 s
13/07/27 23:25:45 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.324022004 s
res1: Long = 500094

scala> s.count()
13/07/27 23:25:45 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Got job 2 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Final stage: Stage 2 (count at <console>:15)
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Submitting Stage 2 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 2 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 38 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 38
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 38
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 0)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 39 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 39
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 39
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 1)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 40 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 40
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 40
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 2)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 41 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 41
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 41
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 3)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 42 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 42
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 42
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 4)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 43 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 43
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 43
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 5)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 44 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 44
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 44
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 6)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 45 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 45
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 45
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 7)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 46 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 46
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 46
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 8)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 47 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 47
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 47
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 9)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 48 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 48
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 48
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 10)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 49 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 49
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 49
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 11)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 50 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 50
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 50
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 12)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 51 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 51
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 51
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 13)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 52 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 52
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 52
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 14)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 53 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 53
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 53
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 15)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 54 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 54
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 54
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 16)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 55 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 55
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 55
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 17)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 56 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 56
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 56
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(2, 18)
13/07/27 23:25:45 INFO local.LocalScheduler: Remove TaskSet 2.0 from pool 
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Stage 2 (count at <console>:15) finished in 0.280 s
13/07/27 23:25:45 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.286312495 s
res2: Long = 500094

scala> s.count()
13/07/27 23:25:45 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Got job 3 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Final stage: Stage 3 (count at <console>:15)
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Submitting Stage 3 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 3 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 57 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 57
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 57
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(3, 0)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 58 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 58
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 58
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(3, 1)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 59 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 59
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 59
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(3, 2)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 60 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 60
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 60
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(3, 3)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 61 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 61
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 61
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(3, 4)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 62 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 62
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 62
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(3, 5)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 63 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 63
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 63
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(3, 6)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 64 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 64
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 64
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(3, 7)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 65 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 65
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 65
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(3, 8)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 66 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 66
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 66
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(3, 9)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 67 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 67
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 67
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(3, 10)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 68 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 68
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 68
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(3, 11)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 69 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 69
13/07/27 23:25:45 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:25:45 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:45 INFO local.LocalScheduler: Finished 69
13/07/27 23:25:45 INFO scheduler.DAGScheduler: Completed ResultTask(3, 12)
13/07/27 23:25:45 INFO local.LocalTaskSetManager: Size of task 70 is 1492 bytes
13/07/27 23:25:45 INFO local.LocalScheduler: Running 70
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 70
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(3, 13)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 71 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 71
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 71
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(3, 14)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 72 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 72
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 72
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(3, 15)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 73 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 73
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 73
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(3, 16)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 74 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 74
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 74
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(3, 17)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 75 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 75
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 75
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(3, 18)
13/07/27 23:25:46 INFO local.LocalScheduler: Remove TaskSet 3.0 from pool 
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Stage 3 (count at <console>:15) finished in 0.267 s
13/07/27 23:25:46 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.273088855 s
res3: Long = 500094

scala> s.count()
13/07/27 23:25:46 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Got job 4 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Final stage: Stage 4 (count at <console>:15)
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Submitting Stage 4 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 4 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 76 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 76
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 76
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 0)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 77 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 77
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 77
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 1)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 78 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 78
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 78
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 2)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 79 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 79
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 79
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 3)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 80 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 80
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 80
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 4)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 81 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 81
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 81
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 5)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 82 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 82
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 82
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 6)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 83 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 83
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 83
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 7)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 84 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 84
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 84
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 8)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 85 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 85
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 85
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 9)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 86 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 86
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 86
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 10)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 87 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 87
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 87
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 11)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 88 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 88
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 88
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 12)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 89 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 89
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 89
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 13)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 90 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 90
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 90
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 14)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 91 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 91
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 91
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 15)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 92 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 92
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 92
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 16)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 93 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 93
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 93
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 17)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 94 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 94
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 94
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(4, 18)
13/07/27 23:25:46 INFO local.LocalScheduler: Remove TaskSet 4.0 from pool 
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Stage 4 (count at <console>:15) finished in 0.262 s
13/07/27 23:25:46 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.26788928 s
res4: Long = 500094

scala> s.count()
13/07/27 23:25:46 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Got job 5 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Final stage: Stage 5 (count at <console>:15)
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Submitting Stage 5 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 5 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 95 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 95
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 95
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(5, 0)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 96 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 96
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 96
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(5, 1)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 97 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 97
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 97
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(5, 2)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 98 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 98
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 98
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(5, 3)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 99 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 99
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 99
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(5, 4)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 100 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 100
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 100
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(5, 5)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 101 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 101
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 101
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(5, 6)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 102 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 102
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 102
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(5, 7)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 103 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 103
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 103
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(5, 8)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 104 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 104
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 104
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(5, 9)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 105 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 105
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 105
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(5, 10)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 106 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 106
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 106
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(5, 11)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 107 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 107
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 107
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(5, 12)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 108 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 108
13/07/27 23:25:46 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:25:46 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:46 INFO local.LocalScheduler: Finished 108
13/07/27 23:25:46 INFO scheduler.DAGScheduler: Completed ResultTask(5, 13)
13/07/27 23:25:46 INFO local.LocalTaskSetManager: Size of task 109 is 1492 bytes
13/07/27 23:25:46 INFO local.LocalScheduler: Running 109
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 109
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(5, 14)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 110 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 110
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 110
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(5, 15)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 111 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 111
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 111
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(5, 16)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 112 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 112
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 112
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(5, 17)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 113 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 113
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 113
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(5, 18)
13/07/27 23:25:47 INFO local.LocalScheduler: Remove TaskSet 5.0 from pool 
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Stage 5 (count at <console>:15) finished in 0.253 s
13/07/27 23:25:47 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.259161679 s
res5: Long = 500094

scala> s.count()
13/07/27 23:25:47 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Got job 6 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Final stage: Stage 6 (count at <console>:15)
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Submitting Stage 6 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 6 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 114 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 114
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 114
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 0)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 115 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 115
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 115
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 1)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 116 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 116
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 116
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 2)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 117 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 117
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 117
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 3)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 118 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 118
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 118
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 4)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 119 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 119
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 119
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 5)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 120 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 120
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 120
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 6)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 121 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 121
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 121
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 7)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 122 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 122
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 122
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 8)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 123 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 123
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 123
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 9)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 124 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 124
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 124
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 10)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 125 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 125
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 125
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 11)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 126 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 126
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 126
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 12)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 127 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 127
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 127
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 13)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 128 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 128
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 128
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 14)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 129 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 129
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 129
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 15)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 130 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 130
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 130
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 16)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 131 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 131
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 131
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 17)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 132 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 132
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 132
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(6, 18)
13/07/27 23:25:47 INFO local.LocalScheduler: Remove TaskSet 6.0 from pool 
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Stage 6 (count at <console>:15) finished in 0.246 s
13/07/27 23:25:47 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.251968387 s
res6: Long = 500094

scala> s.count()
13/07/27 23:25:47 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Got job 7 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Final stage: Stage 7 (count at <console>:15)
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Submitting Stage 7 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 7 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 133 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 133
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 133
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 0)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 134 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 134
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 134
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 1)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 135 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 135
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 135
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 2)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 136 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 136
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 136
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 3)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 137 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 137
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 137
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 4)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 138 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 138
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 138
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 5)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 139 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 139
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 139
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 6)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 140 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 140
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 140
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 7)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 141 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 141
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 141
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 8)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 142 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 142
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 142
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 9)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 143 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 143
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 143
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 10)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 144 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 144
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 144
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 11)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 145 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 145
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 145
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 12)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 146 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 146
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 146
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 13)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 147 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 147
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 147
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 14)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 148 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 148
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 148
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 15)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 149 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 149
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 149
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 16)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 150 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 150
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 150
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 17)
13/07/27 23:25:47 INFO local.LocalTaskSetManager: Size of task 151 is 1492 bytes
13/07/27 23:25:47 INFO local.LocalScheduler: Running 151
13/07/27 23:25:47 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:25:47 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:47 INFO local.LocalScheduler: Finished 151
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Completed ResultTask(7, 18)
13/07/27 23:25:47 INFO local.LocalScheduler: Remove TaskSet 7.0 from pool 
13/07/27 23:25:47 INFO scheduler.DAGScheduler: Stage 7 (count at <console>:15) finished in 0.235 s
13/07/27 23:25:47 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.240247128 s
res7: Long = 500094

scala> s.count()
13/07/27 23:25:48 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Got job 8 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Final stage: Stage 8 (count at <console>:15)
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Submitting Stage 8 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 8 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 152 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 152
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 152
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 0)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 153 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 153
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 153
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 1)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 154 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 154
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 154
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 2)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 155 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 155
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 155
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 3)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 156 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 156
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 156
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 4)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 157 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 157
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 157
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 5)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 158 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 158
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 158
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 6)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 159 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 159
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 159
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 7)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 160 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 160
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 160
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 8)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 161 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 161
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 161
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 9)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 162 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 162
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 162
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 10)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 163 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 163
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 163
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 11)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 164 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 164
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 164
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 12)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 165 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 165
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 165
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 13)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 166 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 166
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 166
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 14)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 167 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 167
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 167
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 15)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 168 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 168
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 168
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 16)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 169 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 169
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 169
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 17)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 170 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 170
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 170
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(8, 18)
13/07/27 23:25:48 INFO local.LocalScheduler: Remove TaskSet 8.0 from pool 
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Stage 8 (count at <console>:15) finished in 0.236 s
13/07/27 23:25:48 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.24133874 s
res8: Long = 500094

scala> s.count()
13/07/27 23:25:48 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Got job 9 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Final stage: Stage 9 (count at <console>:15)
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Submitting Stage 9 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 9 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 171 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 171
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 171
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(9, 0)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 172 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 172
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 172
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(9, 1)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 173 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 173
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 173
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(9, 2)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 174 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 174
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 174
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(9, 3)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 175 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 175
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 175
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(9, 4)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 176 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 176
13/07/27 23:25:48 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:25:48 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:48 INFO local.LocalScheduler: Finished 176
13/07/27 23:25:48 INFO scheduler.DAGScheduler: Completed ResultTask(9, 5)
13/07/27 23:25:48 INFO local.LocalTaskSetManager: Size of task 177 is 1492 bytes
13/07/27 23:25:48 INFO local.LocalScheduler: Running 177
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 177
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(9, 6)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 178 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 178
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 178
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(9, 7)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 179 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 179
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 179
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(9, 8)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 180 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 180
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 180
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(9, 9)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 181 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 181
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 181
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(9, 10)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 182 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 182
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 182
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(9, 11)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 183 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 183
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 183
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(9, 12)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 184 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 184
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 184
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(9, 13)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 185 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 185
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 185
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(9, 14)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 186 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 186
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 186
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(9, 15)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 187 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 187
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 187
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(9, 16)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 188 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 188
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 188
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(9, 17)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 189 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 189
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 189
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(9, 18)
13/07/27 23:25:49 INFO local.LocalScheduler: Remove TaskSet 9.0 from pool 
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Stage 9 (count at <console>:15) finished in 0.728 s
13/07/27 23:25:49 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.733627444 s
res9: Long = 500094

scala> s.count()
13/07/27 23:25:49 INFO spark.SparkContext: Starting job: count at <console>:15
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Got job 10 (count at <console>:15) with 19 output partitions (allowLocal=false)
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Final stage: Stage 10 (count at <console>:15)
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Submitting Stage 10 (MappedRDD[1] at textFile at <console>:12), which has no missing parents
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Submitting 19 missing tasks from Stage 10 (MappedRDD[1] at textFile at <console>:12)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 190 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 190
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_0
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 190
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 0)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 191 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 191
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_1
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 191
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 1)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 192 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 192
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_2
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 192
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 2)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 193 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 193
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_3
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 193
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 3)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 194 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 194
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_4
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 194
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 4)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 195 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 195
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_5
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 195
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 5)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 196 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 196
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_6
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 196
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 6)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 197 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 197
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_7
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 197
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 7)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 198 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 198
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_8
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 198
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 8)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 199 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 199
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_9
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 199
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 9)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 200 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 200
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_10
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 200
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 10)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 201 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 201
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_11
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 201
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 11)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 202 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 202
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_12
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 202
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 12)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 203 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 203
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_13
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 203
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 13)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 204 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 204
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_14
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 204
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 14)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 205 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 205
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_15
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 205
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 15)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 206 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 206
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_16
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 206
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 16)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 207 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 207
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_17
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 207
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 17)
13/07/27 23:25:49 INFO local.LocalTaskSetManager: Size of task 208 is 1492 bytes
13/07/27 23:25:49 INFO local.LocalScheduler: Running 208
13/07/27 23:25:49 INFO spark.CacheManager: Cache key is rdd_1_18
13/07/27 23:25:49 INFO spark.CacheManager: Found partition in cache!
13/07/27 23:25:49 INFO local.LocalScheduler: Finished 208
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Completed ResultTask(10, 18)
13/07/27 23:25:49 INFO local.LocalScheduler: Remove TaskSet 10.0 from pool 
13/07/27 23:25:49 INFO scheduler.DAGScheduler: Stage 10 (count at <console>:15) finished in 0.218 s
13/07/27 23:25:49 INFO spark.SparkContext: Job finished: count at <console>:15, took 0.223054175 s
res10: Long = 500094

scala> 13/07/27 23:25:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/,null}
13/07/27 23:25:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/static,null}
13/07/27 23:25:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/executors,null}
13/07/27 23:25:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/environment,null}
13/07/27 23:25:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages,null}
13/07/27 23:25:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/stages/stage,null}
13/07/27 23:25:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage,null}
13/07/27 23:25:49 INFO handler.ContextHandler: stopped o.e.j.s.h.ContextHandler{/storage/rdd,null}
